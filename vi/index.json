[{"uri":"https://khanh-0.github.io/aws/vi/","title":"Báo cáo thực tập","tags":[],"description":"","content":"Báo cáo thực tập Thông tin sinh viên: Họ và tên: Đinh Viết Vĩnh Khánh\nSố điện thoại: 0353513278\nEmail: khanhdvvse181518@fpt.edu.vn\nTrường: Đại Học FPT HCM\nNgành: Trí Tuệ Nhân Tạo\nLớp: AWS082025\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: GenAI Intern\nThời gian thực tập: Từ ngày 8/09/2025 đến ngày 9/12/2026\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "},{"uri":"https://khanh-0.github.io/aws/vi/4-eventparticipated/4.1-event1/","title":"Kick-off AWS First Cloud Journey Workforce","tags":[],"description":"","content":"Mục tiêu Sự kiện Chúc mừng các bạn sinh viên đã xuất sắc vượt qua vòng tuyển chọn để tham gia chương trình AWS First Cloud Journey – Training on the Job (OJT FALL 2025) Đánh dấu sự khởi đầu của một hành trình học tập có định hướng và trải nghiệm cloud thực tế cùng Amazon Web Services (AWS) Trang bị kỹ năng thực hành trong các lĩnh vực Cloud, DevOps, Security, AI/ML và Data \u0026amp; Analytics Kết nối sinh viên với cộng đồng AWS Study Group (47.000+ thành viên) và các công ty đối tác AWS Xây dựng cầu nối giữa kiến thức – công nghệ – sự nghiệp, định hướng thế hệ AWS Builders tiếp theo tại Việt Nam Diễn Giả Nguyễn Trần Phước Bảo – Head of Corporate Relations, FPT University Nguyễn Gia Hưng – Head of Solutions Architect, AWS Vietnam Đỗ Huy Thắng – DevOps Lead, VNG Danh Hoàng Hiếu Nghị – GenAI Engineer, Renova Bùi Hồ Linh Nhi – AI Engineer, SoftwareOne Phạm Nguyễn Hải Anh – Cloud Engineer, G-Asia Pacific Nguyễn Đông Thành Hiệp – Principal Cloud Engineer, G-Asia Pacific Điểm Nổi Bật Lễ khởi động chương trình AWS First Cloud Journey Workforce Lần đầu tiên tôi được gặp những con người tuyệt vời đang thực hiện những hoạt động tuyệt vời tại AWS HCMC. Đây thực sự là trải nghiệm ấn tượng nhất mà tôi từng chứng kiến.\nSự kiện đánh dấu lễ khởi động chính thức của hơn 150 sinh viên thuộc đợt OJT Fall 2025.\nKể từ năm 2021, AWS First Cloud Journey đã hỗ trợ hơn 2.000 sinh viên, trong đó nhiều bạn hiện đang làm việc tại các công ty công nghệ hàng đầu trong và ngoài nước.\nTrong buổi Kick-off, các diễn giả đã chia sẻ về:\nTương lai của Cloud Computing tại Việt Nam Định hướng nghề nghiệp trong DevOps, Cloud và AI/ML Xu hướng nhân lực và nhu cầu thị trường trong những năm tới Agenda tổng quan sự kiện 8:30 – 9:00 | Check-in, Networking \u0026amp; Chụp hình nhóm 9:00 – 9:15 | Khai mạc từ FPT University 9:15 – 9:40 | AWS First Cloud Journey \u0026amp; Future Direction – Nguyễn Gia Hưng 9:40 – 10:05 | DevOps \u0026amp; Career Opportunities – Đỗ Huy Thắng 10:05 – 10:20 | Tea Break \u0026amp; Networking 10:20 – 10:40 | From FCJ to GenAI Engineer – Danh Hoàng Hiếu Nghị 10:40 – 11:00 | She in Tech – The FCJ Journey – Bùi Hồ Linh Nhi 11:00 – 11:20 | A Day in the Life of a Cloud Engineer – Phạm Nguyễn Hải Anh 11:20 – 11:40 | Becoming a Cloud Engineer – Nguyễn Đông Thành Hiệp 11:40 – 12:00 | Q\u0026amp;A \u0026amp; Chụp hình cuối chương trình Những Điều Rút Ra Góc Nhìn Nghề Nghiệp \u0026amp; Chiến Lược Phát Triển Bản Thân Cloud và DevOps tiếp tục là hai lĩnh vực có nhu cầu nhân lực cao nhất Các kỹ năng quan trọng được nhấn mạnh: Nền tảng cloud (IAM, VPC, Compute, Storage…) Tư duy DevOps và CI/CD Tư duy phân tích và giải quyết vấn đề Lộ trình học tập gợi ý: Cloud Foundation → Hands-on Projects → DevOps Tools → Chuyên sâu (AI/ML, Security, Data) Góc Nhìn Từ Doanh Nghiệp \u0026amp; Alumni AWS tái khẳng định sứ mệnh xây dựng thế hệ AWS Builders tiếp theo tại Việt Nam Doanh nghiệp chia sẻ nhu cầu tuyển dụng: Cloud Engineer DevOps Engineer AI/ML Engineer Data Engineer Alumni chia sẻ rằng tự học, thực hành và tham gia cộng đồng là yếu tố giúp họ thành công Ứng Dụng vào Công Việc Bắt đầu với các kiến thức nền tảng AWS: IAM, EC2, S3, VPC Làm quen với các công cụ DevOps: Git, Docker, CI/CD (GitHub Actions) Xây dựng mini-projects và viết tài liệu kỹ thuật Tham gia sự kiện, workshop, mentoring của AWS Study Group Dần khám phá các chủ đề nâng cao: Serverless, Containers, IaC, AI/ML Trải Nghiệm Sự Kiện Là một intern của AWS FCJ HCMC Team, tham dự Kick-off AWS First Cloud Journey Workforce OJT FALL 2025 là một trải nghiệm đầy cảm hứng và động lực.\nNhững gì tôi học được Hiểu rõ hơn về thị trường việc làm Cloud \u0026amp; DevOps tại Việt Nam Nhận nguồn động lực lớn từ các anh chị alumni FCJ Các mindset quan trọng xuyên suốt chương trình: Tự học Thử nghiệm Sẵn sàng đối mặt thử thách Tầm quan trọng của networking và kết nối với mentor, peers Networking \u0026amp; Cộng Đồng Gặp gỡ các mentor, diễn giả, AWS specialist và engineers trong lĩnh vực Cloud–DevOps–AI Xây dựng network vững mạnh cùng teammates và các bạn trong FCJ Cohort Sự kiện Kick-off không chỉ mang lại góc nhìn nghề nghiệp và định hướng kỹ thuật, mà còn tiếp thêm động lực để tôi bắt đầu hành trình trở thành một AWS Builder.\n"},{"uri":"https://khanh-0.github.io/aws/vi/1-worklog/","title":"Nhật ký công việc","tags":[],"description":"","content":"Trong trang này bạn sẽ tìm thấy nhật ký công việc ghi lại hành trình học AWS của tôi. Tôi đã hoàn thành chương trình này trong 12 tuần (khoảng 3 tháng), học và thực hành các dịch vụ AWS một cách có hệ thống từ cơ bản đến nâng cao.\nTrong suốt thời gian thực tập, tôi đã tiến bộ từ các khái niệm AWS cơ bản đến thiết kế và triển khai các kiến trúc cloud hoàn chỉnh. Mỗi tuần tập trung vào các dịch vụ AWS cụ thể và thực hành hands-on, xây dựng dựa trên kiến thức trước đó để phát triển kỹ năng điện toán đám mây toàn diện.\nDưới đây là tiến trình học tập theo từng tuần của tôi:\nTuần 1: Làm quen với AWS và các dịch vụ cơ bản trong AWS\nTuần 2: Tìm hiểu AWS Virtual Private Cloud (VPC)\nTuần 3: Nắm vững Amazon EC2 và các dịch vụ compute\nTuần 4: Hiểu về AWS IAM và EC2 Instance Storage\nTuần 5: Học High Availability, Scalability và các dịch vụ Database\nTuần 6: Nắm vững Amazon Route 53 và Classic Solutions Architecture\nTuần 7: Hiểu về Amazon S3 và các tính năng lưu trữ\nTuần 8: Học CloudFront, Global Accelerator và AWS Integration \u0026amp; Messaging\nTuần 9: Nắm vững Containers và Serverless architectures\nTuần 10: Hiểu về Databases, Data \u0026amp; Analytics và Machine Learning services\nTuần 11: Học AWS Monitoring, Security và Advanced Identity\nTuần 12: Nắm vững Disaster Recovery, Migration strategies và ôn tập tổng hợp\n"},{"uri":"https://khanh-0.github.io/aws/vi/1-worklog/1.1-week1/","title":"Worklog Tuần 1","tags":[],"description":"","content":"Mục tiêu tuần 1: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập 08/09/2025 08/09/2025 3 - Tìm hiểu AWS và các loại dịch vụ + Compute + Storage + Networking + Database + \u0026hellip; 09/09/2025 12/09/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account 10/09/2025 10/09/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu các loại budget cơ bản: + Cost budget + Usage budget + Saving plans budget + Reservation budget 11/09/2025 11/09/2025 https://cloudjourney.awsstudygroup.com/ 6 - Tìm hiểu và thực hành: + AWS support packages + Change AWS support packages + Manage support request 12/09/2025 12/09/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 1: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute:Dùng để chạy ứng dụng, xử lý dữ liệu, tạo môi trường máy chủ ảo hoặc container. Một số dịch vụ chính: EC2 (Elastic Compute Cloud): Máy chủ ảo chạy trên AWS (giống VPS nhưng linh hoạt hơn). Lambda: Chạy code serverless, không cần quản lý server, trả phí theo số lần chạy. ECS/EKS (Elastic Container Service / Elastic Kubernetes Service): Quản lý container (Docker/K8s). Elastic Beanstalk: Deploy app tự động (giống PaaS)\nStorage:Lưu dữ liệu, từ file nhỏ đến dữ liệu Big Data. S3 (Simple Storage Service): Lưu trữ đối tượng (object storage) – dùng cho file, ảnh, video. EBS (Elastic Block Store): Lưu trữ dạng block (dùng kèm EC2 như ổ cứng). EFS (Elastic File System): Lưu trữ dạng file system, nhiều máy có thể cùng truy cập. Glacier: Lưu trữ lâu dài, giá rẻ (cho backup/archive).\nNetworking: Kết nối các dịch vụ, bảo mật và phân phối ứng dụng. VPC (Virtual Private Cloud): Tạo mạng riêng ảo trong AWS (giống data center riêng). Route 53: Dịch vụ DNS, quản lý domain. CloudFront: CDN phân phối nội dung nhanh hơn cho người dùng toàn cầu. ELB (Elastic Load Balancer): Cân bằng tải giữa nhiều server. API Gateway: Quản lý và bảo mật API.\nDatabase: Lưu trữ và quản lý dữ liệu có cấu trúc/phi cấu trúc. RDS (Relational Database Service): Quản lý CSDL quan hệ (MySQL, PostgreSQL, Oracle, SQL Server). Aurora: Database do AWS phát triển, tương thích MySQL/PostgreSQL, nhanh hơn RDS. DynamoDB: NoSQL Database (phi quan hệ), tốc độ cao, tự động scale. Redshift: Data warehouse để phân tích dữ liệu lớn. ElastiCache: Cache dữ liệu (Redis/Memcached).\nĐã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Xem dịch vụ EC2 Tạo và quản lý key pair Kiểm tra thông tin dịch vụ đang chạy "},{"uri":"https://khanh-0.github.io/aws/vi/5-workshop/5.3-architecture/5.3.1-agentcore-memory/","title":"Agent core memory","tags":[],"description":"","content":"Cấu hình Memory trong AgentCore Để tạo bộ nhớ cho AgentCore, thực hiện theo các bước dưới đây.\n1. Tạo Memory trong Bedrock Vào Bedrock → chọn AgentCore. Chuyển sang tab Memory. Nhấn Create memory. Trong giao diện tạo Memory, bạn sẽ thấy các phần sau:\nMemory name Đặt tên bộ nhớ mà AgentCore sẽ sử dụng.\nShort-term memory (raw event) expiration Số ngày hệ thống lưu lại lịch sử hội thoại chi tiết.\nDemo này có thể để mặc định 90 ngày.\n2. Các loại Memory trong AgentCore 1. Summarization – Tóm tắt hội thoại Chức năng: Tóm tắt nội dung hội thoại sau khi kết thúc hoặc theo chu kỳ.\nTác dụng: Giữ lại ngữ cảnh dài hạn mà không chiếm nhiều bộ nhớ.\nVí dụ:\nBạn chat 100 câu về lỗi AWS CLI → lần sau Agent nhớ:\n“Người dùng đang gặp lỗi kết nối AWS CLI.”\n2. Semantic Memory – Bộ nhớ ngữ nghĩa Chức năng: Lưu trữ các facts/kiến thức quan trọng, độc lập với ngữ cảnh.\nTác dụng: Dùng để trả lời các câu hỏi liên quan đến thông tin đã nói trước đó.\nVí dụ:\n“Dự án A dùng Python 3.9.”\nLần sau hỏi lại → Agent trả lời ngay Python 3.9.\n3. User Preferences – Sở thích người dùng Chức năng: Tự nhận biết thói quen và phong cách của người dùng.\nTác dụng: Cá nhân hóa cách phản hồi.\nVí dụ:\nBạn hay yêu cầu:\n“Hãy trả lời ngắn gọn.”\nAgent sẽ tự động trả lời đúng ý mỗi lần.\n4. Episodes – Bộ nhớ tình huống Chức năng: Lưu chuỗi sự kiện, phân tích thành công/thất bại qua Reflections.\nTác dụng: Giúp Agent học từ kinh nghiệm.\nVí dụ:\nLần trước đặt vé bị lỗi vì thiếu ngày tháng → Agent nhớ.\nLần sau nó sẽ hỏi ngày tháng trước.\n3. Loại Memory dùng trong Demo Trong phần demo, chỉ cần dùng loại:\nSummarization Chọn Summarization rồi nhấn Create để hoàn tất.\n4. Cập nhật Memory ID trong Python Sau khi tạo Memory, bạn sẽ nhận được Memory ID.\nThêm vào file Python như sau:\n# AgentCore Memory Configuration REGION = \u0026#34;ap-southeast-1\u0026#34; MEMORY_ID = \u0026#34;memory_j98zj-4LFDxqB2o1\u0026#34; GROQ_API_KEY = os.getenv(\u0026#34;GROQ_API_KEY\u0026#34;) lưu ý thay đổi Id Memory và Region theo đúng cái bạn đã tạo\n"},{"uri":"https://khanh-0.github.io/aws/vi/5-workshop/5.4-agent-core-run/5.4.1-run-agentcore/","title":"Cấu hình &amp; Deploy AgentCore","tags":[],"description":"","content":"Bắt đầu với AgentCore Configure Đầu tiên, bạn cần đẩy code từ máy local lên AWS AgentCore bằng lệnh:\nagentcore configure -e ./{ten_file_python.py} 1. Agent Name Nhập tên cho Agent của bạn.\n2. Configuration File Nhấn Enter để dùng file cấu hình mặc định pyproject.toml.\n3. Deployment Configuration Chọn 2 – Deploy bằng Docker để AgentCore tự tạo Docker image và quản lý dễ dàng hơn.\n4. Execution Role Để mặc định và cho AWS tự tạo IAM Role.\n5. ECR Repository Nhấn Enter để AWS tự tạo nơi lưu Docker image.\n6. Authorization Configuration Chọn No cho OAuth. Agent chỉ cho phép truy cập qua AWS IAM Access Key \u0026amp; Secret Key.\n7. Request Header Allowlist Nhấn Enter để dùng cấu hình mặc định.\nKết quả Hoàn tất bước này là bạn đã đẩy code lên AgentCore thành công.\nKhởi chạy Agent\nDùng lệnh sau để chạy Agent với API Key (dùng GROQ):\nagentcore launch \u0026ndash;env GROQ_API_KEY=your_api_key_here\nKhi terminal báo trạng thái Running, Agent của bạn đã hoạt động thành công.\n"},{"uri":"https://khanh-0.github.io/aws/vi/3-blogstranslated/3.1-blog1/","title":"Dynamic Kubernetes request right sizing with Kubecost","tags":[],"description":"","content":"Dynamic Kubernetes Request Right Sizing with Kubecost Trong bài viết này, chúng ta sẽ tìm hiểu cách sử dụng Kubecost Amazon Elastic Kubernetes Service (Amazon EKS) add-on để giảm chi phí hạ tầng và tối ưu hóa hiệu suất Kubernetes. Tính năng Container Request Right Sizing giúp đánh giá cách các yêu cầu container được cấu hình, phát hiện sự kém hiệu quả và tối ưu chúng thủ công hoặc tự động.\nChúng ta cũng sẽ xem cách đánh giá các đề xuất right sizing và thực hiện các cập nhật một lần hoặc tự động theo lịch trình, giúp môi trường Amazon EKS duy trì trạng thái tối ưu liên tục.\nYêu cầu Container là gì? Trong Kubernetes, một container request là mức CPU và bộ nhớ tối thiểu mà workload khai báo để scheduler có thể đặt pod lên node phù hợp.\nScheduler sẽ tìm node có đủ tài nguyên chưa dùng. Khi pod được đặt lên node, tài nguyên đó được “giữ chỗ”, dù container có dùng hết hay không. Nếu yêu cầu quá cao → lãng phí tài nguyên và tăng chi phí. Yêu cầu còn ảnh hưởng đến lớp Quality-of-Service (QoS) và quyết định eviction. Kubecost Savings Insights Kubecost Amazon EKS add-on cung cấp khả năng hiển thị chi tiết về các container đang yêu cầu tài nguyên quá mức.\nDashboard Container Request Sizing hiển thị:\nDanh sách container có thể tối ưu yêu cầu tài nguyên Hiệu quả yêu cầu CPU/memory hiện tại Mức sử dụng CPU/memory trung bình và tối đa Ước tính chi phí tiết kiệm mỗi tháng Tổng mức tiết kiệm tiềm năng cho toàn cluster Hình 1: Container Request Right Sizing recommendations\nRight sizing đặc biệt hiệu quả trong môi trường dev, test và staging — nơi yêu cầu hiệu suất thường “dư thừa”.\nTùy chỉnh đề xuất thay đổi kích thước Kubecost cho phép điều chỉnh các đề xuất theo:\nLoại workload Criticality Mục tiêu vận hành Bạn có thể chọn các profile dựng sẵn như:\ndevelopment production high availability Hoặc tự tạo profile riêng.\nCác tham số điều chỉnh gồm:\nCPU/memory target utilization Query window (48h, 7 ngày, …) Lọc workload theo label, namespace, controller Hành động với đề xuất của Kubecost 1. Thay đổi kích thước một lần Resize Requests Now trong dashboard giúp áp dụng ngay các request được đề xuất lên:\nDeployments StatefulSets Jobs Phản ánh đúng profile bạn đã chọn. Hình 2: Enable Resize Requests, and Enable Autoscaling\n2. Right sizing theo lịch trình Chọn Enable Autoscaling để:\nThiết lập job resize định kỳ Cập nhật yêu cầu theo dữ liệu sử dụng gần đây Duy trì request tối ưu theo thời gian Ví dụ:\nJob chạy mỗi 2 giờ, dựa trên dữ liệu 48h, target 80% CPU/memory.\n3. Tự động hóa bằng Helm Có thể enable tự động right sizing ngay trong bước cài đặt Kubecost bằng Helm.\nVí dụ cấu hình:\nclusterController: enabled: true actionConfigs: containerRightsize: filterConfig: - filter: | controllerKind:\u0026#34;deployment\u0026#34; schedule: start: \u0026#34;2024-08-20T00:00:00Z\u0026#34; frequencyMinutes: 120 recommendationQueryWindow: \u0026#34;48h\u0026#34; targetUtilizationCPU: 0.8 targetUtilizationMemory: 0.8 Cấu hình này:\nChạy mỗi 2 giờ Nhắm mục tiêu mức sử dụng 80% Áp dụng cho tất cả Deployments Lý tưởng cho platform team muốn enforce best practices tự động Kết luận Lợi ích thực tế từ Kubecost request sizing:\nGiảm 20–60% chi phí compute trong môi trường non-production Tăng mức sử dụng node Lập lịch pod nhanh hơn Tối ưu hiệu suất và giảm bottleneck Kubecost giúp bạn:\nPhát hiện workload kém hiệu quả Nhận đề xuất dựa trên dữ liệu Tùy chỉnh chiến lược tối ưu Áp dụng thủ công hoặc tự động Nếu bạn chưa dùng Kubecost, hãy bắt đầu tại trang Get Started để cài đặt vào EKS cluster.\nVề tác giả | | Kai Wombacher\nGiám đốc sản phẩm tại IBM Kubecost, chuyên về tối ưu Kubernetes chi phí lớn. |\n| | Jason Janiak\nKiến trúc sư giải pháp đối tác tại AWS. |\n| | Mike Stefaniak\nGiám đốc cấp cao nhóm sản phẩm Amazon EKS tại AWS. |\n"},{"uri":"https://khanh-0.github.io/aws/vi/5-workshop/5.1-workshop-overview/","title":"Giới thiệu","tags":[],"description":"","content":"Giới thiệu về WorkShop Workshop này hướng dẫn từng bước thiết lập IAM, AWS CLI, UV, Groq API, triển khai mã nguồn RAG tích hợp Groq LLM vào AWS AgentCore và cuối cùng là publish API qua AWS Gateway. Mục tiêu WorkShop \u0026ldquo;Cách gọi api\u0026rdquo; hiểu cách gọi api bên ngoài Aws Agent Core \u0026ldquo;Chunking\u0026rdquo; cách chunking chia dữ liệu cho Rag có thể lấy ra được một cách tối ưu \u0026ldquo;Thêm bộ nhớ cho Rag\u0026rdquo; tìm hiểu cách mà Agent Rag có thể nhớ được từng dữ liệu khi tương tác với người đùng \u0026ldquo;Deploy Aws Agent Core\u0026rdquo; tim hiểu cách mà triển khai được Aws Agent Core \u0026ldquo;Triển khai API\u0026rdquo; cách gọi Agent Core thông qua API "},{"uri":"https://khanh-0.github.io/aws/vi/4-eventparticipated/4.2-event2/","title":"Cloud Day AWS 2025 in HCMC","tags":[],"description":"","content":"Mục tiêu Sự kiện Trải nghiệm phiên toàn thể được livestream trực tiếp từ Hà Nội Lắng nghe các keynote và thông báo đột phá định hình tương lai điện toán đám mây tại Việt Nam Generative AI: Khám phá những cập nhật mới nhất và ứng dụng thực tiễn Data Analytics: Chuyển đổi doanh nghiệp thông qua insights từ dữ liệu Migration \u0026amp; Modernization: Điều hướng hành trình chuyển đổi lên đám mây Diễn Giả Eric Yeo – Country General Manager, Vietnam, Cambodia, Laos \u0026amp; Myanmar, AWS Jaime Valles – Vice President, Commercial Sales \u0026amp; Business Development APJ, AWS Jeff Johnson – Managing Director ASEAN, AWS Dr Jens Lottner – CEO, Techcombank Trang Phung – CEO, U2U Network Vũ Văn – Co-founder \u0026amp; CEO, ELSA Corp Nguyễn Hoà Bình – Chairman, Nexttech Group Dieter Botha – CEO, Tymex Nguyễn Văn Hải – Director of Software Engineering, Techcombank Nguyễn Thế Vinh – Co-Founder \u0026amp; CTO, Ninety Eight Nguyễn Minh Ngân – AI Specialist, OCB Nguyễn Mạnh Tuyến – Head of Data Application, LPBank Securities Điểm Nổi Bật Vietnam Cloud Day 2025 – Trải nghiệm Hybrid Dù sự kiện chính diễn ra tại Hà Nội, tôi vô cùng háo hức khi được trải nghiệm một sự kiện hybrid liền mạch ngay tại TP. Hồ Chí Minh.\nKết nối cùng các chuyên gia cloud và nhà lãnh đạo ngành công nghệ ngay tại HCMC!\nTrải nghiệm phiên toàn thể livestream từ Hà Nội với những keynote và thông báo quan trọng sẽ định hình tương lai cloud tại Việt Nam.\nCác Chủ Đề Trọng Tâm \u0026amp; Phiên Chuyên Sâu Các phiên tại TP.HCM tập trung vào 3 chủ đề lớn:\nGenerative AI – Cập nhật mới nhất và ứng dụng thực tế Data Analytics – Chuyển đổi doanh nghiệp bằng dữ liệu Migration \u0026amp; Modernization – Điều hướng hành trình chuyển đổi ứng dụng lên cloud Lợi Ích Đáng Kể Kết nối cộng đồng công nghệ tại HCMC Học trực tiếp từ các chuyên gia hàng đầu Việt Nam về cloud Đón đầu xu hướng với các cập nhật về tương lai điện toán đám mây Những Điều Rút Ra Nhận Thức Chiến Lược từ Vietnam Cloud Day 2025 Đà tăng tốc của việc ứng dụng cloud: Các doanh nghiệp Việt Nam đang đẩy mạnh chuyển đổi số Hợp tác với Chính phủ: Mở đầu nhấn mạnh sáng kiến cloud-first quốc gia Câu chuyện thành công của khách hàng: Techcombank và U2U Network chia sẻ hành trình dùng AWS Tầm nhìn lãnh đạo: Panel discussion nhấn mạnh việc đồng bộ hóa chiến lược GenAI với mục tiêu kinh doanh Kiến Thức Chuyên Sâu – Generative AI \u0026amp; Data Nền tảng dữ liệu thống nhất: Chiến lược xây dựng pipeline dữ liệu có khả năng mở rộng và quản trị tốt Lộ trình ứng dụng GenAI: Hướng dẫn cách tận dụng AWS để đổi mới với AI AI-DLC (AI-Driven Development Lifecycle): Tích hợp AI xuyên suốt SDLC Best practices bảo mật: Bảo vệ dữ liệu, mô hình và ứng dụng với bảo mật nhiều lớp của AWS AI Agents: Tiến xa hơn automation – tạo ra hệ thống thông minh và thích ứng Kiến Trúc \u0026amp; Vận Hành Thiết kế rời rạc và event-driven: Xây dựng hệ thống resilient và dễ mở rộng Tùy chọn compute: EC2, containers hay serverless tùy workload Scalability \u0026amp; Observability: Thiết kế hệ thống có khả năng giám sát và tối ưu chi phí Ứng Dụng vào Công Việc Đánh giá workload hiện tại để xác định ứng dụng phù hợp chuyển lên AWS trước Xây dựng nền tảng dữ liệu: từ ingestion → storage → processing cho analytics \u0026amp; AI Thử nghiệm GenAI: Dùng Amazon Bedrock hoặc SageMaker cho các use-case thử nghiệm Tăng cường bảo mật: IAM least privilege, cấu hình network an toàn Nâng cao kỹ năng đội ngũ: Khuyến khích học AI/ML và các dịch vụ AWS Trải nghiệm Sự kiện Đây là lần đầu tiên tôi biết đến anh Eric Yeo – Giám đốc khu vực của AWS. Anh là một nhà lãnh đạo tuyệt vời.\nTham dự “Vietnam Cloud Day 2025: Ho Chi Minh City Connect Edition for Builders” mang lại cho tôi cái nhìn rõ ràng hơn về hành trình hiện đại hóa ứng dụng và cơ sở dữ liệu bằng các phương pháp và công cụ tiên tiến.\nHọc từ Các Nhà Lãnh Đạo Ngành Thu nhận nhiều insight giá trị từ chuyên gia AWS và các lãnh đạo công nghệ Các case study thực tế giúp tôi hiểu rõ hơn cách áp dụng Domain-Driven Design (DDD) và Event-Driven Architecture vào dự án quy mô lớn Trải Nghiệm Kỹ Thuật Thực Tế Tham gia event storming workshops, mô phỏng quy trình nghiệp vụ thành domain events Thực hành phân rã hệ thống thành microservices với bounded contexts rõ ràng Tìm hiểu ưu – nhược điểm giữa synchronous vs asynchronous communication, và khi nào dùng pub/sub, point-to-point, streaming patterns Khám Phá Công Cụ Hiện Đại Tìm hiểu Amazon Q Developer, một trợ lý AI hỗ trợ toàn bộ SDLC Thực hành tự động hóa refactor code Hiểu cách triển khai serverless architectures với AWS Lambda để tối ưu tốc độ và tính linh hoạt Kết Nối \u0026amp; Giao Lưu Kết nối với chuyên gia AWS, lãnh đạo doanh nghiệp và các builder Thảo luận về tầm quan trọng của ubiquitous language giữa team kỹ thuật và team nghiệp vụ Bài Học Quan Trọng Áp dụng DDD và event-driven patterns nâng cao khả năng mở rộng, độ bền và khả năng bảo trì Hiện đại hóa hệ thống cần cách tiếp cận theo từng giai đoạn, có đo lường ROI để giảm rủi ro AI tools như Amazon Q Developer rút ngắn đáng kể thời gian phát triển và tối ưu workflow Một số hình ảnh sự kiện Nhìn chung, sự kiện không chỉ mang lại kiến thức kỹ thuật mà còn giúp tôi thay đổi góc nhìn về thiết kế ứng dụng, hiện đại hóa hệ thống và sự phối hợp hiệu quả giữa các đội nhóm.\n"},{"uri":"https://khanh-0.github.io/aws/vi/1-worklog/1.2-week2/","title":"Worklog Tuần 2","tags":[],"description":"","content":"Mục tiêu tuần 2: Tìm hiểu nội dung về AWS Virtual Private Cloud Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Lên văn phòng làm quen bạn mới - Tìm hiểu về cơ bản về amazon vpc -Lí thuyết về subnets, Routetable, Internet Gateway, Nat gateway 15/09/2025 15/09/2025 3 - Lí thuyết về tường lửa trong VPC - Security group, Network ACLs, VPC Resource map 16/09/2025 16/09/2025 https://cloudjourney.awsstudygroup.com/ 4 - Làm bài thực hành cơ bản - Tạo VPC, Ineternet Gateway, Tạo route table, Tạo security group - Kích hoạt VPC flow Logs 17/09/2025 17/09/2025 https://cloudjourney.awsstudygroup.com/ 5 - Triển khai amazon EC2 + Tạo máy chủ EC2 + Tạo NAT Gateway + Sử dụng Reachability Analyzer - Các cách remote SSH vào EC2 - Tìm hiểu Elastic IP 18/09/2025 18/09/2025 https://cloudjourney.awsstudygroup.com/ 6 - Tìm hiểu: + Cấu hình Site to Site VPN + Dọn dẹp tài nguyên 19/09/2025 19/09/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 2: Hiểu AWS và nắm được các nhóm dịch vụ cơ bản của Amazon VPC: Subnets Route table Internet gateway NAT gateway Tường lửa trong Amazon VPC Triển khai Amazon EC2 Instances "},{"uri":"https://khanh-0.github.io/aws/vi/5-workshop/5.2-prerequiste/","title":"Các bước chuẩn bị","tags":[],"description":"","content":"IAM permissions Các quyền cần thêm AdministratorAccess AmazonBedrockFullAccess AWSCodeBuildAdminAccess AWSCodeBuildDeveloperAccess BedrockAgentCoreFullAccess Tạo user và gán quyền Vào IAM → Users → chọn Create user. Thêm các quyền đã liệt kê ở trên. Hoàn tất tạo user và lưu Access Key nếu cần dùng SDK. Tải AWS CLI Tải AWS CLI: AWS CLI Link\nSau đó cài đặt theo hướng dẫn.\nCấu hình UV management 1. Vì sao dùng UV? UV nhanh, nhẹ, quản lý môi trường tốt hơn pip.\n2. Cài đặt UV trên Windows Chạy lệnh:\npowershell -ExecutionPolicy ByPass -c \u0026#34;irm https://astral.sh/uv/install.ps1 | iex\u0026#34; Thêm UV vào PATH:\n$env:Path = \u0026#34;C:\\Users\\leamo\\.local\\bin;$env:Path\u0026#34; Khởi động lại máy để nhận PATH mới.\n3. Khởi tạo môi trường UV Trong thư mục dự án:\nuv init Sau đó chọn environment trong VS Code.\nKết nối máy với AWS CLI Vào lại IAM để tạo Access Key.\nTạo Access Key và cấu hình AWS CLI Trong user: Security credentials → Create access key Chọn loại Command Line Interface (CLI) Cấu hình AWS CLI Chạy lệnh:\naws configure Nhập lần lượt:\nAWS Access Key ID\nAWS Secret Access Key\nDefault region name (demo: ap-southeast-1)\nDefault output format\njson Khởi chạy AWS CLI AgentCore Chạy:\nuv run which agentcore sau khi chạy sẽ tải các thư viện cần thiết cho AWS Agentcore về máy\nTạo Groq API bạn vào trang Groq và tạo api như hình.Đây là các tool bên ngoài bổ trợ cho Rag của liên kết thông qua AWS Agentcore "},{"uri":"https://khanh-0.github.io/aws/vi/2-proposal/","title":"Đề xuất","tags":[],"description":"","content":"APT Magic Nền tảng AI serverless cho tạo ảnh cá nhân hoá và tương tác xã hội 1. Tóm tắt điều hành APT Magic là một ứng dụng web serverless được trang bị AI, cho phép người dùng tạo, cá nhân hoá và chia sẻ nội dung nghệ thuật (ví dụ ảnh do AI tạo). Nền tảng tích hợp với các mô hình nền tảng qua Amazon Bedrock và cung cấp trải nghiệm web mượt mà bằng Next.js (SSR) được host trên AWS Amplify.\nPhiên bản MVP tập trung vào tạo ảnh thời gian thực và chia sẻ, trong khi Thiết kế tương lai dự kiến mở rộng với Bedrock AgentCore / SageMaker Inference, SQS/SNS, Secrets Manager \u0026amp; CloudTrail và các pipeline AWS MLOps để điều phối mô hình và tự động hoá nâng cao.\nAPT Magic được phát triển theo kiến trúc AWS-native hiện đại, tối ưu chi phí và bảo mật cho nhóm người dùng nhỏ đến trung bình, với kế hoạch mở rộng lên điều phối AI cấp doanh nghiệp.\n2. Vấn đề cần giải quyết Vấn đề là gì? Hầu hết nền tảng tạo ảnh AI hiện nay tốn kém, dựa vào API của bên thứ ba thiếu minh bạch và hạn chế khả năng cá nhân hoá. Nhà phát triển và creator thường gặp độ trễ cao, thiếu quản lý mô hình minh bạch và ít kiểm soát về bảo mật dữ liệu người dùng.\nGiải pháp APT Magic tận dụng kiến trúc serverless trên AWS để mang lại:\nTạo ảnh AI thời gian thực thông qua các mô hình Amazon Bedrock (Stability AI). Xác thực người dùng và quản lý nội dung an toàn với Amazon Cognito và DynamoDB. Xử lý API có thể mở rộng bằng AWS Lambda và API Gateway. Phân phối toàn cầu với độ trễ thấp qua CloudFront CDN và bảo vệ bằng WAF. Các nâng cấp tương lai sẽ bổ sung SQS/SNS để để điều phối, Bedrock AgentCore / SageMaker Inference cho pipelines mô hình, và CI/CD hiệu quả chi phí thông qua CloudFormation, biến APT Magic thành nền tảng MLOps tự động hoàn toàn.\n3. Kiến trúc giải pháp Kiến trúc MVP MVP là một kiến trúc hoàn toàn serverless, chú trọng khả năng mở rộng, dễ bảo trì và tối ưu chi phí.\nDịch vụ AWS cốt lõi:\nRoute53 + CloudFront + WAF — Truy cập an toàn toàn cầu và caching. Amplify (Next.js SSR) — Host frontend và lớp server-side rendering. API Gateway + Lambda Functions — Quản lý logic backend (xử lý ảnh, subscription, API bài đăng). Amazon Cognito — Xác thực người dùng và quản lý quyền truy cập. Amazon S3 + DynamoDB — Lưu trữ ảnh và dữ liệu. Amazon Bedrock — Tích hợp mô hình nền tảng (Stability AI) cho tạo ảnh. CloudWatch — Ghi log và giám sát. Bảo mật\nWAF + IAM policies để lọc lưu lượng và kiểm soát truy cập theo vai trò. Thiết kế tương lai (Kiến trúc mở rộng) Trong giai đoạn tiếp theo, APT Magic sẽ phát triển thành một nền tảng điều phối AI, bổ sung các lớp tự động hoá, khả năng chịu lỗi và quản lý vòng đời mô hình.\nDịch vụ mới sẽ thêm vào:\nAmazon SQS — Hàng đợi tin nhắn tin cậy giữa các task Lambda bất đồng bộ.\nAmazon SNS — Thông báo sự kiện theo thời gian thực đến người dùng hoặc admin.\nAmazon ElastiCache (Redis) — Rate limiting và cache cho các yêu cầu inference thường xuyên.\nAmazon Bedrock AgentCore — Host các mô hình tùy chỉnh đã fine-tune và quản lý endpoint mô hình.\nCI/CD\nCloudFormation cho triển khai hạ tầng tự động hoá. 4. Triển khai kỹ thuật Các giai đoạn triển khai Giai đoạn 1 – Triển khai MVP (Đã hoàn thành / Hiện tại)\nTriển khai Amplify (Next.js SSR) + API Gateway + Lambda. Tích hợp Bedrock Stability AI API. Thiết lập CI/CD qua GitLab CI/CD. Kích hoạt xác thực người dùng (Cognito) và lưu trữ (S3 + DynamoDB). Ghi log và giám sát qua CloudWatch. Giai đoạn 2 – Mở rộng Thiết kế Tương lai\nThêm SQS/SNS. Bổ sung ElastiCache cho throttling và caching. Tích hợp Bedrock Agent để nâng cao pipeline AI. Kết nối GitLab Runner với CodeBuild cho CI/CD thống nhất. 5. Timeline \u0026amp; Mốc quan trọng Giai đoạn Mô tả Thời gian ước tính Mốc triển khai Tháng 1: Thiết lập \u0026amp; API cốt lõi Triển khai hạ tầng (IaC), Cognito, API Gateway, DynamoDB, và các Lambda cơ bản. 4 Tuần Backend cốt lõi hoạt động, Auth/Quản lý người dùng hoàn thành. Tháng 2: Tích hợp AI Tích hợp LLM trên Amazon Bedrock (Stability AI), Replicate API, hoàn thiện các chức năng xử lý ảnh. 4 Tuần Demo xử lý ảnh AI end-to-end thành công. Tháng 3: Front-end \u0026amp; CI/CD Phát triển UI/UX (Amplify/Next.js), hoàn thiện pipeline CI/CD, cấu hình Giám sát/Bảo mật (CloudWatch/WAF). 4 Tuần Nền tảng sẵn sàng cho thử nghiệm người dùng. Tháng 4: Tối ưu \u0026amp; Go-Live Thực hiện test hiệu năng (Stress Test), tối ưu chi phí, và triển khai Production. 4 Tuần Go-Live (Khởi chạy chính thức). 6. Ước tính chi phí (Dự toán AWS) Tổng chi phí Hàng tháng: $9.80 Trả trước: $0.00 12 Tháng: $117.60 Tổng quan dịch vụ Dịch vụ Vùng Chi phí/tháng Trả trước Chi phí 12 tháng Ghi chú Amazon Route 53 Asia Pacific (Singapore) $0.50 $0.00 $6.00 1 Hosted Zone, 1 domain, 1 linked VPC Amazon CloudFront Asia Pacific (Singapore) $0.00 $0.00 $0.00 Không cấu hình đặc biệt AWS WAF Asia Pacific (Singapore) $6.00 $0.00 $72.00 1 Web ACL; 1 rule per ACL AWS Amplify Asia Pacific (Singapore) $0.00 $0.00 $0.00 Build instance: Standard (8GB/4vCPU); request duration 500ms AWS CloudFormation Asia Pacific (Singapore) $0.00 $0.00 $0.00 Không mở rộng; không thao tác Amazon API Gateway Asia Pacific (Singapore) $0.13 $0.00 $1.59 10k requests/month; WebSocket message 1KB; request size 30KB AWS Lambda Asia Pacific (Singapore) $1.67 $0.00 $20.04 1 million invokes; x86; 512MB ephemeral storage Amazon CloudWatch Asia Pacific (Singapore) $0.85 $0.00 $10.22 1 metric; 0.5GB logs in; 0.5GB logs to S3 S3 Standard Asia Pacific (Singapore) $0.23 $0.00 $2.76 10GB storage; 20k PUT; 40k GET DynamoDB On-Demand Asia Pacific (Singapore) $0.42 $0.00 $5.04 1GB storage; 1KB item; on-demand mode Tổng (Ước tính) — $9.80 $0.00 $117.60 Dựa trên AWS Pricing Calculator Metadata Tiền tệ: USD Locale: en_US Ngày tạo: 12/9/2025 Share URL: AWS Calculator Link Miễn trừ trách nhiệm: Bảng ước tính chi phí chỉ mang tính tham khảo; chi phí thực tế có thể thay đổi theo mức sử dụng. Giá mô hình AI Mô hình Độ phân giải / Token Chất lượng Giá/Yêu cầu (USD) Ghi chú Titan Image Generator v2 \u0026lt; 512×512 Standard 0.008 Giá cố định cho 1 ảnh Titan Image Generator v2 \u0026lt; 512×512 Premium 0.01 Giá cố định cho 1 ảnh Titan Image Generator v2 \u0026gt; 1024×1024 Standard 0.01 Giá cố định cho 1 ảnh Titan Image Generator v2 \u0026gt; 1024×1024 Premium 0.012 Giá cố định cho 1 ảnh Stable Diffusion 3.5 Large Any N/A 0.08 Giá cố định cho 1 ảnh Claude (text + image) 40 input tokens + 1 image N/A 0.00195 Giá cho 1 request bao gồm text và 1 ảnh 1024×1024 Tuỳ chọn bổ sung Chế độ Augmentation Giá (USD) text→img no augment 0.08 text→img with augment 0.08195 img→img no augment 0.012 img→img with augment 0.094 7. Đánh giá rủi ro Rủi ro Tác động Xác suất Biện pháp giảm thiểu Độ trễ inference mô hình AI Trung bình Cao Dùng ElastiCache + SQS/SNS để xử lý bất đồng bộ Tăng chi phí do gọi mô hình Cao Trung bình Kiểm soát sử dụng Bedrock, autoscaling SageMaker Lỗi cấu hình CI/CD Trung bình Thấp Chính sách rollback CloudFormation Lỗ hổng bảo mật Cao Trung bình WAF, GuardDuty, PrivateLink, IAM least privilege Phụ thuộc API bên thứ ba Trung bình Trung bình Dự phòng: lưu kết quả inference vào S3 8. Kết quả kỳ vọng Kết quả kỹ thuật: Hoàn thiện workflow tạo ảnh AI serverless với CI/CD bảo mật. Kiến trúc mô-đun cho phép tích hợp MLOps nhanh chóng. Cải thiện độ trễ và độ tin cậy bằng caching và workflow bất đồng bộ. Giá trị dài hạn: Nền tảng cho mở rộng AI as a Service (AIaaS). Khung MLOps sẵn sàng mở rộng với tự động huấn luyện lại. Hạ tầng đám mây có thể tái sử dụng cho sản phẩm AI trong tương lai. "},{"uri":"https://khanh-0.github.io/aws/vi/5-workshop/5.4-agent-core-run/5.4.2-call-agentcore/","title":"Gọi AgentCore","tags":[],"description":"","content":"Demo đơn giản với AgentCore 1. Gửi câu hỏi đầu tiên Dùng lệnh:\nagentcore invoke \u0026#34;{\u0026#39;prompt\u0026#39;: \u0026#39;Tell me about roaming activations\u0026#39;}\u0026#34; Agent sẽ trả lời dựa trên dữ liệu bạn đã triển khai (database + logic trong code).\n2. Kiểm tra khả năng ghi nhớ giữa các lần gọi (session) Sau khi hỏi lần đầu, bạn tiếp tục hỏi một câu có liên quan \u0026mdash; ví dụ\nagentcore invoke \u0026#34;{\u0026#39;prompt\u0026#39;: \u0026#39;Activate it for Vietnam\u0026#39;}\u0026#34; agentcore invoke \u0026#34;{\u0026#39;prompt\u0026#39;: \u0026#39;which country was i referring to\u0026#39;}\u0026#34; Nếu Agent phản hồi đúng ý và nhớ thông tin trước đó → chứng tỏ Memory hoạt động và AgentCore đang lưu ngữ cảnh giữa các lần gọi.\nAgentCore hoạt động đúng như mong đợi trong demo này.\n"},{"uri":"https://khanh-0.github.io/aws/vi/5-workshop/5.3-architecture/5.3.2-groq-api/","title":"Gọi Groq API","tags":[],"description":"","content":"Mục tiêu Sử dụng thư viện Groq (ở đây là ChatGroq / init_chat_model với model_provider=\u0026quot;groq\u0026quot;) để gọi model OpenAI (Groq-hosted).\nCấu hình trong Code Trong code demo:\nLấy API Key từ Environment GROQ_API_KEY = os.getenv(\u0026#34;GROQ_API_KEY\u0026#34;) Biến GROQ_API_KEY lấy API key từ environment variable.\nKhởi tạo Model llm = init_chat_model( model=\u0026#34;openai/gpt-oss-20b\u0026#34;, model_provider=\u0026#34;groq\u0026#34;, api_key=GROQ_API_KEY ) Tích hợp vào Agent Agent gọi LLM thông qua create_agent(...) với tham số model=llm:\nagent = create_agent( model=llm, tools=tools, checkpointer=checkpointer, store=store, middleware=[MemoryMiddleware()], system_prompt=system_prompt, ) Luồng xử lý Agent → Groq API → Model Inference → Response "},{"uri":"https://khanh-0.github.io/aws/vi/3-blogstranslated/3.2-blog2/","title":"Unlocking Next-Generation AI Performance with Dynamic Resource Allocation on Amazon EKS &amp; EC2 P6e-GB200","tags":[],"description":"","content":"Mở khóa hiệu năng AI thế hệ mới với Dynamic Resource Allocation trên Amazon EKS và Amazon EC2 P6e-GB200 Bài viết của Vara Bonthu, Nick Baker, và Chris Splinter - 02 tháng 9, 2025\nSự tiến hóa nhanh chóng của AI \u0026ldquo;agentic\u0026rdquo; và các mô hình ngôn ngữ lớn (LLM), đặc biệt là các mô hình suy luận, đã tạo ra nhu cầu chưa từng có về tài nguyên tính toán. Các mô hình AI tiên tiến ngày nay trải dài từ hàng trăm tỷ đến nghìn tỷ tham số và đòi hỏi sức mạnh tính toán khổng lồ, bộ nhớ lớn và liên kết tốc độ cao để hoạt động hiệu quả.\nCác tổ chức phát triển ứng dụng cho xử lý ngôn ngữ tự nhiên, mô phỏng khoa học, tạo nội dung 3D và suy luận đa phương thức cần hạ tầng có thể mở rộng từ các mô hình tỷ tham số ngày nay đến biên giới nghìn tỷ tham số trong tương lai mà vẫn giữ hiệu suất.\nTrong bài viết này, chúng ta sẽ khám phá cách Amazon Elastic Compute Cloud (Amazon EC2) P6e-GB200 UltraServers mới thay đổi khối lượng công việc AI phân tán qua tích hợp liền mạch với Kubernetes.\nAWS giới thiệu các UltraServers EC2 P6e-GB200 để đáp ứng nhu cầu ngày càng tăng về huấn luyện và suy luận mô hình AI quy mô lớn. Chúng đại diện cho một bước đột phá kiến trúc đáng kể cho khối lượng công việc AI phân tán. Hơn nữa, việc ra mắt EC2 P6e-GB200 UltraServer bao gồm hỗ trợ Amazon EKS (Elastic Kubernetes Service), cung cấp môi trường nguyên gốc Kubernetes để triển khai và mở rộng từ các mô hình hàng trăm tỷ đến nghìn tỷ tham số khi bối cảnh AI tiếp tục phát triển.\nSức mạnh phía sau P6e-GB200: kiến trúc NVIDIA GB200 Grace Blackwell Ở trung tâm của các UltraServer EC2 P6e-GB200 là NVIDIA GB200 Grace Blackwell Superchip, tích hợp hai GPU NVIDIA Blackwell và một CPU NVIDIA Grace. Ngoài ra, nó cung cấp kết nối NVLink-Chip-to-Chip (C2C) giữa các thành phần này, đem lại 900 GB/s băng thông hai chiều, nhanh hơn đáng kể so với các giao diện PCIe truyền thống.\nKhi được triển khai ở quy mô rack, các UltraServer EC2 P6e-GB200 tham gia vào kiến trúc NVL72 của NVIDIA, tạo ra các miền bộ nhớ đồng nhất (memory-coherent domains) đến 72 GPU.\nCông nghệ NVLink thế hệ năm hỗ trợ giao tiếp GPU-to-GPU giữa các máy chủ riêng biệt trong cùng miền lên tới 1.8 TB/s mỗi GPU. Yếu tố then chốt cho hiệu suất này là mạng Elastic Fabric Adapter (EFAv4), cung cấp tổng băng thông mạng lên đến 28.8 Tbps cho mỗi UltraServer.\nEFA kết hợp với NVIDIA GPUDirect RDMA cho phép giao tiếp GPU-to-GPU giữa các máy chủ với độ trễ thấp, vượt qua hệ điều hành. Điều này đảm bảo rằng fabric GPU phân tán hoạt động với hiệu suất gần như bộ nhớ cục bộ giữa các node.\nĐây là bước tiến đáng kể so với các UltraServer EC2 P6-B200 trước đây, vốn chỉ cung cấp tối đa 8 GPU B200 Blackwell trên nền tảng x86 dùng PCIe. P6e-GB200 nâng cấp kiến trúc bằng cách cung cấp bộ nhớ thực sự thống nhất qua các rack \u0026mdash; một yêu cầu quan trọng để huấn luyện và vận hành mô hình nghìn tỷ tham số một cách hiệu quả.\nHình 1: Amazon EC2 P6e-GB200 UltraServers\nHiểu kiến trúc UltraServer EC2 P6e-GB200 Một UltraServer EC2 P6e-GB200 không phải là một instance EC2 đơn lẻ. Thay vào đó, nó gồm nhiều instance EC2 được kết nối với nhau để hoạt động như một thực thể hợp nhất:\nu-p6e-gb200x36: Gồm 36 GPU phân phối trên 9 instance EC2 u-p6e-gb200x72: Gồm 72 GPU phân phối trên 18 instance EC2 Mỗi instance P6e-GB200 cung cấp 4 GPU NVIDIA Blackwell. Do đó:\nMột UltraServer u-p6e-gb200x36 là 9 instance (9 × 4 = 36 GPU) Một UltraServer u-p6e-gb200x72 là 18 instance (18 × 4 = 72 GPU) Trong Amazon EKS, mỗi instance EC2 xuất hiện dưới dạng một node Kubernetes riêng biệt, nhưng EKS hiểu vị trí topology và xử lý chúng như một phần của cùng UltraServer thông qua định tuyến aware topology.\nTích hợp P6e-GB200 UltraServers với Amazon EKS Nhóm Amazon EKS đã hợp tác chặt chẽ với NVIDIA từ đầu để thiết lập yêu cầu tích hợp P6e-GB200 với các node làm việc và control plane Kubernetes. Dựa trên các yêu cầu đó, chúng tôi phát triển AMI (Amazon Machine Images) dành cho ARM64 Amazon Linux 2023 với flavor NVIDIA.\nChúng tôi cũng đóng gói sẵn các binary cho Internal Node Memory Exchange/Management Service (IMEX) và cài sẵn phiên bản driver NVIDIA cần thiết.\nHơn nữa, Amazon EKS đã nhanh chóng hỗ trợ Dynamic Resource Allocation (DRA) cho người dùng bắt đầu từ phiên bản Kubernetes 1.33 trên EKS (tính năng này hiện vẫn là beta trong Kubernetes gốc).\nCác instance đã được kiểm tra với NVLink qua IMEX cũng như qua EFA, để đạt được luồng dữ liệu tối ưu trong và giữa các UltraServer. Trong thử nghiệm nội bộ, chúng tôi sử dụng thư viện NVIDIA Collective Communications Library (NCCL) của NVIDIA, giúp trừu tượng hóa quyết định cấp giao vận từ lớp ứng dụng.\nThách thức: chạy khối lượng công việc AI phân tán trên Kubernetes Việc triển khai các workload GPU bó chặt (tightly coupled) qua nhiều node truyền thống gặp nhiều thách thức trong Kubernetes. Cách cấp tài nguyên truyền thống của Kubernetes giả định phần cứng gắn liền với từng node, làm khó quản lý tài nguyên GPU và kết nối bộ nhớ đồng nhất (memory-coherent interconnects) giữa các node.\nĐiều này phổ biến với các workload huấn luyện quy mô lớn như LLM hoặc mô hình thị giác máy tính cần nhiều GPU hoạt động song song.\nHãy xem cách tiếp cận truyền thống khi yêu cầu GPU trong một pod:\nresources: limits: nvidia.com/gpu: 2 Cách tiếp cận tĩnh này hoạt động tốt cho GPU cục bộ nhưng không thể biểu diễn topology kết nối phức tạp hoặc kênh giao tiếp GPU-to-GPU cần thiết cho các framework huấn luyện phân tán.\nGiải pháp: Kubernetes DRA và IMEX Để giải quyết những thách thức này, Kubernetes giới thiệu DRA (Dynamic Resource Allocation), một framework mở rộng Kubernetes vượt ra ngoài CPU và bộ nhớ truyền thống để xử lý các topologies phần cứng phức tạp.\nAmazon EKS đã kích hoạt DRA trong Kubernetes phiên bản 1.33, cung cấp khả năng quản lý topology GPU tinh vi mà trước đây không thể thực hiện được bằng cấp tài nguyên GPU truyền thống.\nCách DRA giải quyết vấn đề cấp GPU truyền thống Khác với mô hình tài nguyên tĩnh (ví dụ nvidia.com/gpu: 2) \u0026ndash; trong đó bạn yêu cầu một số GPU cố định mà không quan tâm topology \u0026ndash; DRA cho phép ứng dụng mô tả yêu cầu tài nguyên theo cách khai báo qua ComputeDomain và ResourceClaims.\nĐây là sự chuyển đổi căn bản, giúp Kubernetes đưa ra quyết định cấp tài nguyên thông minh dựa vào topology thực tế, xem xét kết nối NVLink, băng thông bộ nhớ, và khoảng cách vật lý một cách tự động.\nQuan trọng nhất, DRA ẩn đi các cấu hình thủ công phức tạp như cài đặt dịch vụ IMEX, quản lý partition NVLink, và khởi tạo phần cứng cấp thấp \u0026mdash; những việc này nếu không sẽ đòi hỏi chuyên môn sâu về cụm GPU.\nNVIDIA DRA Driver là phần kết nối quan trọng giữa API DRA của Kubernetes và phần cứng bên dưới. Nó bao gồm hai plugin kubelet chuyên dụng:\ngpu-kubelet-plugin: cho các tính năng cấp GPU nâng cao compute-domain-kubelet-plugin: điều phối primitives IMEX một cách tự động Khi bạn tạo một ComputeDomain yêu cầu 36 GPU qua 9 instance EC2 (mỗi instance có 4 GPU Blackwell), hoặc 72 GPU qua 18 instance cho một UltraServer đầy đủ, hệ thống sẽ tự động:\nTriển khai daemon IMEX Thiết lập giao tiếp gRPC giữa các node Tạo miền bộ nhớ đồng nhất (memory-coherent domain) với ánh xạ cross-node Cung cấp các file thiết bị trong container Lên lịch aware topology \u0026amp; đồng nhất bộ nhớ (memory coherence) Khi một node tham gia vào một cluster EKS, control plane sẽ tiếp nhận thông tin topology liên quan đến instance qua API topology EC2 và gán nhãn (labels) cho node Kubernetes khi tham gia:\nMỗi node P6e-GB200 được tự động gán nhãn loại capacity block (eks.amazonaws.com/capacityType=CAPACITY_BLOCK và eks.amazonaws.com/nodegroup=...) và các nhãn topology mạng chi tiết (topology.k8s.aws/network-node-layer-1 đến network-node-layer-4) Những nhãn này chỉ ra vị trí vật lý trong fabric mạng UltraServer Khi GPU Feature Discovery (GFD) được bật trong NVIDIA GPU Operator, nó áp các nhãn clique (nvidia.com/gpu.clique) cho mỗi node để xác định GPU nào thuộc cùng một miền NVLink.\nNhững chiều topology này cho phép bạn thiết kế scheduling aware topology cho workload phân tán trên hoặc xuyên các nhóm node UltraServer.\nIMEX là khả năng then chốt của các hệ thống hỗ trợ NVLink như GB200 cho phép GPU giữa các node khác nhau truy cập trực tiếp bộ nhớ của nhau qua NVLink. Khi một kênh IMEX (IMEX channel) được cấp qua Kubernetes và DRA thông qua một ComputeDomain, nó xuất hiện trong container như một file thiết bị (ví dụ /dev/nvidia-caps-imex-channels/channel0).\nĐiều này cho phép ứng dụng CUDA hoạt động như thể tất cả GPU nằm trên cùng một board.\nKhả năng này đặc biệt quan trọng cho các framework huấn luyện phân tán như MPI và NCCL. Chúng giờ đây có thể đạt hiệu suất gần như mức \u0026ldquo;bare-metal\u0026rdquo; qua các ranh giới node mà không cần cấu hình tùy chỉnh hay thay đổi mã.\nCông nghệ NVLink 5.0 cung cấp nền tảng băng thông để vận hành các kênh này với 1.8 TB/s hai chiều mỗi GPU.\nĐiều này cho phép thực thi các miền tính toán (compute domains) đồng nhất bộ nhớ xuyên rack \u0026mdash; tạo nền tảng cho hệ thống AI đa node chạy thời gian thực. Trong kiến trúc NVL72, lên đến 72 GPU có thể kết nối trong một miền NVLink đồng nhất bộ nhớ.\nGPU được tổ chức thành các clique dựa trên kết nối vật lý qua NVSwitches, với mọi GPU trong cùng một node chắc chắn thuộc cùng một clique và chia sẻ cùng Cluster UUID.\nKhi GFD được bật, nó gán nhãn nvidia.com/gpu.clique cho mỗi node chứa ID miền NVL và ID clique (ví dụ cluster-abc.0), cho phép người dùng thiết kế scheduling aware topology sử dụng node affinity rules.\nKhi lên lịch công việc huấn luyện qua 9 instance của UltraServer u-p6e-gb200x36 hoặc 18 instance u-p6e-gb200x72, kube-scheduler với các affinity rule hợp lý đảm bảo rằng tất cả node thuộc cùng một miền NVLink để đạt băng thông tối đa.\nMặc dù NVLink cung cấp băng thông siêu cao trong cùng miền vật lý, mạng EFA đảm bảo giao tiếp giữa các UltraServers khác nhau có độ trễ thấp và throughput cao. Khả năng RDMA của EFA kết hợp với GPUDirect cho phép các GPU giao tiếp trực tiếp xuyên node mà CPU không can thiệp, tạo ra kiến trúc lai trong đó giao tiếp nội UltraServer dùng NVLink còn giữa các UltraServer dùng EFA.\nĐiều này làm cho P6e-GB200 phù hợp cho huấn luyện mô hình khổng lồ có thể mở rộng từ triển khai đơn rack đến cụm siêu máy tính đa rack trong khi vẫn giữ được đặc tính hiệu suất tối ưu ở mọi quy mô.\nQuy trình lên lịch workload với DRA Lưu đồ dưới đây minh họa cách Kubernetes DRA tích hợp với công nghệ NVIDIA GB200 IMEX để triển khai khối lượng công việc huấn luyện AI phân tán trên nhiều node.\nKhi một pod yêu cầu 8 GPU để huấn luyện phân tán với các quy tắc affinity được cấu hình chính xác, hệ thống sẽ điều phối việc triển khai thông qua một quy trình phối hợp:\nNgười dùng chỉ định các pod cụ thể nhắm mục tiêu theo affinity theo node (nvidia.com/gpu.clique) Kube-scheduler đặt các pod dựa trên các ràng buộc về affinity này Các thành phần DRA xử lý việc quản lý tài nguyên và phối hợp giữa các node Driver NVIDIA quản lý phân bổ GPU và điều phối IMEX Dịch vụ IMEX đảm bảo tính nhất quán của bộ nhớ giữa các node thông qua giao tiếp gRPC Kết quả là triển khai liền mạch trên hai node (mỗi node 4 GPU) trong cùng một miền NVLink, cho phép giao tiếp băng thông cao, độ trễ thấp, điều cần thiết cho khối lượng công việc huấn luyện AI quy mô lớn.\nCách sử dụng P6e-GB200 với Kubernetes DRA trên Amazon EKS Phần này hướng dẫn từng bước thiết lập cụm EKS với UltraServer EC2 P6e-GB200 để tận dụng các khả năng nói trên.\nYêu cầu tiên quyết Trước khi bắt đầu, hãy đảm bảo rằng bạn có các công cụ và quyền truy cập sau. Tham khảo EKS User Guide để biết hướng dẫn.\nĐã cài đặt AWS Command Line Interface (AWS CLI) eksctl (phiên bản hỗ trợ EKS 1.33) kubectl helm Quyền truy cập Capacity Blocks EC2 cho các instance P6e-GB200 Bước 1: Đặt trước capacity UltraServer P6e-GB200 UltraServers P6e-GB200 chỉ có sẵn thông qua Capacity Blocks dành cho machine learning (ML). Bạn phải đặt trước UltraServer (không phải các instance riêng lẻ) trước khi tạo cụm EKS.\nTrong giao diện console AWS:\nVào EC2 Console → Capacity Reservations → Capacity Blocks Chọn tab UltraServers (không phải Instances) Chọn một trong: u-p6e-gb200x36 (36 GPU qua 9 instance) u-p6e-gb200x72 (72 GPU qua 18 instance) Hoàn thành việc đặt trước cho khoảng thời gian mong muốn Bước 2: Tạo file cấu hình EKS cluster Tạo file tên cluster-config.yaml với nội dung:\n# cluster-config.yaml apiVersion: eksctl.io/v1alpha5 kind: ClusterConfig metadata: name: p6e-cluster region: us-east-1 version: \u0026#39;1.33\u0026#39; iam: withOIDC: true managedNodeGroups: - name: p6e-nodegroup amiFamily: AmazonLinux2023 instanceType: p6e-gb200.36xlarge desiredCapacity: 9 # All 9 instances from the UltraServer (36 GPUs total) minSize: 9 maxSize: 9 labels: nvidia.com/gpu.present: \u0026#34;true\u0026#34; taints: - key: nvidia.com/gpu value: \u0026#34;true\u0026#34; effect: NoSchedule availabilityZones: [\u0026#34;us-east-1-dfw-2a\u0026#34;] # Enable EFA (mandatory for P6e-GB200 UltraServers) efaEnabled: true capacityReservation: enabled: true capacityReservationTarget: capacityReservationId: \u0026#34;cr-1234567890abcdef\u0026#34; # Replace with your reservation ID Bước 3: Triển khai cụm EKS eksctl create cluster -f cluster-config.yaml Lệnh này sẽ tạo cụm EKS phiên bản 1.33 với 9 instance p6e-gb200.36xlarge từ UltraServer bạn đã đặt trước, với mạng EFA được bật để tối ưu giao tiếp GPU-to-GPU.\nBước 4: Triển khai NVIDIA GPU Operator GPU Operator của NVIDIA là thành phần thiết yếu cho instance GB200 vì nó quản lý toàn bộ vòng đời GPU \u0026mdash; bao gồm cấu hình runtime và các tính năng nâng cao như MIG (Multi-Instance GPU).\nVới topology NVLink phức tạp trải qua nhiều node, GPU Operator quản lý tài nguyên GPU động, cấu hình MIG, và xử lý các mối quan hệ liên kết interconnect mà plugin tĩnh không thể xử lý.\n# Add the NVIDIA GPU Operator Helm repository helm repo add nvidia https://nvidia.github.io/gpu-operator helm repo update # Deploy the NVIDIA GPU Operator with custom values cat \u0026lt;\u0026lt;EOF \u0026gt; gpu-operator-values.yaml # gpu-operator-values.yaml driver: enabled: false mig: strategy: mixed migManager: enabled: true env: - name: WITH_REBOOT value: \u0026#34;true\u0026#34; config: create: true name: custom-mig-parted-configs default: \u0026#34;all-disabled\u0026#34; data: config.yaml: |- version: v1 mig-configs: all-disabled: - devices: all mig-enabled: false # P4DE profiles (A100 80GB) p4de-half-balanced: - devices: [0, 1, 2, 3] mig-enabled: true mig-devices: \u0026#34;1g.10gb\u0026#34;: 2 \u0026#34;2g.20gb\u0026#34;: 1 \u0026#34;3g.40gb\u0026#34;: 1 - devices: [4, 5, 6, 7] mig-enabled: false devicePlugin: enabled: true config: name: \u0026#34;\u0026#34; create: false default: \u0026#34;\u0026#34; toolkit: enabled: false nfd: enabled: true gfd: enabled: true dcgmExporter: enabled: true serviceMonitor: enabled: true interval: 15s honorLabels: false additionalLabels: release: kube-prometheus-stack daemonsets: tolerations: - key: \u0026#34;nvidia.com/gpu\u0026#34; operator: \u0026#34;Exists\u0026#34; effect: \u0026#34;NoSchedule\u0026#34; nodeSelector: accelerator: nvidia priorityClassName: system-node-critical EOF # Install GPU Operator using values file helm install gpu-operator nvidia/gpu-operator \\ --namespace gpu-operator \\ --create-namespace \\ --version v25.3.1 \\ --values gpu-operator-values.yaml Bước 5: Cài đặt NVIDIA DRA Driver Driver DRA của NVIDIA là thành phần thiết yếu cho UltraServer P6e-GB200 vì nó cung cấp các khả năng vượt ra ngoài plugin GPU truyền thống.\nMặc dù plugin NVIDIA Device Plugin chuẩn chỉ expose các GPU riêng lẻ như tài nguyên đếm được (nvidia.com/gpu: 2), DRA Driver mở rộng hai khả năng quan trọng:\nQuản lý ComputeDomain: DRA Driver quản lý các ComputeDomain \u0026mdash; là abstraction cho các triển khai Multi-Node NVLink (MNNVL) Cấp GPU nâng cao: Ngoài việc đếm GPU, DRA Driver cho phép cấp cấu hình GPU động, các thiết bị MIG, và scheduling aware topology DRA Driver bao gồm hai plugin kubelet:\ngpu-kubelet-plugin: cho các chức năng cấp GPU nâng cao compute-domain-kubelet-plugin: điều phối ComputeDomain Tạo file values.yaml để triển khai NVIDIA DRA Driver:\n# values.yaml --- nvidiaDriverRoot: / gpuResourcesEnabledOverride: true # Required to deploy GPU and MIG deviceclasses resources: gpus: enabled: true # set to false to disable experimental gpu support computeDomains: enabled: true controller: nodeSelector: null affinity: null tolerations: [] kubeletPlugin: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: \u0026#34;nvidia.com/gpu.present\u0026#34; operator: In values: - \u0026#34;true\u0026#34; tolerations: - key: \u0026#34;nvidia.com/gpu\u0026#34; operator: Exists effect: NoSchedule Sau đó cài đặt trình điều khiển NVIDIA DRA:\nhelm repo add nvidia https://helm.ngc.nvidia.com/nvidia helm repo update helm install nvidia-dra-driver-gpu nvidia/nvidia-dra-driver-gpu \\ --version=\u0026#34;25.3.0-rc.4\u0026#34; \\ --namespace nvidia-dra-driver-gpu \\ --create-namespace \\ -f values.yaml Sau khi cài, DRA Driver sẽ tạo ra các tài nguyên DeviceClass giúp Kubernetes hiểu và cấp ComputeDomain. Điều này giúp việc quản lý topology nâng cao cho workload AI phân tán trên UltraServer EC2 P6e-GB200 trở nên khả thi.\nBước 6: Xác minh tài nguyên DRA Kiểm tra xem các tài nguyên DRA đã khả dụng chưa:\nkubectl api-resources | grep resource.k8s.io/v1beta1 # Output: # deviceclasses resource.k8s.io/v1beta1 false DeviceClass # resourceclaims resource.k8s.io/v1beta1 true ResourceClaim # resourceclaimtemplates resource.k8s.io/v1beta1 true ResourceClaimTemplate # resourceslices resource.k8s.io/v1beta1 false ResourceSlice kubectl get deviceclasses # Output: # NAME CAPACITY ALLOCATABLE ALLOCATED # compute-domain-daemon.nvidia.com 36 36 0 # gpu.nvidia.com 0 0 0 # mig.nvidia.com 0 0 0 Xác thực cấp kênh IMEX Khi GPU Operator và DRA driver đã cấu hình, bạn có thể tạo các kênh IMEX để cho phép truy cập bộ nhớ trực tiếp giữa GPU xuyên các node. Ví dụ sau minh họa cách một tài nguyên ComputeDomain tự cấp phát hạ tầng IMEX cần thiết:\nTạo file imex-channel-injection.yaml:\n# filename: imex-channel-injection.yaml --- apiVersion: resource.nvidia.com/v1beta1 kind: ComputeDomain metadata: name: imex-channel-injection spec: numNodes: 1 channel: resourceClaimTemplate: name: imex-channel-0 --- apiVersion: v1 kind: Pod metadata: name: imex-channel-injection spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: nvidia.com/gpu.clique operator: Exists containers: - name: ctr image: ubuntu:22.04 command: [\u0026#34;bash\u0026#34;, \u0026#34;-c\u0026#34;] args: [\u0026#34;ls -la /dev/nvidia-caps-imex-channels; trap \u0026#39;exit 0\u0026#39; TERM; sleep 9999 \u0026amp; wait\u0026#34;] resources: claims: - name: imex-channel-0 resourceClaims: - name: imex-channel-0 resourceClaimTemplateName: imex-channel-0 YAML này tạo một tài nguyên ComputeDomain và tham chiếu nó từ một pod. Controller ComputeDomain tự động tạo ResourceClaimTemplate, pod sử dụng để truy cập kênh IMEX. Ở phía sau, việc này kích hoạt việc triển khai daemon IMEX trên node được chọn, và tạo miền IMEX một cách động thay vì thiết lập tĩnh trước.\nÁp dụng và xác thực:\nBạn sẽ thấy pod như imex-channel-injection-... trong trạng thái Running.\nkubectl apply -f imex-channel-injection.yaml # Confirm the pod that runs to configure the compute domain kubectl get pods -n nvidia-dra-driver-gpu -l resource.nvidia.com/computeDomain # Output: # NAME READY STATUS RESTARTS AGE # imex-channel-injection-zrrlw-b6dqx 1/1 Running 5 (2m34s ago) 4m5s # Confirm the IMEX channel is created kubectl logs imex-channel-injection # Output: # total 0 # drwxr-xr-x. 2 root root 60 Apr 22 00:15 . # drwxr-xr-x. 6 root root 380 Apr 22 00:15 .. # crw-rw-rw-. 1 root root 241, 0 Apr 22 00:15 channel0 # Show logs of the pod configuring IMEX for the compute domain kubectl logs -n nvidia-dra-driver-gpu -l resource.nvidia.com/computeDomain --tail=-1 # Output: # /etc/nvidia-imex/nodes_config.cfg: # 192.168.56.245 # IMEX Log initializing at: 4/22/2025 00:14:21.228 # [Apr 22 2025 00:14:21] [INFO] [tid 43] IMEX version 570.133.20 is running with the following configuration options # [Apr 22 2025 00:14:21] [INFO] [tid 43] Logging level = 4 # [Apr 22 2025 00:14:21] [INFO] [tid 43] Logging file name/path = /var/log/nvidia-imex.log # [Apr 22 2025 00:14:21] [INFO] [tid 43] Append to log file = 0 # [Apr 22 2025 00:14:21] [INFO] [tid 43] Max Log file size = 1024 (MBs) # [Apr 22 2025 00:14:21] [INFO] [tid 43] Use Syslog file = 0 # [Apr 22 2025 00:14:21] [INFO] [tid 43] IMEX Library communication bind interface = # [Apr 22 2025 00:14:21] [INFO] [tid 43] IMEX library communication bind port = 50000 # [Apr 22 2025 00:14:21] [INFO] [tid 43] Identified this node as ID 0, using bind IP of \u0026#39;196.181.26.911\u0026#39;, and network interface of enp4s0 # [Apr 22 2025 00:14:21] [INFO] [tid 43] nvidia-imex persistence file /var/run/nvidia-imex/persist.dat does not exist. Assuming no previous importers. # [Apr 22 2025 00:14:21] [INFO] [tid 43] NvGpu Library version matched with GPU Driver version # [Apr 22 2025 00:14:21] [INFO] [tid 70] Started processing of incoming messages. # [Apr 22 2025 00:14:21] [INFO] [tid 71] Started processing of incoming messages. # [Apr 22 2025 00:14:21] [INFO] [tid 72] Started processing of incoming messages. # [Apr 22 2025 00:14:21] [INFO] [tid 43] Creating gRPC channels to all peers (nPeers = 1). # [Apr 22 2025 00:14:21] [INFO] [tid 73] Started processing of incoming messages. # [Apr 22 2025 00:14:21] [INFO] [tid 43] IMEX_WAIT_FOR_QUORUM != FULL, continuing initialization without waiting for connections to all nodes. # [Apr 22 2025 00:14:21] [INFO] [tid 43] GPU event successfully subscribed # [Apr 22 2025 00:14:21] [INFO] [tid 74] Connection established to node 0 with ip address 192.168.56.245. Number of times connected: 1 Kết quả log sẽ cho biết thông tin khởi tạo IMEX, thiết lập gRPC giữa nodes, và xác nhận rằng miền bộ nhớ đồng nhất được kích hoạt. Điều này cho thấy GPU bộ nhớ từ các node khác nhau trong UltraServer giờ có thể truy cập trực tiếp qua NVLink. Kết quả cuối là hiệu năng chưa từng có cho workload AI phân tán.\nGiao tiếp IMEX đa node trong thực tế Để minh họa cách driver DRA điều phối giao tiếp GPU xuyên node, phần tiếp theo triển khai một benchmark MPI đa node sử dụng kênh IMEX cho truyền bộ nhớ GPU-to-GPU băng thông cao xuyên các node EC2 P6e-GB200 UltraServer.\nTriển khai Job MPI đa node Tạo file yaml nvbandwidth-test-job.yaml:\n# nvbandwidth-test-job.yaml --- apiVersion: resource.nvidia.com/v1beta1 kind: ComputeDomain metadata: name: nvbandwidth-test-compute-domain spec: numNodes: 2 # Request 2 nodes for cross-node testing channel: resourceClaimTemplate: name: nvbandwidth-test-compute-domain-channel --- apiVersion: kubeflow.org/v2beta1 kind: MPIJob metadata: name: nvbandwidth-test spec: slotsPerWorker: 4 # 4 GPUs per worker node launcherCreationPolicy: WaitForWorkersReady mpiReplicaSpecs: Worker: replicas: 2 # 2 worker nodes template: spec: containers: - image: ghcr.io/nvidia/k8s-samples:nvbandwidth-v0.7-8d103163 name: mpi-worker resources: limits: nvidia.com/gpu: 4 # Request 4 GPUs per worker claims: - name: compute-domain-channel # Link to IMEX channel resourceClaims: - name: compute-domain-channel resourceClaimTemplateName: nvbandwidth-test-compute-domain-channel Khi áp file này:\nkubectl apply -f nvbandwidth-test-job.yaml ComputeDomain creation and node selection: Trình điều khiển DRA ngay lập tức bắt đầu sắp xếp thiết lập nhiều node: a. Xác định 2 node có GPU GB200 có sẵn b. Xác minh các node thuộc cùng một domain NVLink c. Tạo tài nguyên ComputeDomain resource\nIMEX domain establishment: DRA tự động hóa: a. Triển khai nhóm daemon IMEX trên cả hai node đã chọn b. Định cấu hình các kênh cross-node gRPC c. Thiết lập shared memory mappings giữa các GPU\nKết quả của experiment chứng minh DRA biến cụm GPU đa node thành tài nguyên hợp nhất, cho phép huấn luyện LLM trải khắp các node UltraServer với truy cập bộ nhớ GPU native trong khi vẫn giữ hiệu suất tối ưu. Tất cả 72 GPU trong một UltraServer u-p6e-gb200x72 hiển thị như một vùng nhớ thống nhất cho ứng dụng, và Kubernetes đảm trách toàn bộ orchestration IMEX phức tạp để đội ngũ dữ liệu chỉ cần tập trung vào mô hình, không phải hạ tầng.\nKết luận Amazon EC2 P6e-GB200 UltraServers trên Amazon EKS đại diện cho bước tiến lớn cho người dùng muốn huấn luyện và triển khai mô hình AI nghìn tỷ tham số ở quy mô. Sự kết hợp giữa GPU Grace Blackwell của NVIDIA với NVLink, hỗ trợ từ Amazon EKS, DRA và công cụ của NVIDIA, đã giúp AWS đưa tính toán AI ở cấp exascale vào phạm vi tiếp cận thông qua các pattern quản lý container quen thuộc.\nViệc tích hợp các kênh IMEX và NVLink cho phép tạo cụm GPU đồng nhất bộ nhớ trải khắp các node và rack, phá vỡ giới hạn truyền thống của tính toán GPU cục bộ node. Cải tiến kiến trúc này mở ra các khả năng mới cho:\nHuấn luyện mô hình nền tảng hàng nghìn tỷ tham số Chạy AI đa phương thức với yêu cầu hiệu suất thời gian thực Triển khai pipeline suy luận phức tạp với độ trễ dưới một giây Để bắt đầu với DRA trên Amazon EKS, bạn có thể tham khảo tài liệu Amazon EKS AI/ML để có hướng dẫn toàn diện, và khám phá dự án AI on EKS, cung cấp các ví dụ DRA bạn có thể thử nghiệm và triển khai trong môi trường của mình.\nLƯU Ý BẢO MẬT: Các cấu hình trình bày trong bài viết này chỉ là ví dụ cơ bản nhằm minh họa chức năng cốt lõi. Trong môi trường sản xuất, bạn nên bổ sung các kiểm soát bảo mật. Hãy liên hệ với nhóm tài khoản AWS của bạn để biết thêm về cách sử dụng P6e-GB200 trên Amazon EKS.\nVề tác giả Vara Bonthu là Chuyên gia SA chuyên về mã nguồn mở dẫn đầu Data trên EKS và AI trên EKS tại AWS, thúc đẩy các sáng kiến mã nguồn mở và hỗ trợ khách hàng từ nhiều tổ chức. Ông chuyên sâu về công nghệ mã nguồn mở, phân tích dữ liệu, AI/ML và Kubernetes, với kinh nghiệm sâu rộng trong phát triển, DevOps và kiến trúc.\nChris Splinter là Quản lý Sản phẩm cao cấp nhóm Amazon EKS, tập trung vào hỗ trợ khách hàng chạy workload AI với Kubernetes.\nNick Baker là Kỹ sư phát triển phần mềm trong Nhóm Node Runtime trên Amazon EKS. Anh tập trung vào việc bổ sung hỗ trợ cho workload tăng tốc và cải thiện tính ổn định data-plane trên EKS.\n"},{"uri":"https://khanh-0.github.io/aws/vi/4-eventparticipated/4.3-event3/","title":"AI-Driven Development Session with Amazon Q Developer &amp; Kiro","tags":[],"description":"","content":"Mục tiêu Sự kiện Hiểu cách Generative AI đang thay đổi vòng đời phát triển phần mềm Học cách các công cụ AI như Amazon Q Developer và Kiro tăng tốc quy trình phát triển Khám phá cách AI tích hợp vào kiến trúc, lập trình, kiểm thử, triển khai và bảo trì Trải nghiệm demo trực tiếp về phát triển phần mềm có hỗ trợ AI trong bối cảnh kỹ thuật thực tế Nâng cao năng suất bằng việc tự động hóa các tác vụ nặng tính lặp lại, giúp developer tập trung vào sáng tạo và đổi mới Diễn giả Toan Huynh – Instructor, AWS GenAI Builder Club My Nguyen – Instructor, AWS GenAI Builder Club Điều phối chương trình Diem My – Program Coordinator Dai Truong – Event Coordinator Dinh Nguyen – Operations Coordinator Điểm nổi bật Toan Huynh là người truyền cảm hứng mạnh mẽ, luôn hướng dẫn bằng cả trái tim và kiến thức sâu rộng của mình.\nMy Huynh thì cực kỳ nhiệt tình, giải đáp mọi câu hỏi của khán giả một cách sâu sắc và đầy hiểu biết.\nChuyển đổi Phát triển Phần mềm bằng Generative AI Generative AI mở ra kỷ nguyên mới trong ngành phần mềm, thay đổi cách developer học, lập kế hoạch, tạo sản phẩm, triển khai và vận hành ứng dụng.\nBuổi chia sẻ nhấn mạnh rằng AI-driven development mang lại:\nTự động hóa các tác vụ lặp lại Tăng tốc prototyping và rút ngắn vòng đời phát triển Cải thiện chất lượng và bảo mật mã nguồn nhờ AI review Giúp developer tập trung vào công việc giá trị cao như thiết kế và tối ưu hệ thống AI trong Vòng đời Phát triển Phần mềm (AI-DLC) Buổi chia sẻ giới thiệu cách AI tích hợp xuyên suốt SDLC:\nLập kế hoạch kiến trúc Sinh code và refactor Tạo test cases và kiểm thử tự động Triển khai qua pipelines Bảo trì và giám sát hệ thống Thông qua Amazon Q Developer và Kiro, người tham dự hiểu rõ hơn cách AI tăng cường năng lực của developer.\nAgenda 2:00 PM – 2:15 PM | Đón tiếp \u0026amp; Giới thiệu 2:15 PM – 3:30 PM | Tổng quan AI-Driven Development Lifecycle \u0026amp; Demo Amazon Q Developer Giảng viên: Toan Huynh 3:30 PM – 3:45 PM | Nghỉ giải lao 3:45 PM – 4:30 PM | Demo Kiro Giảng viên: My Nguyen Những Điều Rút Ra Nhận Thức Chiến Lược về AI-Driven Development AI tăng tốc đáng kể quá trình phát triển phần mềm bằng cách tự động hóa công việc lặp lại Các nhóm phát triển có thể tập trung hơn vào thiết kế kiến trúc và giải quyết vấn đề AI giảm thời gian debug, refactor và viết tài liệu Tổ chức áp dụng AI vào development sẽ thấy rõ mức tăng năng suất Bài Học Thực Tiễn – Amazon Q Developer Sinh code chất lượng cao từ prompt ngôn ngữ tự nhiên Tự động sửa lỗi và tối ưu hàm Viết unit test và tài liệu bằng AI Cải thiện workflow DevOps nhờ tự động hóa CI/CD Bài Học Thực Tiễn – Kiro Sử dụng AI của Kiro cho thiết kế hệ thống và phát triển phần mềm Gợi ý thời gian thực về kiến trúc, cấu trúc mã và best practices Cải thiện readability, maintainability và consistency của code Ứng dụng vào Công Việc Áp dụng AI để tối ưu các tác vụ phát triển hằng ngày Dùng Amazon Q Developer để prototype nhanh và nâng cao chất lượng mã nguồn Tích hợp Kiro vào quy trình thiết kế và lập kế hoạch kiến trúc Khuyến khích đội nhóm thử nghiệm AI để tăng hiệu quả và giảm tải công việc lặp lại Bắt đầu khám phá AI-augmented SDLC để hiện đại hóa quy trình kỹ thuật Trải nghiệm Sự kiện Tham dự buổi AI-Driven Development này là một trải nghiệm mới mẻ và đầy cảm hứng. Buổi chia sẻ cho thấy cách Generative AI đang làm thay đổi hoàn toàn workflow của developer và mở ra một cấp độ năng suất mới.\nHọc Từ Chuyên Gia Nhận được nhiều insight giá trị từ Toan Huynh và My Nguyen về cách ứng dụng AI thực tế Hiểu cách AI không chỉ giúp lập trình mà còn hỗ trợ kiến trúc và quy trình DevOps Demo Thực Tế Quan sát Amazon Q Developer refactor code, tạo tài liệu và viết test ngay lập tức Trải nghiệm cách Kiro hỗ trợ lập kế hoạch hệ thống và đưa ra quyết định kỹ thuật Giao Lưu \u0026amp; Kết Nối Kết nối với các thành viên của AWS GenAI Builder Club Thảo luận về các use case và cơ hội ứng dụng AI trong công việc kỹ thuật Bài Học Quan Trọng AI-driven development giúp tăng tốc, tăng độ chính xác và năng suất Vai trò của developer đang chuyển dịch từ “người viết code” thành nhà thiết kế hệ thống và người giải quyết bài toán Đón nhận AI sớm sẽ mang lại lợi thế cạnh tranh trong đội ngũ kỹ thuật hiện đại Diễn giả - Toan Huynh\nDiễn giả - My Nguyen\nNhìn chung, buổi chia sẻ củng cố một thông điệp mạnh mẽ: AI sẽ không thay thế developer — nhưng developer biết dùng AI sẽ vượt xa những người không dùng.\n"},{"uri":"https://khanh-0.github.io/aws/vi/3-blogstranslated/","title":"Các bài blogs đã dịch","tags":[],"description":"","content":"Dynamic Kubernetes request right sizing with Kubecost Trong bài viết này, chúng ta sẽ tìm hiểu cách sử dụng Kubecost Amazon Elastic Kubernetes Service (Amazon EKS) add-on để giảm chi phí hạ tầng và tối ưu hóa hiệu suất Kubernetes. Tính năng Container Request Right Sizing giúp đánh giá cách các yêu cầu container được cấu hình, phát hiện sự kém hiệu quả và tối ưu chúng thủ công hoặc tự động.\nChúng ta cũng sẽ xem cách đánh giá các đề xuất right sizing và thực hiện các cập nhật một lần hoặc tự động theo lịch trình, giúp môi trường Amazon EKS duy trì trạng thái tối ưu liên tục.\nBlog 2 - Unlocking Next-Generation AI Performance with Dynamic Resource Allocation on Amazon EKS \u0026amp; EC2 P6e-GB200 Sự tiến hóa nhanh chóng của AI \u0026ldquo;agentic\u0026rdquo; và các mô hình ngôn ngữ lớn (LLM), đặc biệt là các mô hình suy luận, đã tạo ra nhu cầu chưa từng có về tài nguyên tính toán. Các mô hình AI tiên tiến ngày nay trải dài từ hàng trăm tỷ đến nghìn tỷ tham số và đòi hỏi sức mạnh tính toán khổng lồ, bộ nhớ lớn và liên kết tốc độ cao để hoạt động hiệu quả.\nCác tổ chức phát triển ứng dụng cho xử lý ngôn ngữ tự nhiên, mô phỏng khoa học, tạo nội dung 3D và suy luận đa phương thức cần hạ tầng có thể mở rộng từ các mô hình tỷ tham số ngày nay đến biên giới nghìn tỷ tham số trong tương lai mà vẫn giữ hiệu suất.\nBlog 3 - Cách Strangeworks sử dụng Amazon Braket để khám phá vấn đề xếp hàng hóa lên máy bay Máy tính lượng tử hứa hẹn đem lại bước ngoặt cho việc tính toán các bài toán ở nhiều ngành công nghiệp, mặc dù vẫn còn là câu hỏi mở là công nghệ này sẽ hữu ích ra sao trong thực tế. Trong bài blog này, nhóm từ Strangeworks, một đối tác AWS, đánh giá các triển khai khác nhau của thuật toán QAOA (Quantum Approximate Optimization Algorithm) đối với vấn đề xếp hàng hóa lên máy bay do Airbus đặt ra như một phần của Quantum Mobility Challenge năm trước.\n"},{"uri":"https://khanh-0.github.io/aws/vi/3-blogstranslated/3.3-blog3/","title":"Cách Strangeworks sử dụng Amazon Braket để khám phá vấn đề xếp hàng hóa lên máy bay","tags":[],"description":"","content":" Bài viết gốc được đăng trên AWS Quantum Technologies Blog\nMáy tính lượng tử hứa hẹn đem lại bước ngoặt cho việc tính toán các bài toán ở nhiều ngành công nghiệp, mặc dù vẫn còn là câu hỏi mở là công nghệ này sẽ hữu ích ra sao trong thực tế. Trong bài blog này, nhóm từ Strangeworks, một đối tác AWS, đánh giá các triển khai khác nhau của thuật toán QAOA (Quantum Approximate Optimization Algorithm) đối với vấn đề xếp hàng hóa lên máy bay do Airbus đặt ra như một phần của Quantum Mobility Challenge năm trước.\nTổng quan về vấn đề Vấn đề xếp hàng hóa máy bay mà Airbus đưa ra là dạng bài toán tối ưu kiểu bin packing (đóng hộp) xảy ra trong nhiều ngành - du lịch, sản xuất, logistics. Những bài toán kiểu này rất khó giải vì số lượng các khả năng tăng theo cấp số nhân khi biến đổi nhiều hơn, dẫn đến không gian bài toán rất lớn ngay cả với các trường hợp đơn giản.\nTại sao sử dụng máy tính lượng tử? Máy tính lượng tử có thể phù hợp để giải các bài toán tối ưu này, có tiềm năng tăng tốc so với giải pháp cổ điển (classical). Tuy nhiên, khi phần cứng lượng tử hiện tại vẫn chưa vượt trội so với các công nghệ cổ điển, các phương pháp heuristic kết hợp xử lý lượng tử và cổ điển (hybrid) đang được xem xét nhiều.\nHiện tại phần cứng lượng tử kiểu \u0026ldquo;gate-based\u0026rdquo; chưa vượt qua được công nghệ cổ điển tốt nhất, nhưng phương pháp benchmark trong bài này đạt được kết quả chính xác cho các bài toán lên đến 80 qubit/biến.\nCác thuật toán QAOA được sử dụng Thuật toán QAOA thuộc loại hybrid quantum-classical, nghĩa là nó sử dụng cả phần tính toán lượng tử và phần tính toán cổ điển, được tin là phù hợp trong thời đại NISQ (noisy intermediate-scale quantum). Nhóm Strangeworks dựa trên hai thuật toán QAOA có sẵn:\nQAOA tiêu chuẩn (Standard QAOA): Có trong nhiều thư viện mã nguồn mở bao gồm Braket algorithm library\nRelax-and-Round QAOA: Một biến thể được phát triển bởi đội của Rigetti Computing\nStrangeworksQAOA: Biến thể riêng với cải tiến trong phần xử lý cổ điển, vượt trội so với QAOA chuẩn trong bài toán này\nSử dụng Braket Hybrid Jobs Kết hợp tài nguyên lượng tử và cổ điển thông qua các thuật toán hybrid như QAOA là con đường để sử dụng máy tính lượng tử hiện có cùng với luồng công việc cổ điển. Nhóm dùng Amazon Braket Hybrid Jobs, cho phép toàn bộ workflow QAOA được gửi như một job duy nhất.\nLợi ích của Braket Hybrid Jobs Giảm thời gian chờ: Thuật toán chỉ phải chờ trong hàng đợi Braket một lần, thay vì chờ mỗi lần gửi mạch lượng tử riêng lẻ\nCached circuit compilation: Cho phép các mạch kế tiếp nếu có cấu trúc giống mạch trước đó dùng lại phần biên dịch trước đó, tiết kiệm thời gian và chi phí\nTích hợp với nền tảng Strangeworks Người dùng có thể truy cập Braket và các tính năng này qua platform Strangeworks Compute. Nền tảng này có hệ thống quản lý công việc trực tuyến và SDK để tải xuống, cho phép người dùng truy cập StrangeworksQAOA, Braket Hybrid Jobs cũng như các thiết bị lượng tử, lượng tử cảm hứng (\u0026ldquo;quantum-inspired\u0026rdquo;) và các solver cổ điển.\nPhương pháp benchmark Để benchmark StrangeworksQAOA, nhóm xét bài toán tối ưu xếp hàng hóa lên máy bay, được hình thành ban đầu như một phần của thử thách tính toán lượng tử của Airbus. Bài toán này cố gắng tối đa hóa khối lượng hàng được xếp lên máy bay, đồng thời đảm bảo rằng số lượng container (n) có thể vừa vào số chỗ có sẵn (N).\nCác trường hợp kiểm tra Bảng 1: Các giá trị xét cho số container (n) và số chỗ có sẵn trên máy bay (N)\nContainers (n) Spaces (N) Số biến/qubits 5 3 26 6 4 38 6 5 46 7 5 52 7 6 61 8 6 68 8 7 78 Kết quả so sánh Hình 1: So sánh máy lượng tử Rigetti Ankaa-3 chạy thuật toán StrangeworksQAOA (vòng tròn liền) với Standard QAOA (ô vuông liền), cả hai dùng framework Braket Hybrid Job. Ngoài ra, còn có kết quả từ QRR của Rigetti (ô vuông gạch) và StrangeworksQRR (vòng tròn gạch).\nKết quả được lấy trung bình trên 8 lần chạy. Thanh lỗi thống kê nhỏ so với bề rộng đường biểu diễn cho thấy kết quả ổn định với bài toán được xét.\nPhân tích gradient Bảng 2: Gradient của đường khớp cho mỗi thuật toán\nThuật toán Gradient Gurobi -1.25 StrangeworksQAOA 3.47 Standard QAOA n.a Strangeworks QRR QAOA -0.16 Rigetti QRR QAOA 1.06 Standard QAOA tăng theo cấp số (exponential) nên không thể có một fit tuyến tính hợp lý cho trường hợp đó.\nPhân tích gradient cho thấy phiên bản Strangeworks của QRR có gradient gần nhất với kết quả chính xác (Gurobi), nghĩa là phiên bản này sẽ tiếp tục có sai số nhỏ nhất khi kích thước hệ thống tăng.\nChi tiết thuật toán StrangeworksQAOA Thuật toán QAOA là một thuật toán hybrid cổ điển-lượng tử lặp trong một vòng giữa phần tính toán lượng tử và xử lý cổ điển.\nHình 2: QAOA workflow - (a) thiết lập mạch với tham số biến phân cổ điển và áp dụng lên qubit; (b) đo ra bitstring; (c) lặp nhiều lần để tạo phân bố xác suất; (d) tính chi phí và dùng thuật toán tối ưu hoá cổ điển để sinh mạch mới với tham số cập nhật\nQuy trình hoạt động Tham số hoá mạch lượng tử: Bắt đầu với tập tham số cổ điển θ. Nhóm sử dụng Real Amplitude Quantum Circuit thay vì ansatz QAOA tiêu chuẩn do hạn chế độ sâu mạch\nChạy trên QPU: Mạch được chạy trên QPU Rigetti Ankaa-3, đo trạng thái qubit (0 hoặc 1), lặp nhiều lần để thu được phân bố xác suất\nTính hàm chi phí: Phân bố xác suất được đưa vào hàm cổ điển để tính chi phí\nTối ưu hoá: Sử dụng phương pháp COBYLA từ gói SciPy để cập nhật tham số biến phân\nĐiểm khác biệt của StrangeworksQAOA Trong Standard QAOA, đáp án thường được chọn từ bitstring có xác suất cao nhất. Tuy nhiên, với hệ lớn, phân bố xác suất trở nên phẳng, mỗi trạng thái chỉ được đo một lần.\nTrong StrangeworksQAOA, nhóm:\nTheo dõi giá trị chi phí C_q nhỏ nhất trong suốt các vòng lặp Báo cáo trạng thái cơ sở có chi phí tối thiểu là lời giải Việc này hợp lý vì lời giải cho bài toán xếp hàng hóa là một đáp án cổ điển đơn Công thức tính chi phí Chi phí cho trạng thái cơ sở thứ q:\nTổng chi phí trung bình:\nTrong đó:\nq_i ∈ {0,1} là giá trị bit thứ i trong bitstring thứ q J_{i,j} là các hệ số coupling của QUBO/đồ thị vấn đề N_q là số lần trạng thái cơ sở được đo Kết luận và triển vọng Phân tích cho thấy giá trị của việc tối ưu hoá các thuật toán lượng tử cho ứng dụng cụ thể. Các phát hiện chính:\nStrangeworksQAOA bền vững hơn trước các bất cập của thuật toán lai lượng-cổ điển Kết hợp giữa nền tảng Strangeworks, StrangeworksQAOA, Braket Hybrid Jobs và thiết bị Rigetti Ankaa-3 thể hiện con đường thực tế để giải các bài toán tối ưu Phương pháp tinh chỉnh kỹ càng có thể đạt kết quả tốt hơn mà không tốn thêm chi phí Độ tin cậy và khả năng tái lập của kết quả trên bài toán xếp hàng hóa gợi mở một hướng đi khả quan cho việc đạt lợi thế lượng tử thực tiễn (practical quantum advantage).\nBắt đầu sử dụng Để khám phá các thuật toán này cho thách thức tối ưu của bạn:\nTruy cập nền tảng Strangeworks Xem tài liệu về QAOA Bắt đầu với Amazon Braket Tài liệu tham khảo Romero, S., Osaba, E., Villar-Rodriguez, E., Oregi, I. \u0026amp; Ban, Y. Hybrid approach for solving real-world bin packing problem instances using quantum annealers. Sci Rep 13, 11777 (2023).\nFarhi, E., Goldstone, J. \u0026amp; Gutmann, S. A Quantum Approximate Optimization Algorithm. arXiv:1411.4028 (2014).\nDupont, M. \u0026amp; Sundar, B. Extending relax-and-round combinatorial optimization solvers with quantum correlations. PhysRevA.109.012429 (2024).\nAirbus Quantum Computing Challenge\nPilon, G., Gugole, N. \u0026amp; Massarenti, N. Aircraft Loading Optimization \u0026ndash; QUBO models under multiple constraints. arXiv:2102.09621 (2021).\nGuerreschi, G. G. Solving Quadratic Unconstrained Binary Optimization with divide-and-conquer and quantum algorithms. arXiv:2101.07813v1 (2021).\nGurobi Optimization\nQAOA Circuit Ansatz\nReal Amplitude Quantum Circuit Ansatz\nBraket QAOA Example\nVề các tác giả Stuart Flannigan Senior Quantum Software Engineer tại Strangeworks, có nền tảng phân tích các thí nghiệm mô phỏng lượng tử. Từ khi gia nhập Strangeworks 3 năm trước, anh đã làm việc để kết hợp các ý tưởng lý thuyết của hệ thống lượng tử vào quy trình làm việc cổ điển và AI, giúp công nghệ này dễ tiếp cận hơn với ngành công nghiệp.\nAndrew J. Ochoa Chief Scientist tại Strangeworks, lãnh đạo các sáng kiến nghiên cứu và phát triển. Có bằng Tiến sĩ Vật lý từ Texas A\u0026amp;M University và MBA từ UT McCombs. Đã có nhiều công trình xuất bản về tính toán lượng tử và làm việc tại Strangeworks từ năm 2018.\nMichael Brett Principal Specialist for Quantum Computing trong nhóm High Performance Computing tại AWS. Lãnh đạo các nỗ lực phát triển kinh doanh và tiếp thị toàn cầu cho Amazon Braket. Trước đây là SVP for Applications tại Rigetti Computing và CEO của QxBranch.\nCharunethran Panchalam Govindarajan Sr. Product Marketing Manager tại AWS, tập trung vào High-Performance Computing và Quantum Technologies. Có bằng Thạc sĩ Kỹ thuật Điện từ Stanford University. Ngoài công việc, thích vẽ và các cuộc trò chuyện triết học.\nBài viết được đăng vào 02 THÁNG 9, 2025 trong Amazon Braket, Quantum Technologies\n"},{"uri":"https://khanh-0.github.io/aws/vi/1-worklog/1.3-week3/","title":"Worklog Tuần 3","tags":[],"description":"","content":"Mục tiêu tuần 3: Nắm vững Amazon EC2 và các tính năng cơ bản. Hiểu về EC2 instance types, AMI và pricing models. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu Amazon EC2 Fundamentals + EC2 instance types (General Purpose, Compute Optimized, Memory Optimized) + AMI (Amazon Machine Images) + Key pairs và Security Groups 22/09/2025 22/09/2025 https://cloudjourney.awsstudygroup.com/ 3 - Thực hành EC2: + Launch EC2 instances (Linux và Windows) + Kết nối SSH/RDP + Cấu hình Security Groups + Sử dụng User Data scripts 23/09/2025 23/09/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tìm hiểu EC2 Advanced Features + Launch Templates + Tạo custom AMI + EC2 Instance Metadata + Placement Groups 24/09/2025 24/09/2025 https://cloudjourney.awsstudygroup.com/ 5 - Triển khai ứng dụng trên EC2 + Deploy web application trên Amazon Linux + Deploy application trên Windows Server 2022 + Cấu hình Load Balancer cơ bản 25/09/2025 25/09/2025 https://cloudjourney.awsstudygroup.com/ 6 - Tìm hiểu EC2 Pricing Models + On-Demand, Reserved, Spot Instances + Savings Plans + Cost optimization strategies + Dọn dẹp tài nguyên 26/09/2025 26/09/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 3: Nắm vững Amazon EC2:\nEC2 instance types và use cases AMI (Amazon Machine Images) và cách tạo custom AMI Key pairs và Security Groups EC2 User Data để bootstrap instances EC2 Instance Metadata service Hiểu về EC2 Advanced Features:\nLaunch Templates để standardize deployments Placement Groups (Cluster, Spread, Partition) EC2 Instance Connect Elastic IP addresses Thực hành thành công:\nLaunch và kết nối EC2 instances (Linux và Windows) Cấu hình Security Groups và Network ACLs Tạo custom AMI từ running instance Deploy web applications trên EC2 Sử dụng User Data scripts để automate setup Hiểu về EC2 Pricing Models:\nOn-Demand Instances (pay as you go) Reserved Instances (1 hoặc 3 năm) Spot Instances (giá rẻ nhưng có thể bị terminate) Savings Plans Cost optimization best practices "},{"uri":"https://khanh-0.github.io/aws/vi/5-workshop/5.3-architecture/5.3.3-chunking/","title":"Chunking &amp; Embedding","tags":[],"description":"","content":"Lý do Chunking Tài liệu/FAQ thường dài; để tính embedding hiệu quả và tối ưu truy vấn tương đồng, cần chia văn bản lớn thành các đoạn nhỏ (chunk).\nLợi ích Giảm loss of context khi embed Retrieval chính xác hơn bằng vector similarity Tối ưu hiệu suất khi tìm kiếm Phù hợp với giới hạn token của model embedding Chiến lược Chunking Trong code sử dụng RecursiveCharacterTextSplitter:\nsplitter = RecursiveCharacterTextSplitter( chunk_size=500, chunk_overlap=0 ) chunks = splitter.split_documents(docs) Tham số Chunking Tham số Giá trị Ý nghĩa chunk_size 500 Kích thước mỗi chunk (characters) chunk_overlap 0 Không có phần chồng lấn giữa các chunk Gợi ý Tối ưu Kích thước chunk hợp lý: 500–1000 tokens (tùy model embedding) Chunk overlap: Nếu cần context liên tục, set overlap 50-100 characters Trade-off: Chunk nhỏ → chính xác cao nhưng nhiều vectors; Chunk lớn → ít vectors nhưng có thể mất ngữ cảnh Tạo Embedding và Vector Store Khởi tạo Embedding Model emb = HuggingFaceEmbeddings( model_name=\u0026#34;sentence-transformers/all-MiniLM-L6-v2\u0026#34; ) Model được chọn: all-MiniLM-L6-v2\nLightweight và nhanh Phù hợp cho tiếng Anh Kích thước embedding: 384 dimensions Tạo FAISS Vector Store faq_store = FAISS.from_documents(chunks, emb) FAISS (Facebook AI Similarity Search) cung cấp:\nTìm kiếm vector nhanh chóng Hiệu quả với datasets lớn Hỗ trợ nhiều thuật toán index Truy vấn Vector Store results = faq_store.similarity_search(query, k=3) Tham số:\nquery: Câu hỏi người dùng k=3: Trả về top 3 chunks có độ tương đồng cao nhất Ghi chú Quan trọng Cập nhật Dữ liệu Nếu dữ liệu thay đổi (add/update documents), cần: Re-embed toàn bộ hoặc Incremental update vector store Chọn Embedding Model Trade-off cần cân nhắc:\nTiêu chí Lightweight Model Heavy Model Tốc độ Nhanh Chậm Độ chính xác Tốt Rất tốt Chi phí Thấp Cao Use case FAQ, chatbot Research, legal Model tiếng Việt Nếu cần hỗ trợ tiếng Việt tốt hơn:\nkeepitreal/vietnamese-sbert sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2 Code Hoàn chỉnh from langchain_text_splitters import RecursiveCharacterTextSplitter from langchain_huggingface import HuggingFaceEmbeddings from langchain_community.vectorstores import FAISS # Load documents docs = load_faq_csv() # Chunking splitter = RecursiveCharacterTextSplitter( chunk_size=500, chunk_overlap=0 ) chunks = splitter.split_documents(docs) # Embedding emb = HuggingFaceEmbeddings( model_name=\u0026#34;sentence-transformers/all-MiniLM-L6-v2\u0026#34; ) # Vector Store faq_store = FAISS.from_documents(chunks, emb) # Query query = \u0026#34;Làm thế nào để đổi mật khẩu?\u0026#34; results = faq_store.similarity_search(query, k=3) Checklist Triển khai Chuẩn bị documents (CSV, JSON, text files) Chọn chunk_size phù hợp (test với 500, 750, 1000) Chọn embedding model (tiếng Anh hoặc đa ngôn ngữ) Tạo và lưu FAISS index Test retrieval với các query mẫu Monitor và điều chỉnh k value "},{"uri":"https://khanh-0.github.io/aws/vi/5-workshop/5.3-architecture/","title":"Kiến trúc mô hình Rag triển khai trên AWS Agent core","tags":[],"description":"","content":"Sử dụng Gateway endpoint Trong phần này, chúng ta sẽ tìm hiểu cách tích hợp Groq để gọi model OpenAI-compatible và cách chunking dữ liệu cho RAG.\n"},{"uri":"https://khanh-0.github.io/aws/vi/4-eventparticipated/4.4-event4/","title":"CMC Global TechTalk Series – Cloud &amp; Digital Transformation","tags":[],"description":"","content":"Mục tiêu Sự kiện Khám phá các công nghệ dẫn đầu được ứng dụng trong hệ sinh thái chuyển đổi số của CMC Global Học hỏi kiến thức thực tiễn về Cloud Engineering và Cloud Architecture từ các chuyên gia trong ngành Hiểu cách triển khai thực tế các giải pháp cloud migration, hiện đại hóa hệ thống và giải pháp doanh nghiệp Tạo cơ hội cho sinh viên và developer tiếp cận trực tiếp các thực hành cloud hiện đại và quy trình kỹ thuật Thúc đẩy sự kết nối cộng đồng giữa chuyên gia CMC Global và thế hệ kỹ sư cloud tương lai Diễn Giả Lê Thanh Đức – Cloud Delivery Manager, CMC Global Dư Quốc Thành – Technical Leader, CMC Global Văn Hoàng Kha – Cloud Engineer, AWS Community Builder Điểm Nổi Bật Kiến thức công nghệ dẫn đầu từ CMC Global TechTalk Series đã giới thiệu cho người tham dự những công nghệ có tác động mạnh mẽ nhất trong các giải pháp chuyển đổi số toàn diện mà CMC Global đang triển khai, bao gồm:\nChiến lược triển khai cloud-native Hiện đại hóa hệ thống ở cấp độ doanh nghiệp Best practices trong cloud migration Tự động hóa hạ tầng và tối ưu vận hành Case studies thực tế được triển khai cho các khách hàng quy mô lớn Mỗi diễn giả mang đến những góc nhìn khác nhau dựa trên nhiều năm kinh nghiệm thực chiến trong cloud delivery, technical leadership và cộng đồng AWS.\nChia sẻ chuyên môn từ các chuyên gia đầu ngành Anh Lê Thanh Đức chia sẻ góc nhìn về quản lý cloud delivery, làm việc với khách hàng và mở rộng đội ngũ cloud. Anh Dư Quốc Thành chia sẻ kiến thức sâu về thiết kế giải pháp và xử lý các thách thức kỹ thuật của doanh nghiệp. Anh Văn Hoàng Kha, với vai trò AWS Community Builder, truyền cảm hứng qua các best practices và tư duy cần có để trở thành cloud engineer thành công. Những Điều Rút Ra Cuối buổi, rất nhiều câu hỏi được đặt ra khiến không khí vô cùng hào hứng. Tôi đã hỏi anh Đức về “Anh bắt đầu sự nghiệp DevOps như thế nào?” và từ đó tôi hiểu rõ hơn con đường để trở thành một DevOps Engineer.\nNhận Thức Chiến Lược về Cloud \u0026amp; Hiện Đại Hóa Cloud transformation thành công dựa trên kiến trúc vững chắc, lập kế hoạch kỹ và tinh thần phối hợp nhóm Doanh nghiệp phụ thuộc nhiều vào tự động hóa để đảm bảo tính ổn định, khả năng mở rộng và hiệu quả vận hành Cloud governance, tối ưu chi phí và bảo mật phải được tích hợp ngay từ đầu Để trở thành cloud engineer, cần học liên tục, thực hành, và tham gia cộng đồng Bài Học Thực Tiễn từ TechTalk Hiểu cách các doanh nghiệp lớn xây dựng và quản lý dự án cloud migration Cách CMC Global ứng dụng cloud-native patterns để triển khai giải pháp digital end-to-end Tầm quan trọng của Infrastructure as Code (IaC), monitoring và DevOps pipelines Ví dụ thực tế về xử lý bottlenecks và vấn đề reliability trong hệ thống production Ứng Dụng vào Công Việc Bắt đầu từ nền tảng cloud và thực hành qua dự án thực tế hoặc hands-on labs Áp dụng nguyên tắc cloud-native như microservices, serverless và automation Sử dụng IaC như Terraform hoặc AWS CDK để quản lý hạ tầng có khả năng mở rộng Phát triển kỹ năng về observability, kiểm soát chi phí và kiến trúc secure-by-design Tham gia các cộng đồng như AWS User Group hoặc chương trình AWS Community Builder Trải Nghiệm Sự Kiện Tham dự CMC Global TechTalk Series là một trải nghiệm truyền cảm hứng, giúp tôi hiểu rõ hơn cách công nghệ cloud được áp dụng trong doanh nghiệp thực tế và cách kỹ sư giải quyết các bài toán phức tạp trong dự án chuyển đổi số.\nHọc Từ Chuyên Gia Trong Ngành Nắm được nhiều kiến thức giá trị từ các quản lý cloud, technical leaders và AWS community builders Trân trọng sự cởi mở khi chia sẻ những khó khăn thực tế trong dự án Hiểu rõ tư duy cần có để phát triển sự nghiệp cloud trong doanh nghiệp hiện đại Góc Nhìn Thực Tiễn Học được các ví dụ thực tiễn về triển khai cloud, tự động hóa và hiện đại hóa hệ thống Hiểu cách các đội ngũ tại CMC Global phối hợp để cung cấp giải pháp chất lượng cao Giao Lưu \u0026amp; Mở Rộng Mối Quan Hệ Trao đổi với diễn giả và người tham dự về lộ trình nghề nghiệp cloud Tìm hiểu thêm về cơ hội trong các đội ngũ kỹ thuật và delivery của CMC Global Bài Học Quan Trọng Cloud engineering là hành trình học tập và thử nghiệm không ngừng Doanh nghiệp hiện đại phụ thuộc vào hạ tầng tự động hóa, an toàn và có khả năng mở rộng Việc tham gia cộng đồng giúp tăng tốc phát triển kỹ năng và mở ra nhiều cơ hội Event Banner\nNhìn chung, buổi TechTalk mang lại nhiều góc nhìn giá trị về kỹ thuật cloud doanh nghiệp, thiết kế hệ thống hiện đại và tầm quan trọng của việc học hỏi liên tục trong thời đại chuyển đổi số.\n"},{"uri":"https://khanh-0.github.io/aws/vi/4-eventparticipated/","title":"Các events đã tham gia","tags":[],"description":"","content":"Em đã từng là một thành viên tổ chức sự kiện tại trường đại học trong thời gian gần đây. Tuy nhiên, AWS tại TP. Hồ Chí Minh thực sự khiến em ấn tượng bởi sự chuyên nghiệp và ý nghĩa trong từng hoạt động. Những sự kiện dưới đây chỉ là một phần mà em đã trực tiếp tham gia:\nEvent 1 Tên sự kiện: Kick-off AWS FCJ Workforce - FPTU OJT FALL 2025\nThời gian: 8:30 - 12:00, 06/09/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 2 Tên sự kiện: Cloud Day AWS 2025 in HCMC\nThời gian: 18/09/2025\nĐịa điểm: Tầng 26-36, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 3 Tên sự kiện: AI-Driven Development Life Cycle: Reimagining Software Engineering.\nThời gian: 03/10/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 4 Tên sự kiện: Reinventing DevSecOps with AWS Generative AI.\nThời gian: 16/10/2025\nĐịa điểm: Online Meeting\nVai trò trong sự kiện: Người tham dự\nEvent 5 Tên sự kiện: AWS Cloud Mastery Series #1: AI/ML/GenAI on AWS\nThời gian: 15/11/2025\nĐịa điểm: tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 6 Tên sự kiện: AWS Cloud Mastery Series #2: DevOps on AWS\nThời gian: 17/11/2025\nĐịa điểm: tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 7 Tên sự kiện: CloundFront as Your Foundation And AWS WAF \u0026amp; Application Protection\nThời gian: 19/11/2025\nĐịa điểm: tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 8 Tên sự kiện: Game Day - Secret Agent(ic) Unicorns\nThời gian: 14:00, 21/11/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 9 Tên sự kiện: AWS Cloud Mastery Series #3: AWS Well-Architected Security Pillar\nThời gian: 8:30 - 12:00, 29/11/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\n"},{"uri":"https://khanh-0.github.io/aws/vi/1-worklog/1.4-week4/","title":"Worklog Tuần 4","tags":[],"description":"","content":"Mục tiêu tuần 4: Nắm vững AWS IAM để quản lý truy cập và bảo mật. Hiểu về EC2 Instance Storage và các loại lưu trữ. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu AWS IAM + Users, Groups, Roles + Policies và Permissions + Best practices cho IAM 29/09/2025 29/09/2025 https://cloudjourney.awsstudygroup.com/ 3 - Thực hành IAM: + Tạo users và groups + Gán policies + Tạo và sử dụng IAM roles 30/09/2025 30/09/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tìm hiểu EC2 Instance Storage + Amazon EBS (Elastic Block Store) + EC2 Instance Store + Amazon EFS (Elastic File System) 01/10/2025 01/10/2025 https://cloudjourney.awsstudygroup.com/ 5 - Thực hành Storage: + Tạo và gắn EBS volumes + Tạo snapshots + Sử dụng EFS cho shared storage 02/10/2025 02/10/2025 https://cloudjourney.awsstudygroup.com/ 6 - Tìm hiểu về backup và disaster recovery + EBS snapshots + AMI creation + Cross-region backup 03/10/2025 03/10/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 4: Nắm vững AWS IAM và các khái niệm:\nUsers, Groups, Roles Policies và cách gán quyền MFA (Multi-Factor Authentication) Best practices về bảo mật IAM Hiểu rõ về EC2 Instance Storage:\nEBS volumes và các loại (gp3, io2, st1, sc1) EC2 Instance Store (ephemeral storage) EFS cho shared file system So sánh giữa các loại storage Thực hành thành công:\nTạo và quản lý IAM users, groups, roles Tạo, gắn và quản lý EBS volumes Tạo snapshots và restore Thiết lập EFS và mount vào EC2 Hiểu về backup strategies và disaster recovery cho EC2 và storage.\n"},{"uri":"https://khanh-0.github.io/aws/vi/5-workshop/5.4-agent-core-run/","title":"Run Agent Core","tags":[],"description":"","content":"Tổng quan Trong phần này, bạn sẽ học cách triển khai và gọi AWS Agent Core từ máy local Tại sao nên sử dụng AWS CLI: AWS CLI có thể giúp bạn truy cập và cấu hình set up được Agent Core từ máy của mình, linh hoạt và tiện lợi "},{"uri":"https://khanh-0.github.io/aws/vi/4-eventparticipated/4.5-event5/","title":"AWS Cloud Mastery Series #1: AI/ML/GenAI on AWS","tags":[],"description":"","content":"Mục tiêu Sự kiện Giới thiệu cho người tham dự các kiến thức nền tảng và ứng dụng thực tiễn của dịch vụ AI/ML trên AWS Cung cấp hiểu biết thực hành về Amazon SageMaker cho toàn bộ quy trình machine learning end-to-end Khám phá khả năng của Amazon Bedrock trong xây dựng và triển khai ứng dụng Generative AI Củng cố kiến thức về prompt engineering, kiến trúc RAG và lựa chọn mô hình phù hợp Giúp developer hiểu các thực hành MLOps tiêu chuẩn ngành với công cụ AWS Tạo cơ hội giao lưu và hợp tác giữa những người đam mê AI/ML Diễn Giả Đội ngũ AWS Vietnam AI/ML Specialist Các Facilitator từ AWS Training \u0026amp; Certification Điểm Nổi Bật Hiểu về Bối cảnh AI/ML Workshop mở đầu với cái nhìn tổng quan về hệ sinh thái AI và ML đang phát triển mạnh tại Việt Nam, bao gồm nhu cầu doanh nghiệp ngày càng tăng, mức độ ứng dụng AI trong các ngành như tài chính, thương mại điện tử, và vai trò của foundational models trong ứng dụng hiện đại.\nNgười tham dự đã nắm rõ hơn về:\nTốc độ phát triển nhanh của nhân lực AI và nhu cầu thị trường Các use case thực tiễn trong tài chính, e-commerce, chuyển đổi số Tầm quan trọng của nền tảng đám mây trong việc mở rộng quy mô workloads ML Deep Dive vào Dịch vụ AI của AWS Buổi workshop mang đến hướng dẫn chi tiết về công cụ, framework và best practices mà AWS cung cấp nhằm tăng tốc quá trình phát triển ML — từ chuẩn bị dữ liệu, huấn luyện, triển khai đến giám sát.\nAgenda 8:30 AM – 9:00 AM | Welcome \u0026amp; Introduction\nĐăng ký và giao lưu Giới thiệu tổng quan workshop và mục tiêu học tập Hoạt động ice-breaker Tổng quan bối cảnh AI/ML tại Việt Nam 9:00 AM – 10:30 AM | AWS AI/ML Services Overview\nAmazon SageMaker: Nền tảng ML end-to-end Quy trình chuẩn bị dữ liệu và labeling Huấn luyện, tinh chỉnh, và triển khai mô hình Tích hợp MLOps Live Demo: Trải nghiệm SageMaker Studio 10:30 AM – 10:45 AM | Nghỉ giải lao\n10:45 AM – 12:00 PM | Generative AI with Amazon Bedrock\nFoundation Models: Claude, Llama, Titan – so sánh \u0026amp; cách lựa chọn Prompt engineering: Chain-of-thought, few-shot prompting Kiến trúc RAG \u0026amp; thiết kế knowledge base Bedrock Agents cho workflow nhiều bước và tích hợp công cụ Cấu hình Guardrails để tạo output an toàn Live Demo: Xây dựng chatbot GenAI bằng Bedrock 12:00 PM | Nghỉ trưa (tự túc)\nNhững Điều Rút Ra Nhận Thức Chiến Lược về AI/ML trên AWS Quy trình ML end-to-end nhanh hơn đáng kể với các dịch vụ managed như SageMaker Triển khai và giám sát mô hình yêu cầu nền tảng MLOps vững chắc Lựa chọn Foundation Model phù hợp cần xem xét độ chính xác, độ trễ và đặc thù nghiệp vụ Workload GenAI đòi hỏi governance và kiểm soát an toàn chặt chẽ Bài Học Thực Tiễn từ SageMaker Chuẩn bị dữ liệu hiệu quả nhờ công cụ labeling và processing tích hợp Tối ưu mô hình tự động qua hyperparameter tuning Triển khai đơn giản bằng real-time endpoints và model monitoring Tầm quan trọng của versioning, lineage tracking và reproducibility Bài Học Thực Tiễn từ Bedrock Ứng dụng các pattern prompt engineering để tối ưu kết quả Biết khi nào nên dùng Claude, Llama hoặc Titan Triển khai RAG để tăng độ chính xác và tính hữu dụng Sử dụng Bedrock Agents cho workflow reasoning đa bước Thiết lập Guardrails và lọc output để đảm bảo an toàn Ứng dụng vào Công Việc Bắt đầu thử nghiệm mô hình ML qua SageMaker Studio notebooks Sử dụng Bedrock để prototype chatbot, trợ lý ảo, hoặc công cụ AI theo lĩnh vực Tích hợp pipeline RAG trong dự án yêu cầu thông tin chính xác và cập nhật Áp dụng MLOps để tăng độ tin cậy và khả năng mở rộng Tiếp tục học AI/ML thông qua labs, workshops và chứng chỉ AWS Trải Nghiệm Sự Kiện Tham dự workshop tại AWS Vietnam Office là một trải nghiệm truyền cảm hứng mạnh mẽ. Workshop mang đến cái nhìn thực tế và trực quan về cách xây dựng và triển khai hệ thống ML và GenAI ở quy mô lớn.\nHọc Từ Chuyên Gia AWS Hiểu cách SageMaker đơn giản hóa toàn bộ vòng đời ML Nắm cách doanh nghiệp sử dụng Bedrock để đẩy nhanh việc ứng dụng GenAI Biết cách áp dụng best practices quốc tế vào dự án thực tế tại Việt Nam Demo Thực Hành Quan sát ví dụ thực tế về training và deployment mô hình ML Trải nghiệm xây chatbot GenAI bằng Bedrock chỉ trong vài phút Hiểu cách RAG cải thiện độ chính xác và hiệu quả cho ứng dụng Hợp Tác \u0026amp; Giao Lưu Kết nối với developer, sinh viên và kỹ sư đám mây Chia sẻ insight về hướng đi nghề nghiệp AI và cơ hội học AWS Mở rộng mạng lưới trong cộng đồng AI/ML tại TP.HCM Bài Học Quan Trọng ML và GenAI mạnh nhất khi đi cùng nguyên tắc kỹ thuật vững chắc Năng suất tăng mạnh nhờ dịch vụ AI managed và tự động hóa Luôn cần thử nghiệm liên tục để làm chủ workload AI hiện đại Diễn giả - Presenter\nDiễn giả - Hoàng Anh\nDiễn giả - Hiếu Nghị\nNhìn chung, workshop mang đến góc nhìn sâu sắc về cách xây dựng ứng dụng ML và GenAI thực tế, giúp người tham dự tự tin áp dụng các dịch vụ AI của AWS vào những dự án sắp tới.\n"},{"uri":"https://khanh-0.github.io/aws/vi/1-worklog/1.5-week5/","title":"Worklog Tuần 5","tags":[],"description":"","content":"Mục tiêu tuần 5: Hiểu về High Availability và Scalability trong AWS. Nắm vững các dịch vụ database: RDS, Aurora, ElastiCache. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu High Availability \u0026amp; Scalability + Multi-AZ deployments + Auto Scaling Groups + Elastic Load Balancer (ALB, NLB, CLB) 29/09/2025 29/09/2025 https://cloudjourney.awsstudygroup.com/ 3 - Thực hành HA \u0026amp; Scalability: + Tạo Auto Scaling Group + Cấu hình Load Balancer + Test scaling policies 30/09/2025 30/09/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tìm hiểu Amazon RDS + RDS engines (MySQL, PostgreSQL, Oracle, SQL Server) + Multi-AZ và Read Replicas + Backup và restore 01/10/2025 01/10/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu Amazon Aurora \u0026amp; ElastiCache + Aurora MySQL/PostgreSQL + Aurora Serverless + ElastiCache (Redis, Memcached) 02/10/2025 02/10/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành Database: + Tạo RDS instance + Cấu hình Multi-AZ + Tạo Read Replica + Sử dụng ElastiCache 03/10/2025 03/10/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 5: Nắm vững khái niệm High Availability và Scalability:\nMulti-AZ deployments Auto Scaling Groups và scaling policies Load Balancing (ALB, NLB, CLB) Health checks và monitoring Hiểu rõ về các dịch vụ database trong AWS:\nAmazon RDS và các database engines Multi-AZ cho high availability Read Replicas cho read scalability Amazon Aurora và Aurora Serverless ElastiCache cho caching (Redis, Memcached) Thực hành thành công:\nThiết lập Auto Scaling Group với Launch Template Cấu hình Application Load Balancer Tạo và quản lý RDS instances Cấu hình Multi-AZ và Read Replicas Sử dụng ElastiCache để tăng performance Hiểu về database backup, restore và disaster recovery strategies.\n"},{"uri":"https://khanh-0.github.io/aws/vi/5-workshop/5.5-clean/","title":"Dọn Dẹp","tags":[],"description":"","content":"Overview Trong phần này, chúng ta sẽ xoá những gì đã khởi tạo trong workshop lần này\nXóa một Agent trong AgentCore Runtime Truy cập vào Amazon Bedrock AgentCore trên AWS Console. Trong menu bên trái, chọn Build → Runtime. Tại danh sách Runtime resources, bạn sẽ thấy các agent đã tạo, ví dụ: agent_demo_2 hoặc agent_with_memory. Chọn agent bạn muốn xóa bằng cách tick vào radio button ở cột Name. Nhấn nút Delete ở góc phải. Xác nhận thao tác xóa khi AWS yêu cầu. Agent sẽ bị xóa vĩnh viễn khỏi danh sách Runtime resources. Xóa một Memory trong AgentCore Sau khi xóa agent trong Runtime, bạn có thể quản lý hoặc xóa Memory mà agent đó sử dụng:\nTrong menu bên trái, chọn Build → Memory. Tại danh sách các Memory resources, chọn memory bạn muốn xóa. Nhấn nút Delete ở góc phải. Xác nhận thao tác xóa khi AWS yêu cầu. Memory sẽ bị xóa khỏi hệ thống. "},{"uri":"https://khanh-0.github.io/aws/vi/5-workshop/","title":"Workshop","tags":[],"description":"","content":"Xây dựng RAG Agent với Groq API và AgentCore Memory Tổng quan Trong workshop này, chúng ta sẽ xây dựng một RAG (Retrieval-Augmented Generation) Agent hoàn chỉnh với khả năng:\nGọi Groq API để sử dụng LLM models với hiệu năng cao Chunking \u0026amp; Embedding documents để tối ưu vector search AgentCore Memory để duy trì context lâu dài qua các phiên chat Tool Integration để agent có thể tự động search FAQ và reformulate queries AgentCore cung cấp framework để xây dựng AI agents với memory persistence, middleware hooks, và tool orchestration - cho phép agent \u0026ldquo;nhớ\u0026rdquo; lịch sử hội thoại và personalize responses.\nNội dung Tổng quan về Workshop Chuẩn bị Kiến trúc 5.3.1. Gọi Groq API 5.3.2. Chunking \u0026amp; Embedding 5.3.3. Code Handler AgentCore Chạy Agent Core Dọn dẹp AgentCore Tech Stack Component Technology LLM Provider Groq API (OpenAI models) Embedding Model HuggingFace (all-MiniLM-L6-v2) Vector Store FAISS Agent Framework LangChain + AgentCore Memory Backend AgentCore Memory Store Text Splitting RecursiveCharacterTextSplitter Điều kiện tiên quyết Python 3.8+ Groq API Key Kiến thức cơ bản về RAG và LLM Hiểu biết về vector embeddings Kết quả mong đợi Sau workshop, bạn sẽ có:\nAgent có khả năng trả lời FAQ dựa trên vector search\nMemory system để nhớ preferences và context người dùng\nTool orchestration để agent tự quyết định khi nào dùng tool\nProduction-ready code với error handling và logging\nBắt đầu: 5.1. Tổng quan về Workshop\n"},{"uri":"https://khanh-0.github.io/aws/vi/4-eventparticipated/4.6-event6/","title":"AWS Cloud Mastery Series #2: DevOps on AWS","tags":[],"description":"","content":"Mục tiêu Sự kiện Giới thiệu cho người tham dự về các nguyên tắc và văn hoá DevOps hiện đại Cung cấp kiến thức thực tiễn về các công cụ DevOps trên AWS trong CI/CD, hạ tầng và vận hành Minh họa cách DevOps tăng tốc độ triển khai thông qua tự động hóa, quan sát hệ thống, và cải tiến liên tục Trang bị hiểu biết thực hành về containerization, monitoring và chiến lược deploy Củng cố kiến thức về độ tin cậy, khả năng mở rộng, và operational excellence trên AWS Hỗ trợ người tham dự khám phá định hướng nghề nghiệp DevOps và các chứng chỉ AWS Diễn giả Đội ngũ AWS Vietnam DevOps Specialist Khách mời từ AWS Training \u0026amp; Certification Điểm nổi bật Tiếp cận Tư Duy DevOps Workshop mở đầu bằng thảo luận về sự chuyển dịch mạnh mẽ sang văn hóa DevOps. Người tham dự được giới thiệu:\nCác nguyên tắc hợp tác của DevOps Bộ chỉ số hiệu suất quan trọng (DORA metrics: Deployment Frequency, MTTR, Change Failure Rate) Tầm quan trọng của tự động hóa và cải tiến liên tục Cách DevOps bổ trợ cho quy trình AI/ML từ buổi trước Phiên này nhấn mạnh rằng văn hóa DevOps mạnh giúp tăng tốc độ triển khai, nâng cao độ tin cậy và củng cố tinh thần ownership trong kỹ thuật.\nTìm Hiểu Sâu về Bộ Công Cụ DevOps trên AWS Trong suốt ngày workshop, người tham dự khám phá các công cụ AWS-native về CI/CD, Infrastructure as Code, container orchestration và observability—hiểu rõ cách các đội kỹ thuật hiện đại xây dựng và triển khai hệ thống ở quy mô lớn.\nAgenda Phiên Sáng (8:30 AM – 12:00 PM) 8:30 – 9:00 AM | Welcome \u0026amp; DevOps Mindset\nTóm tắt buổi AI/ML trước Văn hóa và nguyên tắc DevOps Lợi ích và các chỉ số chính (DORA, MTTR, deployment frequency) 9:00 – 10:30 AM | AWS DevOps Services – CI/CD Pipeline\nSource Control: AWS CodeCommit, GitFlow, Trunk-based development Build \u0026amp; Test: cấu hình CodeBuild, kiểm thử tự động Deployment: CodeDeploy với Blue/Green, Canary, Rolling updates Orchestration: tự động hóa workflow bằng CodePipeline Demo: Walkthrough pipeline CI/CD hoàn chỉnh 10:30 – 10:45 AM | Nghỉ giải lao\n10:45 AM – 12:00 PM | Infrastructure as Code (IaC)\nAWS CloudFormation: templates, stacks, drift detection AWS CDK: constructs, reusable patterns, multi-language Demo: Triển khai hạ tầng bằng CloudFormation và CDK Thảo luận: Chọn công cụ IaC nào cho từng trường hợp 12:00 – 1:00 PM | Nghỉ trưa (tự túc)\nPhiên Chiều (1:00 PM – 5:00 PM) 1:00 – 2:30 PM | Container Services on AWS\nKiến thức cơ bản về Docker: microservices và containerization Amazon ECR: lưu trữ image, scanning, lifecycle policy Amazon ECS \u0026amp; EKS: chiến lược deploy, scaling, orchestration AWS App Runner: deploy container đơn giản Demo \u0026amp; Case Study: So sánh triển khai microservices 2:30 – 2:45 PM | Nghỉ giải lao\n2:45 – 4:00 PM | Monitoring \u0026amp; Observability\nCloudWatch: metrics, logs, alarms, dashboards AWS X-Ray: distributed tracing \u0026amp; insights hiệu năng Demo: Thiết lập full-stack observability Best practices: alerting, dashboards, quy trình on-call 4:00 – 4:45 PM | DevOps Best Practices \u0026amp; Case Studies\nMô hình deploy: feature flags, A/B testing Kiểm thử tự động \u0026amp; tích hợp CI/CD Quản lý sự cố và postmortem Case studies từ startups \u0026amp; enterprise 4:45 – 5:00 PM | Q\u0026amp;A \u0026amp; Wrap-up\nĐịnh hướng nghề nghiệp DevOps Lộ trình chứng chỉ AWS Những Điều Rút Ra Nhận Thức Chiến Lược về DevOps trên AWS DevOps tăng tốc triển khai và cải thiện hợp tác nhờ tự động hóa CI/CD giảm rủi ro và tăng tần suất release IaC đảm bảo hạ tầng nhất quán, có thể tái sử dụng và dễ mở rộng Containers tiêu chuẩn hóa môi trường triển khai Observability cực kỳ quan trọng cho high availability Bài học Thực tiễn từ CI/CD CodeCommit, CodeBuild, CodeDeploy và CodePipeline tạo thành pipeline tự động hoàn chỉnh Chiến lược deploy như Canary, Blue/Green giảm downtime và rủi ro Git strategies như Trunk-based development tăng tốc delivery Bài học Thực tiễn từ IaC CloudFormation mang lại cách quản lý hạ tầng có kiểm soát và khai báo CDK giúp mô hình hóa hạ tầng linh hoạt bằng code Hiểu khi nào dùng CloudFormation, khi nào dùng CDK là chìa khóa cho doanh nghiệp Bài học Thực tiễn từ Containers \u0026amp; Observability ECS và EKS mang lại orchestration mạnh mẽ cho microservices App Runner đơn giản hóa quy trình deploy CloudWatch + X-Ray giúp quan sát toàn bộ hệ thống Ứng dụng vào Công Việc Xây dựng pipeline CI/CD để tự động hoá build, test và deploy Sử dụng IaC để duy trì môi trường hạ tầng nhất quán Áp dụng containers cho ứng dụng scalable và portable Áp dụng thực hành observability để tăng độ tin cậy và giảm MTTR Tiếp tục học các công cụ DevOps và theo đuổi chứng chỉ AWS Trải nghiệm Sự kiện Workshop DevOps on AWS đem lại cái nhìn toàn diện và thực tế về quy trình DevOps hiện đại, tạo nền tảng vững chắc cho thử thách kỹ thuật thực tế.\nHọc hỏi từ Chuyên gia AWS DevOps Hiểu sâu về bộ công cụ DevOps native của AWS Nắm cách doanh nghiệp triển khai chuyển đổi DevOps ở quy mô lớn Hiểu vai trò thực sự của automation và observability trong production Thực hành Trực tiếp Quan sát pipeline CI/CD vận hành Thấy cách IaC đơn giản hóa provisioning và maintenance So sánh các chiến lược deploy containers Tạo dashboard monitoring và phân tích distributed tracing Giao lưu \u0026amp; Kết nối Gặp gỡ nhiều kỹ sư và developer đam mê DevOps Chia sẻ tài nguyên, kinh nghiệm và định hướng chứng chỉ Mở rộng network trong cộng đồng AWS DevOps Bài học Quan trọng DevOps là sự kết hợp của văn hóa, công cụ và kỷ luật vận hành Automation là chìa khóa cho tốc độ, độ tin cậy và hiệu quả Observability phải được tích hợp ngay từ đầu Cần học liên tục trong môi trường DevOps thay đổi nhanh Nhìn chung, phiên học này đã củng cố hiểu biết của tôi về nền tảng DevOps, bộ công cụ AWS và các best practices—giúp tôi tự tin hơn trong việc thiết kế, tự động hóa và vận hành các hệ thống cloud-native hiện đại.\n"},{"uri":"https://khanh-0.github.io/aws/vi/1-worklog/1.6-week6/","title":"Worklog Tuần 6","tags":[],"description":"","content":"Mục tiêu tuần 6: Nắm vững Amazon Route 53 và DNS routing. Hiểu về Classic Solutions Architecture và design patterns. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu Amazon Route 53 + DNS fundamentals + Hosted zones + Routing policies (Simple, Weighted, Latency, Failover, Geolocation) 06/10/2025 06/10/2025 https://cloudjourney.awsstudygroup.com/ 3 - Thực hành Route 53: + Đăng ký domain hoặc sử dụng domain có sẵn + Cấu hình các routing policies + Health checks 07/10/2025 07/10/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tìm hiểu Classic Solutions Architecture + 3-tier architecture + Stateless web tier + Stateful application tier 08/10/2025 08/10/2025 https://cloudjourney.awsstudygroup.com/ 5 - Thiết kế kiến trúc mẫu + WordPress on AWS + E-commerce platform + Microservices architecture 09/10/2025 09/10/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Vẽ kiến trúc với draw.io + Triển khai một kiến trúc 3-tier đơn giản + Document architecture decisions 10/10/2025 10/10/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 6: Nắm vững Amazon Route 53:\nDNS fundamentals và cách hoạt động Hosted zones (public và private) Các routing policies và use cases Health checks và DNS failover Domain registration Hiểu về Classic Solutions Architecture:\n3-tier architecture (Web, App, Database) Stateless vs Stateful design Horizontal vs Vertical scaling Best practices cho high availability Cost optimization strategies Thực hành thành công:\nCấu hình Route 53 với các routing policies Thiết lập health checks và failover Vẽ kiến trúc AWS với draw.io Triển khai kiến trúc 3-tier đơn giản Document và present architecture decisions Có khả năng thiết kế và triển khai các kiến trúc cơ bản trên AWS.\n"},{"uri":"https://khanh-0.github.io/aws/vi/6-self-evaluation/","title":"Tự đánh giá","tags":[],"description":"","content":"Trong suốt thời gian thực tập tại [Tên công ty/tổ chức] từ 08/09/2025 đến 09/12/2025, tôi đã có cơ hội học hỏi, rèn luyện và áp dụng kiến thức đã được trang bị tại trường vào môi trường làm việc thực tế.\nTôi đã tham gia dự án APT Magic, qua đó cải thiện kỹ năng lập trình, lên kế hoạch, Aws cloud.\nVề tác phong, tôi luôn cố gắng hoàn thành tốt nhiệm vụ, tuân thủ nội quy, và tích cực trao đổi với đồng nghiệp để nâng cao hiệu quả công việc.\nĐể phản ánh một cách khách quan quá trình thực tập, tôi xin tự đánh giá bản thân dựa trên các tiêu chí dưới đây:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức và kỹ năng chuyên môn Hiểu biết về ngành, áp dụng kiến thức vào thực tế, kỹ năng sử dụng công cụ, chất lượng công việc ☐ ✅ ☐ 2 Khả năng học hỏi Tiếp thu kiến thức mới, học hỏi nhanh ✅ ☐ ☐ 3 Chủ động Tự tìm hiểu, nhận nhiệm vụ mà không chờ chỉ dẫn ✅ ☐ ☐ 4 Tinh thần trách nhiệm Hoàn thành công việc đúng hạn, đảm bảo chất lượng ✅ ☐ ☐ 5 Kỷ luật Tuân thủ giờ giấc, nội quy, quy trình làm việc ☐ ✅ ☐ 6 Tính cầu tiến Sẵn sàng nhận feedback và cải thiện bản thân ✅ ☐ ☐ 7 Giao tiếp Trình bày ý tưởng, báo cáo công việc rõ ràng ☐ ✅ ☐ 8 Hợp tác nhóm Làm việc hiệu quả với đồng nghiệp, tham gia nhóm ☐ ✅ ☐ 9 Ứng xử chuyên nghiệp Tôn trọng đồng nghiệp, đối tác, môi trường làm việc ✅ ☐ ☐ 10 Tư duy giải quyết vấn đề Nhận diện vấn đề, đề xuất giải pháp, sáng tạo ☐ ✅ ☐ 11 Đóng góp vào dự án/tổ chức Hiệu quả công việc, sáng kiến cải tiến, ghi nhận từ team ✅ ☐ ☐ 12 Tổng thể Đánh giá chung về toàn bộ quá trình thực tập ✅ ☐ ☐ Cần cải thiện Nên cở mở trong việc trình bày trước nhiều người hơn thay thì thông qua nhóm chat Học cách giao tiếp tốt hơn trong giao tiếp hằng ngày và trong công việc, xử lý tình huống "},{"uri":"https://khanh-0.github.io/aws/vi/4-eventparticipated/4.7-event7/","title":"CloudFront as Your Foundation và AWS WAF &amp; Application Protection","tags":[],"description":"","content":"Mục tiêu Sự kiện Giới thiệu cho người tham dự các khái niệm nền tảng của Amazon CloudFront như một CDN toàn cầu Cung cấp kiến thức thực tiễn về cách CloudFront cải thiện hiệu năng, độ tin cậy và tối ưu chi phí Tìm hiểu AWS WAF, Shield và Bot Control trong bảo vệ ứng dụng Layer 7 Minh họa các kiến trúc bảo mật hiện đại cho web applications và API Tăng cường học tập thông qua phần Fun Quiz tương tác Củng cố kiến thức để xây dựng ứng dụng đám mây an toàn, có khả năng mở rộng và tối ưu chi phí Diễn giả Anh Hùng Gia – phiên CloudFront Mr. Julian – phiên WAF Điểm nổi bật Tăng tốc ứng dụng với Amazon CloudFront Phiên đầu giới thiệu về những thách thức trong hiệu năng web, chi phí khó dự đoán và lưu lượng tăng đột biến. Người tham dự được tìm hiểu cách CloudFront giải quyết các vấn đề này thông qua:\nMạng lưới Edge toàn cầu với các Points of Presence Multi-layer caching và Origin Shield Các kỹ thuật tăng tốc nâng cao (HTTP/3, persistent connections, multiplexing) Bảo vệ origin qua VPC Origins và Origin Access Control Các tính năng tối ưu chi phí tích hợp sẵn Các ví dụ thực tế minh họa cách CloudFront giảm độ trễ, giảm tải cho origin, giảm chi phí và cải thiện trải nghiệm người dùng ở quy mô lớn.\nTăng cường bảo mật với AWS WAF \u0026amp; Shield Phần thứ hai tập trung vào bảo mật ứng dụng trong bối cảnh mối đe dọa hiện đại, bao gồm:\nCác dạng tấn công phổ biến: OWASP Top 10, DDoS, bot, CVEs Các thành phần của AWS WAF (WebACL, rules, rule groups, COUNT mode, rate-based rules) AWS Managed Rules cho bảo vệ nhanh chóng Bot Control và kỹ thuật phân tích client AWS Shield và hệ thống phòng vệ DDoS nhiều lớp Các kiến trúc bảo mật CloudFront + WAF + Shield cho bảo vệ L7 vững chắc Người tham dự hiểu sâu hơn cách xây dựng hệ thống ứng dụng an toàn, resilent bằng các dịch vụ edge của AWS.\nAgenda Phiên Sáng (CloudFront) 8:30 – 9:00 AM | Chào mừng \u0026amp; Giới thiệu\nTổng quan về các vấn đề hiệu năng của ứng dụng web hiện đại Vai trò của CDN trong phân phối toàn cầu 9:00 – 10:30 AM | Amazon CloudFront Deep Dive\nHành vi caching và tối ưu cache Tổng quan Global Edge Network Các cải tiến hiệu năng (HTTP/3, nén, persistent TCP) Chiến lược bảo vệ origin Failover và multi-origin routing Demo: Tạo CloudFront distribution \u0026amp; phân tích hành vi 10:30 – 10:45 AM | Nghỉ giải lao\nPhiên Trưa (WAF \u0026amp; Shield) 10:45 AM – 12:00 PM | AWS WAF \u0026amp; Application Protection\nCác loại rule và best practices Rate-based rules chống HTTP flood Tổng quan AWS Managed Rules Bot Control và phân tích hành vi client Shield Advanced và khả năng phòng vệ tự động Demo: Tạo WebACL cho CloudFront 12:00 – 1:00 PM | Nghỉ trưa (tự túc)\nPhiên Chiều (Security Architecture \u0026amp; Fun Quiz) 1:00 – 2:30 PM | Security Architecture at the Edge\nTích hợp CloudFront + WAF + Shield Origin cloaking và VPC Origins Ứng dụng security layers cho API \u0026amp; web apps Công cụ quan sát và giám sát bảo mật 2:30 – 2:45 PM | Nghỉ giải lao\n2:45 – 3:30 PM | Fun Quiz – CloudFront \u0026amp; WAF Challenge\nCác câu hỏi tình huống thực tế Kiểm tra kiến thức về caching, rules và protection layers Quiz tương tác theo đội 3:30 – 4:00 PM | Tổng kết \u0026amp; Q\u0026amp;A\nĐịnh hướng nghề nghiệp cho mảng AWS Edge \u0026amp; Security Lộ trình học CloudFront, WAF và AWS Security Những Điều Rút Ra Tôi được chứng kiến một người làm kỹ thuật gần 60 tuổi – Mr. Julian – và người “sifu” tuyệt vời của chúng tôi – anh Hùng Gia.\nNhận thức Chiến lược về Edge Performance \u0026amp; Security CloudFront cải thiện hiệu năng toàn cầu thông qua caching và tối ưu mạng Origin có thể được bảo vệ khỏi truy cập công khai bằng VPC Origins và OAC WAF cung cấp khả năng bảo vệ L7 dựa trên rule cực kỳ linh hoạt Bot Control nâng cao khả năng phát hiện bot thông qua telemetry và behavioral tokens Shield mang lại khả năng chống DDoS tự động ngay tại edge Bài học thực tiễn từ CloudFront Multi-layer caching giảm chi phí origin và cải thiện độ trễ Failover và routing giúp tăng tính sẵn sàng của ứng dụng HTTP/3 và nén nâng cao cải thiện tốc độ đáng kể Bài học thực tiễn từ WAF COUNT mode rất quan trọng trước khi bật chế độ chặn Rate-based rules hiệu quả trong giảm thiểu flood traffic Managed Rules giúp triển khai bảo mật nhanh chóng Client interrogation phát hiện các loại bot tinh vi Ứng dụng vào Công Việc Sử dụng CloudFront để giảm độ trễ và giảm tải origin Bảo vệ ứng dụng web và API bằng WAF + Managed Rules Triển khai Shield để chống DDoS nâng cao Áp dụng chiến lược defense-in-depth cho edge và application layers Liên tục theo dõi hành vi người dùng và điều chỉnh ruleset Trải nghiệm Sự kiện Workshop CloudFront, WAF \u0026amp; Security Essentials mang đến cả chiều sâu lý thuyết và thực hành. Tôi hiểu rõ hơn cách doanh nghiệp xây dựng ứng dụng an toàn, hiệu năng cao, tối ưu chi phí ở quy mô toàn cầu.\nHọc hỏi từ Chuyên gia AWS Edge \u0026amp; Security Hiểu cách CloudFront tối ưu hiệu năng cho hàng triệu người dùng Nắm cách WAF và Shield giảm thiểu tấn công thực tế Quan sát nhiều kiến trúc được doanh nghiệp sử dụng Thực hành trực tiếp Cấu hình CloudFront distribution và behaviors Tạo và kiểm thử WAF rules với tình huống thực tế Khám phá bot detection và telemetry-based defense Giao lưu \u0026amp; Kết nối cộng đồng Tương tác với những người chung đam mê bảo mật \u0026amp; performance Thảo luận các use case thực tế và định hướng nghề nghiệp Bài học then chốt Performance và security phải được thiết kế song song tại edge Chiến lược caching đúng giúp giảm cả latency lẫn chi phí Defense-in-depth với CloudFront + WAF + Shield mang lại lớp bảo vệ vững chắc Cần học liên tục để theo kịp sự thay đổi của bối cảnh bảo mật Nhìn chung, workshop này đã củng cố hiểu biết của tôi về edge networking, các best practices bảo mật và công cụ bảo vệ ứng dụng AWS—giúp tôi tự tin hơn khi thiết kế hệ thống an toàn, có khả năng mở rộng với CloudFront và AWS WAF.\n"},{"uri":"https://khanh-0.github.io/aws/vi/1-worklog/1.7-week7/","title":"Worklog Tuần 7","tags":[],"description":"","content":"Mục tiêu tuần 7: Nắm vững Amazon S3 và các tính năng lưu trữ. Hiểu về S3 security và advanced features. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu Amazon S3 Basics + Buckets và Objects + Storage classes (Standard, IA, Glacier) + Versioning 13/10/2025 13/10/2025 https://cloudjourney.awsstudygroup.com/ 3 - Tìm hiểu S3 Advanced Features + Lifecycle policies + Cross-region replication + S3 Transfer Acceleration + S3 Select 14/10/2025 14/10/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tìm hiểu S3 Security + Bucket policies + IAM policies for S3 + Encryption (SSE-S3, SSE-KMS, SSE-C) + Access Control Lists (ACLs) 15/10/2025 15/10/2025 https://cloudjourney.awsstudygroup.com/ 5 - Thực hành S3: + Tạo buckets và upload objects + Cấu hình versioning + Thiết lập lifecycle policies 16/10/2025 16/10/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành S3 Security: + Cấu hình bucket policies + Enable encryption + Setup cross-region replication 17/10/2025 17/10/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 7: Nắm vững Amazon S3:\nBuckets, objects và S3 fundamentals Storage classes và cost optimization Versioning và object lifecycle S3 performance optimization Hiểu về S3 Advanced Features:\nLifecycle policies để tự động chuyển storage class Cross-region replication cho disaster recovery S3 Transfer Acceleration S3 Select và Glacier Select Nắm vững S3 Security:\nBucket policies và IAM policies Encryption options (SSE-S3, SSE-KMS, SSE-C) Access Control Lists (ACLs) S3 Block Public Access Pre-signed URLs Thực hành thành công:\nTạo và quản lý S3 buckets Cấu hình versioning và lifecycle policies Thiết lập encryption và bucket policies Setup cross-region replication Host static website trên S3 "},{"uri":"https://khanh-0.github.io/aws/vi/7-feedback/","title":"Chia sẻ, đóng góp ý kiến","tags":[],"description":"","content":" Tại đây bạn có thể tự do đóng góp ý kiến cá nhân về những trải nghiệm khi tham gia chương trình First Cloud Journey, giúp team FCJ cải thiện những vấn đề còn thiếu sót dựa trên các hạng mục sau:\nĐánh giá chung 1. Môi trường làm việc\nMôi trường làm việc rất thân thiện và cởi mở. Các thành viên trong FCJ luôn sẵn sàng hỗ trợ khi mình gặp khó khăn, kể cả ngoài giờ làm việc. Không gian làm việc gọn gàng, thoải mái, giúp mình tập trung tốt hơn. Tuy nhiên, mình nghĩ có thể bổ sung thêm một số buổi giao lưu hoặc team bonding để mọi người hiểu nhau hơn.\n2. Sự hỗ trợ của mentor / team admin\nMentor hướng dẫn rất chi tiết, giải thích rõ ràng khi mình chưa hiểu và luôn khuyến khích mình đặt câu hỏi. Team admin hỗ trợ các thủ tục, tài liệu và tạo điều kiện để mình làm việc thuận lợi. Mình đánh giá cao việc mentor cho phép mình thử và tự xử lý vấn đề thay vì chỉ đưa đáp án.\n3. Sự phù hợp giữa công việc và chuyên ngành học\nCông việc mình được giao phù hợp với kiến thức mình đã học ở trường, đồng thời mở rộng thêm những mảng mới mà mình chưa từng được tiếp cận. Nhờ vậy, mình vừa củng cố kiến thức nền tảng, vừa học thêm kỹ năng thực tế.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng\nTrong quá trình thực tập, mình học được nhiều kỹ năng mới như sử dụng công cụ quản lý dự án, kỹ năng làm việc nhóm, và cả cách giao tiếp chuyên nghiệp trong môi trường công ty. Mentor cũng chia sẻ nhiều kinh nghiệm thực tế giúp mình định hướng tốt hơn cho sự nghiệp.\n5. Văn hóa \u0026amp; tinh thần đồng đội\nVăn hóa công ty rất tích cực: mọi người tôn trọng lẫn nhau, làm việc nghiêm túc nhưng vẫn vui vẻ. Khi có dự án gấp, mọi người cùng nhau cố gắng, hỗ trợ không phân biệt vị trí. Điều này giúp mình cảm thấy mình là một phần của tập thể, dù chỉ là thực tập sinh.\n6. Chính sách / phúc lợi cho thực tập sinh\nCông ty có hỗ trợ phụ cấp thực tập và tạo điều kiện về thời gian linh hoạt khi cần thiết. Ngoài ra, việc được tham gia các buổi đào tạo nội bộ là một điểm cộng lớn.\nMột số câu hỏi khác Điều bạn hài lòng nhất trong thời gian thực tập? Điều bạn nghĩ công ty cần cải thiện cho các thực tập sinh sau? Nếu giới thiệu cho bạn bè, bạn có khuyên họ thực tập ở đây không? Vì sao? Đề xuất \u0026amp; mong muốn Bạn có đề xuất gì để cải thiện trải nghiệm trong kỳ thực tập? Bạn có muốn tiếp tục chương trình này trong tương lai? Góp ý khác (tự do chia sẻ): "},{"uri":"https://khanh-0.github.io/aws/vi/4-eventparticipated/4.8-event8/","title":"Game Day – Secret Agent(ic) Unicorns","tags":[],"description":"","content":"Mục tiêu Sự kiện Giới thiệu cho người tham dự cách giải quyết vấn đề bằng GenAI thông qua trải nghiệm GameDay tương tác Mang đến trải nghiệm thực hành với Amazon Bedrock, AgentCore, Knowledge Bases, Guardrails, và MCP Giúp người chơi hiểu cách các AI agent phối hợp với dịch vụ AWS trong workflow thực tế Khuyến khích tinh thần làm việc nhóm giữa các cấp độ kỹ năng để tăng cường học hỏi và tư duy giải quyết vấn đề Trình bày cách các dịch vụ serverless, database, và search tích hợp vào ứng dụng GenAI Tạo ra một môi trường vui vẻ, hấp dẫn, nơi người chơi kiếm điểm thông qua nhiệm vụ, câu đố và thử thách Các dịch vụ AWS sử dụng Amazon Bedrock (Foundation Models, Knowledge Bases, Guardrails) Amazon Bedrock AgentCore (Runtime, Memory, Code Interpreter, Observability) Strands Agents Model Context Protocol (MCP) Amazon DynamoDB Amazon OpenSearch Serverless Amazon Q Developer for CLI Đối tượng Tham dự Secret Agent(ic) AI GameDay được thiết kế cho nhiều vai trò khác nhau—bao gồm data scientist, ML practitioner, architect, developer và operations engineer.\nNgười tham dự:\nNên quen với AWS Console Có lợi khi làm việc nhóm đa kỹ năng Không bắt buộc biết lập trình (biết thì càng tốt) Được khuyến khích lập nhóm gồm Beginner, Intermediate, Expert để tối ưu hợp tác Độ Khó Mỗi nhóm lý tưởng gồm 3–5 thành viên với kỹ năng đa dạng:\n1–2 Experts 1–2 Intermediate 1–2 Beginners Điều này giúp cân bằng kỹ năng và tạo cơ hội học hỏi chéo.\nĐiểm nổi bật Hành trình GenAI phiêu lưu Sự kiện biến việc học GenAI thành một nhiệm vụ tương tác, nơi các nhóm hoạt động như Đặc vụ Bí mật, giải quyết thử thách bằng AI agents, database, knowledge retrieval và công cụ observability.\nThay vì học lý thuyết, người chơi tiến qua:\nNhiệm vụ Câu đố tính giờ Phân tích chứng cứ Các thử thách tích điểm Format này giúp tăng cường học kỹ thuật và kỹ năng làm việc nhóm.\nTrải nghiệm thực hành với Bedrock \u0026amp; AgentCore Người chơi tương tác với các dịch vụ GenAI hiện đại:\nSử dụng Foundation Models để suy luận ngôn ngữ tự nhiên Truy xuất dữ liệu qua Knowledge Bases Đảm bảo an toàn và tính đúng đắn bằng Guardrails Chạy multi-step agents bằng AgentCore Runtime \u0026amp; Memory Quan sát hành vi agent, debug và trace Lưu dữ liệu nhiệm vụ trong DynamoDB Dùng OpenSearch Serverless cho truy xuất nâng cao Những khái niệm này mô phỏng workload AI thực tế nhưng được trình bày theo cách gamified, dễ tiếp thu.\nHợp tác \u0026amp; Chiến lược Đội nhóm Để thành công, nhóm cần:\nGiao tiếp rõ ràng Chia vai trò hợp lý Ghi chú và theo dõi thông tin chung Xử lý sự cố nhanh Linh hoạt thích ứng Điểm không chỉ dựa trên hoàn thành nhiệm vụ, mà còn dựa trên hiệu suất, sự sáng tạo, và độ chính xác kỹ thuật.\nAgenda Intro Presentation \u0026amp; AWS Account Setup – 30 phút\nLuật chơi và cách tính điểm Đăng nhập tài khoản AWS Giới thiệu Bedrock, AgentCore và các dịch vụ hỗ trợ Game Playtime – 120 phút\nBắt đầu nhiệm vụ Có thời gian nghỉ Câu đố, nhiệm vụ Agent, thử thách theo thời gian Các đội thi đua tích lũy điểm cao nhất Closing – 30 phút\nGửi khảo sát Công bố Top 3 đội thắng Chụp hình lưu niệm Tổng kết kiến thức đã học Những Điều Rút Ra Dù không đạt giải thưởng nào, nhưng đây là một sự kiện đáng nhớ giúp tôi và đội của mình mạnh hơn và tích lũy thêm nhiều kỹ năng phục vụ cho chặng đường tiếp theo.\nGenAI Learning Thực hành trực tiếp với Bedrock Foundation Models Hiểu cách AgentCore quản lý memory, reasoning, operations Kỹ thuật quan sát hành vi agent và trace workflow AI nhiều bước Kỹ năng Kỹ thuật Sử dụng Knowledge Bases và OpenSearch Serverless để truy xuất thông tin Áp dụng Guardrails để kiểm soát output an toàn Tận dụng DynamoDB để lưu trữ dữ liệu nhiệm vụ Dùng Amazon Q Developer CLI để tăng tốc phát triển Kỹ năng Đội nhóm \u0026amp; Chiến lược Làm việc nhóm đa kỹ năng giúp học nhanh hơn Giao tiếp hiệu quả và lập kế hoạch tăng khả năng chiến thắng Áp lực thời gian mô phỏng môi trường làm việc thực tế Ứng dụng vào Công việc Áp dụng AI agents để tự động hóa workflow trong công việc Dùng chiến lược truy xuất (Knowledge Bases / OpenSearch) trong dự án thực Nâng cao thực hành AI an toàn bằng Guardrails Thử nghiệm xây dựng multi-step AI agent với Bedrock Agents \u0026amp; AgentCore Dùng Q Developer CLI để tăng tốc prototyping và engineering Trải nghiệm Sự kiện Tham gia Secret Agent(ic) Unicorns GameDay vừa thú vị vừa kích thích tư duy.\nĐây không phải workshop thông thường—mà là một cuộc điều tra AI yêu cầu tư duy nhanh, sáng tạo và làm việc nhóm hiệu quả.\nHọc thông qua Chơi Gamification giúp các khái niệm GenAI phức tạp trở nên dễ hiểu hơn.\nKhi giải nhiệm vụ, chúng tôi học được cách:\nKết hợp nhiều bước AI agent Debug reasoning path bằng observability Lưu, truy xuất, xác thực thông tin Sử dụng MCP và Bedrock Agents để hoàn thành thử thách Hợp tác \u0026amp; Tinh thần Đồng đội Mỗi thành viên đóng một vai trò riêng:\nngười debug, người phân tích logic, người thao tác dịch vụ AWS…\nSự đa dạng này giúp trải nghiệm vừa vui vừa hiệu quả.\nKhoảnh Khắc Kết Thúc Đáng Nhớ Xem leaderboard, chúc mừng đội thắng và chụp hình lưu niệm tạo nên một buổi tổng kết vui vẻ.\nĐây là sự kết hợp hoàn hảo giữa học tập, cạnh tranh và xây dựng cộng đồng.\nNhìn chung, GameDay là một trải nghiệm khó quên, kết hợp học GenAI và nhiệm vụ tương tác, giúp tôi nâng cao cả kỹ năng kỹ thuật lẫn khả năng hợp tác.\n"},{"uri":"https://khanh-0.github.io/aws/vi/1-worklog/1.8-week8/","title":"Worklog Tuần 8","tags":[],"description":"","content":"Mục tiêu tuần 8: Hiểu về CloudFront, Global Accelerator và AWS Storage Extras. Nắm vững AWS Integration \u0026amp; Messaging services. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu CloudFront \u0026amp; Global Accelerator + CloudFront distributions + Origins và behaviors + Global Accelerator use cases 20/10/2025 20/10/2025 https://cloudjourney.awsstudygroup.com/ 3 - Thực hành CloudFront: + Tạo CloudFront distribution + Cấu hình S3 origin + Custom domain với SSL/TLS 21/10/2025 21/10/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tìm hiểu AWS Storage Extras + AWS Storage Gateway + FSx for Windows File Server + FSx for Lustre + AWS Backup 22/10/2025 22/10/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu AWS Integration \u0026amp; Messaging + Amazon SQS (Standard, FIFO) + Amazon SNS + Amazon Kinesis + AWS Step Functions 23/10/2025 23/10/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành Messaging: + Tạo SQS queues + Tạo SNS topics + Kết nối SQS với SNS + Tạo Step Functions workflow 24/10/2025 24/10/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 8: Nắm vững CloudFront và Global Accelerator:\nCloudFront distributions và caching strategies Origins (S3, EC2, ALB, custom origins) Cache behaviors và TTL Global Accelerator cho low latency So sánh CloudFront vs Global Accelerator Hiểu về AWS Storage Extras:\nAWS Storage Gateway (File, Volume, Tape) FSx for Windows File Server FSx for Lustre cho HPC workloads AWS Backup cho centralized backup Nắm vững AWS Integration \u0026amp; Messaging:\nAmazon SQS (Standard vs FIFO queues) Amazon SNS (pub/sub messaging) Amazon Kinesis (Data Streams, Firehose, Analytics) AWS Step Functions (workflow orchestration) EventBridge cho event-driven architecture Thực hành thành công:\nTạo và cấu hình CloudFront distribution Setup custom domain với SSL/TLS Tạo SQS queues và SNS topics Kết nối các messaging services Tạo Step Functions state machine "},{"uri":"https://khanh-0.github.io/aws/vi/4-eventparticipated/4.9-event9/","title":"AWS Cloud Mastery Series #3: Trụ cột Bảo mật – AWS Well-Architected","tags":[],"description":"","content":"Mục tiêu Sự kiện Giới thiệu cho người tham dự về Trụ cột Bảo mật (Security Pillar) trong AWS Well-Architected Framework Cung cấp kiến thức thực tiễn về danh tính, phát hiện, bảo vệ hạ tầng, bảo vệ dữ liệu và ứng phó sự cố Nâng cao nhận thức về các mối đe dọa bảo mật đám mây trong bối cảnh Việt Nam Khám phá các mô hình IAM hiện đại, phân tách mạng, chiến lược mã hóa và tự động hóa ứng phó sự cố Giúp người tham dự hiểu cách áp dụng Zero Trust và Defense-in-Depth trong môi trường AWS Xây dựng nền tảng kiến thức cho những ai muốn theo đuổi chứng chỉ AWS Security Specialty Đối tượng Tham dự Workshop dành cho:\nCloud engineers, security engineers, kiến trúc sư, DevOps engineers Quản trị viên CNTT và đội ngũ vận hành trên AWS Lập trình viên quan tâm đến các best practices về bảo mật Bất kỳ ai muốn củng cố nền tảng bảo mật đám mây Không yêu cầu chuyên môn sâu, nhưng nên quen với AWS Console.\nĐiểm Nhấn Quan Trọng Nền tảng Bảo mật – Đặt vấn đề Phiên mở đầu giới thiệu về:\nVai trò của Security Pillar trong Well-Architected Framework Các nguyên tắc bảo mật cốt lõi: Least Privilege, Zero Trust, Defense in Depth Mô hình Trách nhiệm Chia sẻ và cách trách nhiệm thay đổi khi dùng dịch vụ managed Các mối đe dọa bảo mật đám mây phổ biến tại Việt Nam Nền tảng này giúp người tham dự hiểu vì sao bảo mật phải được xây dựng ngay từ đầu, không phải bổ sung sau.\nKhám phá sâu 5 trụ cột bảo mật Workshop được tổ chức xoay quanh 5 trụ cột bảo mật của AWS, với hướng dẫn thực tế, demo và ví dụ thực tiễn:\nKiến trúc IAM hiện đại với SSO, SCPs, permission boundaries Phát hiện \u0026amp; giám sát liên tục với CloudTrail, GuardDuty, Flow Logs, EventBridge Bảo vệ hạ tầng với phân tách VPC, WAF, Shield, Network Firewall Bảo vệ dữ liệu bằng mã hóa (KMS), quản lý vòng đời secrets và các guardrail Tự động hóa ứng phó sự cố bằng Lambda và Step Functions Agenda (Nội dung chương trình) Phiên Mở Đầu 8:30 – 8:50 AM | Khởi động \u0026amp; Giới thiệu Nền tảng Bảo mật\nVai trò của Security Pillar Nguyên tắc: Least Privilege, Zero Trust, Defense in Depth Mô hình Trách nhiệm Chia sẻ Các mối đe dọa đám mây hàng đầu tại Việt Nam ⭐ Trụ cột 1 — Identity \u0026amp; Access Management (IAM) 8:50 – 9:30 AM | Kiến trúc IAM hiện đại\nIAM users, roles, policies — tránh dùng long-term credentials IAM Identity Center: SSO và permission sets SCPs \u0026amp; permission boundaries cho multi-account MFA, rotation, Access Analyzer Mini Demo: Kiểm tra IAM policies \u0026amp; mô phỏng quyền truy cập ⭐ Trụ cột 2 — Khả năng Phát hiện (Detection) 9:30 – 9:55 AM | Phát hiện \u0026amp; Giám sát Liên tục\nCloudTrail (cấp tổ chức) GuardDuty \u0026amp; Security Hub Logging: VPC Flow Logs, ALB logs, S3 access logs Tự động hóa với EventBridge Detection-as-Code 9:55 – 10:10 AM | Nghỉ giải lao\n⭐ Trụ cột 3 — Bảo vệ Hạ tầng (Infrastructure Protection) 10:10 – 10:40 AM | Bảo mật mạng \u0026amp; workload\nPhân tách VPC: workloads công khai \u0026amp; riêng tư Security Groups vs NACLs WAF + Shield + Network Firewall Bảo vệ workload: EC2, ECS/EKS ⭐ Trụ cột 4 — Bảo vệ Dữ liệu (Data Protection) 10:40 – 11:10 AM | Mã hóa, khóa \u0026amp; secrets\nKMS: key policy, grants, rotation Mã hóa at-rest \u0026amp; in-transit: S3, EBS, RDS, DynamoDB Secrets Manager \u0026amp; Parameter Store – rotation patterns Phân loại dữ liệu \u0026amp; guardrail truy cập ⭐ Trụ cột 5 — Ứng phó Sự cố (Incident Response) 11:10 – 11:40 AM | Playbook \u0026amp; Tự động hóa IR\nVòng đời ứng phó sự cố trên AWS Playbook cho: IAM bị lộ credentials S3 public exposure EC2 có mã độc Isolation, snapshot, thu thập bằng chứng Tự động hóa bằng Lambda / Step Functions Phiên Tổng Kết 11:40 – 12:00 PM | Tổng kết \u0026amp; Q\u0026amp;A\nTóm tắt 5 trụ cột Các lỗi phổ biến tại doanh nghiệp Việt Nam Lộ trình học bảo mật (Security Specialty, SA Pro) Những Điều Rút Ra Tư duy bảo mật Bảo mật phải liên tục và chủ động Least privilege, Zero Trust, Defense in Depth là nền tảng Hiểu mô hình trách nhiệm chia sẻ là điều bắt buộc IAM \u0026amp; Detection SSO + permission sets giúp quản lý nhiều tài khoản dễ dàng SCPs cung cấp guardrail cấp tổ chức Giám sát liên tục với CloudTrail, GuardDuty, Flow Logs là bắt buộc Bảo vệ Hạ tầng \u0026amp; Dữ liệu Phân tách VPC giúp giảm phạm vi ảnh hưởng khi xảy ra sự cố Mã hóa phải được áp dụng ở mọi nơi Quản lý vòng đời secrets giúp giảm nguy cơ bị xâm nhập Ứng phó Sự cố Tự động hóa giúp rút ngắn thời gian xử lý sự cố Playbook giúp phản ứng nhanh và nhất quán Thu thập bằng chứng phải an toàn và bài bản Ứng dụng vào Công việc Áp dụng IAM Identity Center và SCPs trong môi trường multi-account Kích hoạt CloudTrail \u0026amp; GuardDuty cấp tổ chức Mã hóa \u0026amp; xoay vòng secrets cho mọi workload Dùng WAF, Shield để bảo vệ ứng dụng Xây dựng automation IR bằng Lambda hoặc Step Functions Trải nghiệm Sự kiện Tham gia AWS Well-Architected Security Pillar Workshop giúp tôi hiểu sâu hơn về cách bảo mật cần được thiết kế, triển khai và tự động hóa trong AWS.\nHọc hỏi từ Chuyên gia AWS Nắm được các thực hành IAM quan trọng, phát hiện mối đe dọa và ứng phó sự cố Hiểu cách doanh nghiệp hiện đại triển khai multi-account security Nắm được các lỗi thường gặp trong môi trường thực tế Hướng dẫn Thực hành Bài tập IAM giúp tôi hiểu rõ mô hình least-privilege Demo detection pipeline qua EventBridge \u0026amp; GuardDuty giúp tôi hình dung rõ hơn Playbook IR cho thấy tự động hóa quan trọng thế nào Cộng đồng \u0026amp; Giao lưu Người tham dự chia sẻ nhiều tình huống thực tế Thảo luận về xu hướng bảo mật và các sai cấu hình phổ biến Workshop nhấn mạnh tầm quan trọng của việc học liên tục trong bảo mật đám mây Nhìn chung, workshop giúp tôi củng cố nền tảng bảo mật đám mây, tự tin hơn khi thiết kế hệ thống an toàn và phù hợp với AWS Well-Architected Framework.\n"},{"uri":"https://khanh-0.github.io/aws/vi/1-worklog/1.9-week9/","title":"Worklog Tuần 9","tags":[],"description":"","content":"Mục tiêu tuần 9: Nắm vững Containers và Serverless trên AWS. Hiểu về serverless architectures và best practices. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu Containers on AWS + Docker fundamentals + Amazon ECS (Elastic Container Service) + Amazon EKS (Elastic Kubernetes Service) 27/10/2025 27/10/2025 https://cloudjourney.awsstudygroup.com/ 3 - Thực hành Containers: + Tạo Docker image + Push image lên ECR + Deploy container trên ECS + Fargate vs EC2 launch types 28/10/2025 28/10/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tìm hiểu Serverless Overview + AWS Lambda fundamentals + API Gateway + DynamoDB + Lambda triggers và integrations 29/10/2025 29/10/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu Serverless Architectures + Serverless web application + Event-driven architecture + Lambda best practices + SAM (Serverless App Model) 30/10/2025 30/10/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành Serverless: + Tạo Lambda functions + Cấu hình API Gateway + Kết nối với DynamoDB + Deploy serverless app 31/10/2025 31/10/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 9: Nắm vững Containers trên AWS:\nDocker fundamentals và containerization Amazon ECS (Fargate và EC2 launch types) Amazon EKS cho Kubernetes workloads Amazon ECR (Elastic Container Registry) Task definitions và services Hiểu về Serverless:\nAWS Lambda và event-driven computing Lambda triggers (S3, DynamoDB, API Gateway, etc.) Lambda layers và environment variables API Gateway (REST và HTTP APIs) DynamoDB cho serverless databases Nắm vững Serverless Architectures:\nServerless web applications Event-driven architectures Lambda best practices (cold starts, memory, timeout) AWS SAM (Serverless Application Model) Serverless Framework Thực hành thành công:\nBuild và deploy Docker containers trên ECS Tạo và deploy Lambda functions Cấu hình API Gateway với Lambda Tạo serverless CRUD application với DynamoDB Deploy serverless app với SAM/CloudFormation "},{"uri":"https://khanh-0.github.io/aws/vi/1-worklog/1.10-week10/","title":"Worklog Tuần 10","tags":[],"description":"","content":"Mục tiêu tuần 10: Nắm vững các dịch vụ Databases, Data \u0026amp; Analytics. Hiểu về Machine Learning services trên AWS. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu Databases in AWS + DynamoDB (NoSQL) + Amazon Redshift (Data Warehouse) + Neptune, DocumentDB, Timestream 03/11/2025 03/11/2025 https://cloudjourney.awsstudygroup.com/ 3 - Thực hành Databases: + Tạo DynamoDB table + Query và scan operations + DynamoDB Streams + Global Tables 04/11/2025 04/11/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tìm hiểu Data \u0026amp; Analytics + Amazon Athena + AWS Glue + Amazon EMR + Amazon Kinesis + QuickSight 05/11/2025 05/11/2025 https://cloudjourney.awsstudygroup.com/ 5 - Thực hành Data \u0026amp; Analytics: + Query S3 data với Athena + Tạo Glue crawler + Setup Kinesis stream 06/11/2025 06/11/2025 https://cloudjourney.awsstudygroup.com/ 6 - Tìm hiểu Machine Learning + Amazon SageMaker + Rekognition, Comprehend + Translate, Polly, Transcribe + Amazon Lex 07/11/2025 07/11/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 10: Nắm vững Databases trong AWS:\nDynamoDB (NoSQL database) DynamoDB Streams và Global Tables Amazon Redshift (Data Warehouse) Amazon Neptune (Graph Database) Amazon DocumentDB (MongoDB compatible) Amazon Timestream (Time series database) Hiểu về Data \u0026amp; Analytics:\nAmazon Athena (serverless query service) AWS Glue (ETL service) Amazon EMR (Elastic MapReduce) Amazon Kinesis (real-time data streaming) AWS Data Pipeline Amazon QuickSight (BI service) Nắm vững Machine Learning services:\nAmazon SageMaker (build, train, deploy ML models) Amazon Rekognition (image và video analysis) Amazon Comprehend (NLP service) Amazon Translate, Polly, Transcribe Amazon Lex (chatbots) Thực hành thành công:\nTạo và query DynamoDB tables Sử dụng Athena để query S3 data Setup Glue crawler và ETL jobs Tạo Kinesis stream cho real-time data Sử dụng SageMaker và Rekognition "},{"uri":"https://khanh-0.github.io/aws/vi/1-worklog/1.11-week11/","title":"Worklog Tuần 11","tags":[],"description":"","content":"Mục tiêu tuần 11: Nắm vững AWS Monitoring, Security và Advanced Identity. Hiểu về AWS VPC và networking. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu AWS Monitoring \u0026amp; Performance + Amazon CloudWatch (metrics, logs, alarms) + AWS CloudTrail + AWS Config + AWS Trusted Advisor 10/11/2025 10/11/2025 https://cloudjourney.awsstudygroup.com/ 3 - Thực hành Monitoring: + Tạo CloudWatch dashboards + Setup alarms và notifications + Enable CloudTrail + Review Trusted Advisor 11/11/2025 11/11/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tìm hiểu Advanced Identity \u0026amp; Security + AWS Organizations + AWS SSO + AWS KMS (Key Management Service) + CloudHSM, Secrets Manager 12/11/2025 12/11/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu AWS Security Services + AWS Shield \u0026amp; WAF + Amazon GuardDuty + Amazon Inspector + AWS Security Hub 13/11/2025 13/11/2025 https://cloudjourney.awsstudygroup.com/ 6 - Tìm hiểu Amazon VPC + Subnets, Route Tables, Internet Gateway + NAT Gateway, VPN + VPC Peering, Transit Gateway + VPC Endpoints 14/11/2025 14/11/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 11: Nắm vững AWS Monitoring \u0026amp; Performance:\nAmazon CloudWatch (metrics, logs, alarms, dashboards) AWS CloudTrail (audit và compliance) AWS Config (resource inventory và compliance) AWS Trusted Advisor (best practices recommendations) AWS X-Ray (distributed tracing) Hiểu về Advanced Identity \u0026amp; Security:\nAWS Organizations (multi-account management) AWS SSO (Single Sign-On) AWS KMS (Key Management Service) AWS CloudHSM AWS Secrets Manager và Parameter Store AWS Certificate Manager Nắm vững AWS Security Services:\nAWS Shield (DDoS protection) AWS WAF (Web Application Firewall) Amazon GuardDuty (threat detection) Amazon Inspector (vulnerability assessment) AWS Security Hub (centralized security) Hiểu về Amazon VPC:\nVPC components (subnets, route tables, IGW, NAT) Security Groups và NACLs VPC Peering và Transit Gateway VPN và Direct Connect VPC Endpoints (Gateway và Interface) Thực hành thành công:\nSetup CloudWatch monitoring và alarms Enable CloudTrail và Config Cấu hình KMS encryption Tạo và quản lý VPC với public/private subnets Setup VPN connection "},{"uri":"https://khanh-0.github.io/aws/vi/1-worklog/1.12-week12/","title":"Worklog Tuần 12","tags":[],"description":"","content":"Mục tiêu tuần 12: Nắm vững Disaster Recovery và Migration strategies. Ôn tập tổng hợp và chuẩn bị cho AWS Solutions Architect Associate. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu Disaster Recovery \u0026amp; Migrations + DR strategies (Backup \u0026amp; Restore, Pilot Light, Warm Standby, Multi-Site) + AWS Backup + AWS DRS (Disaster Recovery Service) 17/11/2025 17/11/2025 https://cloudjourney.awsstudygroup.com/ 3 - Tìm hiểu AWS Migration Services + AWS Application Discovery Service + AWS Migration Hub + AWS Database Migration Service (DMS) + AWS Server Migration Service (SMS) 18/11/2025 18/11/2025 https://cloudjourney.awsstudygroup.com/ 4 - Ôn tập More Solutions Architecture + Hybrid cloud architectures + Multi-region architectures + Event-driven architectures + Well-Architected Framework 19/11/2025 19/11/2025 https://cloudjourney.awsstudygroup.com/ 5 - Đọc AWS White Papers \u0026amp; Best Practices + AWS Well-Architected Framework + Security Best Practices + Cost Optimization + Reliability Pillar 20/11/2025 20/11/2025 https://cloudjourney.awsstudygroup.com/ 6 - Ôn tập tổng hợp và làm practice tests: + Review tất cả các modules + Làm practice exams + Hoàn thành workshop cuối khóa 21/11/2025 21/11/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 12: Nắm vững Disaster Recovery strategies:\nBackup \u0026amp; Restore (RPO/RTO cao, chi phí thấp) Pilot Light (RPO/RTO trung bình) Warm Standby (RPO/RTO thấp) Multi-Site/Hot Site (RPO/RTO rất thấp, chi phí cao) AWS Backup và AWS Elastic Disaster Recovery Hiểu về AWS Migration:\nAWS Application Discovery Service AWS Migration Hub AWS Database Migration Service (DMS) AWS Server Migration Service (SMS) AWS DataSync và Transfer Family 6 R\u0026rsquo;s of Migration (Rehost, Replatform, Repurchase, Refactor, Retire, Retain) Nắm vững More Solutions Architecture:\nHybrid cloud architectures Multi-region architectures Event-driven architectures Microservices patterns AWS Well-Architected Framework (5 pillars) Hoàn thành lộ trình học AWS:\nĐã học và thực hành 29 modules Hiểu rõ các dịch vụ AWS chính Có khả năng thiết kế kiến trúc AWS Sẵn sàng cho AWS Solutions Architect Associate exam Hoàn thành workshop cuối khóa và nộp qua Drive/GitHub "},{"uri":"https://khanh-0.github.io/aws/vi/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://khanh-0.github.io/aws/vi/tags/","title":"Tags","tags":[],"description":"","content":""}]