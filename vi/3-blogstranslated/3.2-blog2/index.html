<!doctype html><html lang=vi class="js csstransforms3d"><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=generator content="Hugo 0.134.3"><meta name=description content><meta name=author content="thienlh@thienlu.com"><link rel=icon href=https://khanh-0.github.io/aws/images/favicon.png type=image/png><title>Unlocking Next-Generation AI Performance with Dynamic Resource Allocation on Amazon EKS & EC2 P6e-GB200 :: Báo cáo thực tập</title>
<link href=https://khanh-0.github.io/aws/css/nucleus.css?1765372027 rel=stylesheet><link href=https://khanh-0.github.io/aws/css/fontawesome-all.min.css?1765372027 rel=stylesheet><link href=https://khanh-0.github.io/aws/css/hybrid.css?1765372027 rel=stylesheet><link href=https://khanh-0.github.io/aws/css/featherlight.min.css?1765372027 rel=stylesheet><link href=https://khanh-0.github.io/aws/css/perfect-scrollbar.min.css?1765372027 rel=stylesheet><link href=https://khanh-0.github.io/aws/css/auto-complete.css?1765372027 rel=stylesheet><link href=https://khanh-0.github.io/aws/css/atom-one-dark-reasonable.css?1765372027 rel=stylesheet><link href=https://khanh-0.github.io/aws/css/theme.css?1765372027 rel=stylesheet><link href=https://khanh-0.github.io/aws/css/hugo-theme.css?1765372027 rel=stylesheet><link href=https://khanh-0.github.io/aws/css/theme-workshop.css?1765372027 rel=stylesheet><script src=https://khanh-0.github.io/aws/js/jquery-3.3.1.min.js?1765372027></script><style>:root #header+#content>#left>#rlblock_left{display:none!important}</style></head><body data-url=https://khanh-0.github.io/aws/vi/3-blogstranslated/3.2-blog2/><nav id=sidebar class=showVisitedLinks><div id=header-wrapper><div id=header><a id=logo href=https://khanh-0.github.io/aws/><svg id="Layer_1" data-name="Layer 1" viewBox="0 0 60 30" width="30%"><defs><style>.cls-1{fill:#fff}.cls-2{fill:#f90;fill-rule:evenodd}</style></defs><title>AWS-Logo_White-Color</title><path class="cls-1" d="M14.09 10.85a4.7 4.7.0 00.19 1.48 7.73 7.73.0 00.54 1.19.77.77.0 01.12.38.64.64.0 01-.32.49l-1 .7a.83.83.0 01-.44.15.69.69.0 01-.49-.23 3.8 3.8.0 01-.6-.77q-.25-.42-.51-1a6.14 6.14.0 01-4.89 2.3 4.54 4.54.0 01-3.32-1.19 4.27 4.27.0 01-1.22-3.2 4.28 4.28.0 011.46-3.4A6.06 6.06.0 017.69 6.46a12.47 12.47.0 011.76.13q.92.13 1.91.36V5.73a3.65 3.65.0 00-.79-2.66A3.81 3.81.0 007.86 2.3a7.71 7.71.0 00-1.79.22 12.78 12.78.0 00-1.79.57 4.55 4.55.0 01-.58.22h-.26q-.35.0-.35-.52V2a1.09 1.09.0 01.12-.58 1.2 1.2.0 01.47-.35A10.88 10.88.0 015.77.32 10.19 10.19.0 018.36.0a6 6 0 014.35 1.35 5.49 5.49.0 011.38 4.09zM7.34 13.38a5.36 5.36.0 001.72-.31A3.63 3.63.0 0010.63 12 2.62 2.62.0 0011.19 11a5.63 5.63.0 00.16-1.44v-.7a14.35 14.35.0 00-1.53-.28 12.37 12.37.0 00-1.56-.1 3.84 3.84.0 00-2.47.67A2.34 2.34.0 005 11a2.35 2.35.0 00.61 1.76A2.4 2.4.0 007.34 13.38zm13.35 1.8a1 1 0 01-.64-.16 1.3 1.3.0 01-.35-.65L15.81 1.51a3 3 0 01-.15-.67.36.36.0 01.41-.41H17.7a1 1 0 01.65.16 1.4 1.4.0 01.33.65l2.79 11 2.59-11A1.17 1.17.0 0124.39.6a1.1 1.1.0 01.67-.16H26.4a1.1 1.1.0 01.67.16 1.17 1.17.0 01.32.65L30 12.39 32.88 1.25A1.39 1.39.0 0133.22.6a1 1 0 01.65-.16h1.54a.36.36.0 01.41.41 1.36 1.36.0 010 .26 3.64 3.64.0 01-.12.41l-4 12.86a1.3 1.3.0 01-.35.65 1 1 0 01-.64.16H29.25a1 1 0 01-.67-.17 1.26 1.26.0 01-.32-.67L25.67 3.64l-2.56 10.7a1.26 1.26.0 01-.32.67 1 1 0 01-.67.17zm21.36.44a11.28 11.28.0 01-2.56-.29 7.44 7.44.0 01-1.92-.67 1 1 0 01-.61-.93v-.84q0-.52.38-.52a.9.9.0 01.31.06l.42.17a8.77 8.77.0 001.83.58 9.78 9.78.0 002 .2 4.48 4.48.0 002.43-.55 1.76 1.76.0 00.86-1.57 1.61 1.61.0 00-.45-1.16A4.29 4.29.0 0043 9.22l-2.41-.76A5.15 5.15.0 0138 6.78a3.94 3.94.0 01-.83-2.41 3.7 3.7.0 01.45-1.85 4.47 4.47.0 011.19-1.37 5.27 5.27.0 011.7-.86A7.4 7.4.0 0142.6.0a8.87 8.87.0 011.12.07q.57.07 1.08.19t.95.26a4.27 4.27.0 01.7.29 1.59 1.59.0 01.49.41.94.94.0 01.15.55v.79q0 .52-.38.52a1.76 1.76.0 01-.64-.2 7.74 7.74.0 00-3.2-.64 4.37 4.37.0 00-2.21.47 1.6 1.6.0 00-.79 1.48 1.58 1.58.0 00.49 1.18 4.94 4.94.0 001.83.92L44.55 7a5.08 5.08.0 012.57 1.6A3.76 3.76.0 0147.9 11a4.21 4.21.0 01-.44 1.93 4.4 4.4.0 01-1.21 1.47 5.43 5.43.0 01-1.85.93A8.25 8.25.0 0142.05 15.62z"/><path class="cls-2" d="M45.19 23.81C39.72 27.85 31.78 30 25 30A36.64 36.64.0 01.22 20.57c-.51-.46-.06-1.09.56-.74A49.78 49.78.0 0025.53 26.4 49.23 49.23.0 0044.4 22.53C45.32 22.14 46.1 23.14 45.19 23.81z"/><path class="cls-2" d="M47.47 21.21c-.7-.9-4.63-.42-6.39-.21-.53.06-.62-.4-.14-.74 3.13-2.2 8.27-1.57 8.86-.83s-.16 5.89-3.09 8.35c-.45.38-.88.18-.68-.32C46.69 25.8 48.17 22.11 47.47 21.21z"/></svg></a></div><div class=searchbox><label for=search-by><i class="fas fa-search"></i></label>
<input data-search-input id=search-by type=search placeholder=Search...>
<span data-search-clear><i class="fas fa-times"></i></span></div><script type=text/javascript src=https://khanh-0.github.io/aws/js/lunr.min.js?1765372027></script><script type=text/javascript src=https://khanh-0.github.io/aws/js/auto-complete.js?1765372027></script><script type=text/javascript>var baseurl="https://khanh-0.github.io/aws//vi"</script><script type=text/javascript src=https://khanh-0.github.io/aws/js/search.js?1765372027></script></div><div class=highlightable><ul class=topics><li data-nav-id=/vi/1-worklog/ title="Nhật ký công việc" class=dd-item><a href=https://khanh-0.github.io/aws/vi/1-worklog/><b>1. </b>Nhật ký công việc
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/vi/1-worklog/1.1-week1/ title="Worklog Tuần 1" class=dd-item><a href=https://khanh-0.github.io/aws/vi/1-worklog/1.1-week1/><b>1.1. </b>Worklog Tuần 1
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.2-week2/ title="Worklog Tuần 2" class=dd-item><a href=https://khanh-0.github.io/aws/vi/1-worklog/1.2-week2/><b>1.2. </b>Worklog Tuần 2
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.3-week3/ title="Worklog Tuần 3" class=dd-item><a href=https://khanh-0.github.io/aws/vi/1-worklog/1.3-week3/><b>1.3. </b>Worklog Tuần 3
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.4-week4/ title="Worklog Tuần 4" class=dd-item><a href=https://khanh-0.github.io/aws/vi/1-worklog/1.4-week4/><b>1.4. </b>Worklog Tuần 4
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.5-week5/ title="Worklog Tuần 5" class=dd-item><a href=https://khanh-0.github.io/aws/vi/1-worklog/1.5-week5/><b>1.5. </b>Worklog Tuần 5
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.6-week6/ title="Worklog Tuần 6" class=dd-item><a href=https://khanh-0.github.io/aws/vi/1-worklog/1.6-week6/><b>1.6. </b>Worklog Tuần 6
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.7-week7/ title="Worklog Tuần 7" class=dd-item><a href=https://khanh-0.github.io/aws/vi/1-worklog/1.7-week7/><b>1.7. </b>Worklog Tuần 7
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.8-week8/ title="Worklog Tuần 8" class=dd-item><a href=https://khanh-0.github.io/aws/vi/1-worklog/1.8-week8/><b>1.8. </b>Worklog Tuần 8
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.9-week9/ title="Worklog Tuần 9" class=dd-item><a href=https://khanh-0.github.io/aws/vi/1-worklog/1.9-week9/><b>1.9. </b>Worklog Tuần 9
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.10-week10/ title="Worklog Tuần 10" class=dd-item><a href=https://khanh-0.github.io/aws/vi/1-worklog/1.10-week10/><b>1.10. </b>Worklog Tuần 10
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.11-week11/ title="Worklog Tuần 11" class=dd-item><a href=https://khanh-0.github.io/aws/vi/1-worklog/1.11-week11/><b>1.11. </b>Worklog Tuần 11
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.12-week12/ title="Worklog Tuần 12" class=dd-item><a href=https://khanh-0.github.io/aws/vi/1-worklog/1.12-week12/><b>1.12 </b>Worklog Tuần 12
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/vi/2-proposal/ title="Đề xuất" class=dd-item><a href=https://khanh-0.github.io/aws/vi/2-proposal/><b>2. </b>Đề xuất
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/3-blogstranslated/ title="Các bài blogs đã dịch" class="dd-item
parent"><a href=https://khanh-0.github.io/aws/vi/3-blogstranslated/><b>3. </b>Các bài blogs đã dịch
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/vi/3-blogstranslated/3.1-blog1/ title="Dynamic Kubernetes request right sizing with Kubecost" class=dd-item><a href=https://khanh-0.github.io/aws/vi/3-blogstranslated/3.1-blog1/><b>3.1. </b>Dynamic Kubernetes request right sizing with Kubecost
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/3-blogstranslated/3.2-blog2/ title="Unlocking Next-Generation AI Performance with Dynamic Resource Allocation on Amazon EKS & EC2 P6e-GB200" class="dd-item
active"><a href=https://khanh-0.github.io/aws/vi/3-blogstranslated/3.2-blog2/><b>3.2. </b>Unlocking Next-Generation AI Performance with Dynamic Resource Allocation on Amazon EKS & EC2 P6e-GB200
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/3-blogstranslated/3.3-blog3/ title="Cách Strangeworks sử dụng Amazon Braket để khám phá vấn đề xếp hàng hóa lên máy bay" class=dd-item><a href=https://khanh-0.github.io/aws/vi/3-blogstranslated/3.3-blog3/><b>3. </b>Cách Strangeworks sử dụng Amazon Braket để khám phá vấn đề xếp hàng hóa lên máy bay
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/vi/4-eventparticipated/ title="Các events đã tham gia" class=dd-item><a href=https://khanh-0.github.io/aws/vi/4-eventparticipated/><b>4. </b>Các events đã tham gia
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/vi/4-eventparticipated/4.1-event1/ title="Kick-off AWS First Cloud Journey Workforce" class=dd-item><a href=https://khanh-0.github.io/aws/vi/4-eventparticipated/4.1-event1/><b>4.1. </b>Kick-off AWS First Cloud Journey Workforce
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/4-eventparticipated/4.2-event2/ title="Cloud Day AWS 2025 in HCMC" class=dd-item><a href=https://khanh-0.github.io/aws/vi/4-eventparticipated/4.2-event2/><b>4.2. </b>Cloud Day AWS 2025 in HCMC
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/4-eventparticipated/4.3-event3/ title="AI-Driven Development Session with Amazon Q Developer & Kiro" class=dd-item><a href=https://khanh-0.github.io/aws/vi/4-eventparticipated/4.3-event3/><b>4.3. </b>AI-Driven Development Session with Amazon Q Developer & Kiro
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/4-eventparticipated/4.4-event4/ title="CMC Global TechTalk Series – Cloud & Digital Transformation" class=dd-item><a href=https://khanh-0.github.io/aws/vi/4-eventparticipated/4.4-event4/><b>4.4. </b>CMC Global TechTalk Series – Cloud & Digital Transformation
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/4-eventparticipated/4.5-event5/ title="AWS Cloud Mastery Series #1: AI/ML/GenAI on AWS" class=dd-item><a href=https://khanh-0.github.io/aws/vi/4-eventparticipated/4.5-event5/><b>4.5. </b>AWS Cloud Mastery Series #1: AI/ML/GenAI on AWS
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/4-eventparticipated/4.6-event6/ title="AWS Cloud Mastery Series #2: DevOps on AWS" class=dd-item><a href=https://khanh-0.github.io/aws/vi/4-eventparticipated/4.6-event6/><b>4.6. </b>AWS Cloud Mastery Series #2: DevOps on AWS
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/4-eventparticipated/4.7-event7/ title="CloudFront as Your Foundation và AWS WAF & Application Protection" class=dd-item><a href=https://khanh-0.github.io/aws/vi/4-eventparticipated/4.7-event7/><b>4.7. </b>CloudFront as Your Foundation và AWS WAF & Application Protection
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/4-eventparticipated/4.8-event8/ title="Game Day – Secret Agent(ic) Unicorns" class=dd-item><a href=https://khanh-0.github.io/aws/vi/4-eventparticipated/4.8-event8/><b>4.8. </b>Game Day – Secret Agent(ic) Unicorns
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/4-eventparticipated/4.9-event9/ title="AWS Cloud Mastery Series #3: Trụ cột Bảo mật – AWS Well-Architected" class=dd-item><a href=https://khanh-0.github.io/aws/vi/4-eventparticipated/4.9-event9/><b>4.9. </b>AWS Cloud Mastery Series #3: Trụ cột Bảo mật – AWS Well-Architected
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/vi/5-workshop/ title=Workshop class=dd-item><a href=https://khanh-0.github.io/aws/vi/5-workshop/><b>5. </b>Workshop
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/vi/5-workshop/5.1-workshop-overview/ title="Giới thiệu" class=dd-item><a href=https://khanh-0.github.io/aws/vi/5-workshop/5.1-workshop-overview/><b>5.1. </b>Giới thiệu
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/5-workshop/5.2-prerequiste/ title="Các bước chuẩn bị" class=dd-item><a href=https://khanh-0.github.io/aws/vi/5-workshop/5.2-prerequiste/><b>5.2. </b>Các bước chuẩn bị
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/5-workshop/5.3-architecture/ title="Kiến trúc mô hình Rag triển khai trên AWS Agent core" class=dd-item><a href=https://khanh-0.github.io/aws/vi/5-workshop/5.3-architecture/><b>5.3. </b>Kiến trúc mô hình Rag triển khai trên AWS Agent core
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/vi/5-workshop/5.3-architecture/5.3.1-agentcore-memory/ title="Agent core memory" class=dd-item><a href=https://khanh-0.github.io/aws/vi/5-workshop/5.3-architecture/5.3.1-agentcore-memory/><b>5.3.1 </b>Agent core memory
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/5-workshop/5.3-architecture/5.3.2-groq-api/ title="Gọi Groq API" class=dd-item><a href=https://khanh-0.github.io/aws/vi/5-workshop/5.3-architecture/5.3.2-groq-api/><b>5.3.2 </b>Gọi Groq API
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/5-workshop/5.3-architecture/5.3.3-chunking/ title="Chunking & Embedding" class=dd-item><a href=https://khanh-0.github.io/aws/vi/5-workshop/5.3-architecture/5.3.3-chunking/><b>5.3.3 </b>Chunking & Embedding
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/vi/5-workshop/5.4-agent-core-run/ title="Run Agent Core" class=dd-item><a href=https://khanh-0.github.io/aws/vi/5-workshop/5.4-agent-core-run/><b>5.4. </b>Run Agent Core
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/vi/5-workshop/5.4-agent-core-run/5.4.1-run-agentcore/ title="Cấu hình & Deploy AgentCore" class=dd-item><a href=https://khanh-0.github.io/aws/vi/5-workshop/5.4-agent-core-run/5.4.1-run-agentcore/><b>5.4.1 </b>Cấu hình & Deploy AgentCore
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/5-workshop/5.4-agent-core-run/5.4.2-call-agentcore/ title="Gọi AgentCore" class=dd-item><a href=https://khanh-0.github.io/aws/vi/5-workshop/5.4-agent-core-run/5.4.2-call-agentcore/><b>5.4.2 </b>Gọi AgentCore
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/vi/5-workshop/5.5-clean/ title="Dọn Dẹp" class=dd-item><a href=https://khanh-0.github.io/aws/vi/5-workshop/5.5-clean/><b>5.5 </b>Dọn Dẹp
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/vi/6-self-evaluation/ title="Tự đánh giá" class=dd-item><a href=https://khanh-0.github.io/aws/vi/6-self-evaluation/><b>6. </b>Tự đánh giá
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/7-feedback/ title="Chia sẻ, đóng góp ý kiến" class=dd-item><a href=https://khanh-0.github.io/aws/vi/7-feedback/><b>7. </b>Chia sẻ, đóng góp ý kiến
<i class="fas fa-check read-icon"></i></a></li></ul><section id=shortcuts><h3>More</h3><ul><li><a class=padding href=https://www.facebook.com/groups/awsstudygroupfcj/><i class='fab fa-facebook'></i> AWS Study Group</a></li></ul></section><section id=prefooter><hr><ul><li><a class=padding><i class="fas fa-language fa-fw"></i><div class=select-style><select id=select-language onchange="location=this.value"><option id=en value=https://khanh-0.github.io/aws/3-blogstranslated/3.2-blog2/>English</option><option id=vi value=https://khanh-0.github.io/aws/vi/3-blogstranslated/3.2-blog2/ selected>Tiếng Việt</option></select><svg id="Capa_1" xmlns:xlink="http://www.w3.org/1999/xlink" width="255" height="255" viewBox="0 0 255 255" style="enable-background:new 0 0 255 255"><g><g id="arrow-drop-down"><polygon points="0,63.75 127.5,191.25 255,63.75"/></g></g></svg></div></a></li><li><a class=padding href=# data-clear-history-toggle><i class="fas fa-history fa-fw"></i> Clear History</a></li></ul></section><section id=footer><left><b>Workshop</b><br><img src="https://hitwebcounter.com/counter/counter.php?page=7920860&style=0038&nbdigits=9&type=page&initCount=0" title=Migrate alt="web counter" border=0></a><br><b><a href=https://cloudjourney.awsstudygroup.com/>Cloud Journey</a></b><br><img src="https://hitwebcounter.com/counter/counter.php?page=7830807&style=0038&nbdigits=9&type=page&initCount=0" title="Total CLoud Journey" alt="web counter" border=0>
</left><left><br><br><b>Last Updated</b><br><i><span id=lastUpdated style=color:orange></span>
</i><script>const today=new Date,formattedDate=today.toLocaleDateString("en-GB");document.getElementById("lastUpdated").textContent=formattedDate</script></left><left><br><br><b>Team</b><br><i><a href=https://www.facebook.com/groups/660548818043427 style=color:orange>First Cloud Journey</a><br></i></left><script async defer src=https://buttons.github.io/buttons.js></script></section></div></nav><section id=body><div id=overlay></div><div class="padding highlightable"><div><div id=top-bar><div id=breadcrumbs itemscope itemtype=http://data-vocabulary.org/Breadcrumb><span id=sidebar-toggle-span><a href=# id=sidebar-toggle data-sidebar-toggle><i class="fas fa-bars"></i>
</a></span><span id=toc-menu><i class="fas fa-list-alt"></i></span>
<span class=links><a href=https://khanh-0.github.io/aws/vi/>Báo cáo thực tập</a> > <a href=https://khanh-0.github.io/aws/vi/3-blogstranslated/>Các bài blogs đã dịch</a> > Unlocking Next-Generation AI Performance with Dynamic Resource Allocation on Amazon EKS & EC2 P6e-GB200
          
       </span></div><div class=progress><div class=wrapper><nav id=TableOfContents><ul><li><a href=#sức-mạnh-phía-sau-p6e-gb200-kiến-trúc-nvidia-gb200-grace-blackwell>Sức mạnh phía sau P6e-GB200: kiến trúc NVIDIA GB200 Grace Blackwell</a></li><li><a href=#hiểu-kiến-trúc-ultraserver-ec2-p6e-gb200>Hiểu kiến trúc UltraServer EC2 P6e-GB200</a></li><li><a href=#tích-hợp-p6e-gb200-ultraservers-với-amazon-eks>Tích hợp P6e-GB200 UltraServers với Amazon EKS</a></li><li><a href=#thách-thức-chạy-khối-lượng-công-việc-ai-phân-tán-trên-kubernetes>Thách thức: chạy khối lượng công việc AI phân tán trên Kubernetes</a></li><li><a href=#giải-pháp-kubernetes-dra-và-imex>Giải pháp: Kubernetes DRA và IMEX</a><ul><li><a href=#cách-dra-giải-quyết-vấn-đề-cấp-gpu-truyền-thống>Cách DRA giải quyết vấn đề cấp GPU truyền thống</a></li><li><a href=#lên-lịch-aware-topology--đồng-nhất-bộ-nhớ-memory-coherence>Lên lịch aware topology & đồng nhất bộ nhớ (memory coherence)</a></li><li><a href=#quy-trình-lên-lịch-workload-với-dra>Quy trình lên lịch workload với DRA</a></li></ul></li><li><a href=#cách-sử-dụng-p6e-gb200-với-kubernetes-dra-trên-amazon-eks>Cách sử dụng P6e-GB200 với Kubernetes DRA trên Amazon EKS</a><ul><li><a href=#yêu-cầu-tiên-quyết>Yêu cầu tiên quyết</a></li><li><a href=#bước-1-đặt-trước-capacity-ultraserver-p6e-gb200>Bước 1: Đặt trước capacity UltraServer P6e-GB200</a></li><li><a href=#bước-2-tạo-file-cấu-hình-eks-cluster>Bước 2: Tạo file cấu hình EKS cluster</a></li><li><a href=#bước-3-triển-khai-cụm-eks>Bước 3: Triển khai cụm EKS</a></li><li><a href=#bước-4-triển-khai-nvidia-gpu-operator>Bước 4: Triển khai NVIDIA GPU Operator</a></li><li><a href=#bước-5-cài-đặt-nvidia-dra-driver>Bước 5: Cài đặt NVIDIA DRA Driver</a></li><li><a href=#bước-6-xác-minh-tài-nguyên-dra>Bước 6: Xác minh tài nguyên DRA</a></li></ul></li><li><a href=#xác-thực-cấp-kênh-imex>Xác thực cấp kênh IMEX</a><ul><li><a href=#giao-tiếp-imex-đa-node-trong-thực-tế>Giao tiếp IMEX đa node trong thực tế</a></li></ul></li><li><a href=#kết-luận>Kết luận</a></li><li><a href=#về-tác-giả>Về tác giả</a></li></ul></nav></div></div></div></div><div id=head-tags></div><div id=body-inner><h1>Unlocking Next-Generation AI Performance with Dynamic Resource Allocation on Amazon EKS & EC2 P6e-GB200</h1><h1 id=mở-khóa-hiệu-năng-ai-thế-hệ-mới-với-dynamic-resource-allocation-trên-amazon-eks-và-amazon-ec2-p6e-gb200>Mở khóa hiệu năng AI thế hệ mới với Dynamic Resource Allocation trên Amazon EKS và Amazon EC2 P6e-GB200</h1><p><em>Bài viết của Vara Bonthu, Nick Baker, và Chris Splinter - 02 tháng 9, 2025</em></p><p>Sự tiến hóa nhanh chóng của AI &ldquo;agentic&rdquo; và các mô hình ngôn ngữ lớn (LLM), đặc biệt là các mô hình suy luận, đã tạo ra nhu cầu chưa từng có về tài nguyên tính toán. Các mô hình AI tiên tiến ngày nay trải dài từ hàng trăm tỷ đến nghìn tỷ tham số và đòi hỏi sức mạnh tính toán khổng lồ, bộ nhớ lớn và liên kết tốc độ cao để hoạt động hiệu quả.</p><p>Các tổ chức phát triển ứng dụng cho xử lý ngôn ngữ tự nhiên, mô phỏng khoa học, tạo nội dung 3D và suy luận đa phương thức cần hạ tầng có thể mở rộng từ các mô hình tỷ tham số ngày nay đến biên giới nghìn tỷ tham số trong tương lai mà vẫn giữ hiệu suất.</p><p>Trong bài viết này, chúng ta sẽ khám phá cách <strong><a href=https://aws.amazon.com/ec2/>Amazon Elastic Compute Cloud (Amazon EC2)</a> <a href=https://aws.amazon.com/ec2/instance-types/p6/>P6e-GB200 UltraServers</a></strong> mới thay đổi khối lượng công việc AI phân tán qua tích hợp liền mạch với Kubernetes.</p><p>AWS giới thiệu các UltraServers EC2 P6e-GB200 để đáp ứng nhu cầu ngày càng tăng về huấn luyện và suy luận mô hình AI quy mô lớn. Chúng đại diện cho một bước đột phá kiến trúc đáng kể cho khối lượng công việc AI phân tán. Hơn nữa, việc ra mắt EC2 P6e-GB200 UltraServer bao gồm hỗ trợ <strong><a href=https://aws.amazon.com/eks/>Amazon EKS (Elastic Kubernetes Service)</a></strong>, cung cấp môi trường nguyên gốc Kubernetes để triển khai và mở rộng từ các mô hình hàng trăm tỷ đến nghìn tỷ tham số khi bối cảnh AI tiếp tục phát triển.</p><hr><h2 id=sức-mạnh-phía-sau-p6e-gb200-kiến-trúc-nvidia-gb200-grace-blackwell>Sức mạnh phía sau P6e-GB200: kiến trúc NVIDIA GB200 Grace Blackwell</h2><p>Ở trung tâm của các UltraServer EC2 P6e-GB200 là <strong><a href=https://www.nvidia.com/en-us/data-center/gb200-nvl72/>NVIDIA GB200 Grace Blackwell Superchip</a></strong>, tích hợp hai GPU NVIDIA Blackwell và một CPU NVIDIA Grace. Ngoài ra, nó cung cấp kết nối NVLink-Chip-to-Chip (C2C) giữa các thành phần này, đem lại <strong>900 GB/s</strong> băng thông hai chiều, nhanh hơn đáng kể so với các giao diện PCIe truyền thống.</p><p>Khi được triển khai ở quy mô rack, các UltraServer EC2 P6e-GB200 tham gia vào kiến trúc <strong><a href=https://developer.nvidia.com/blog/nvidia-contributes-nvidia-gb200-nvl72-designs-to-open-compute-project/>NVL72</a></strong> của NVIDIA, tạo ra các miền bộ nhớ đồng nhất (memory-coherent domains) đến 72 GPU.</p><p>Công nghệ <strong><a href=https://www.nvidia.com/en-us/data-center/nvlink/>NVLink</a></strong> thế hệ năm hỗ trợ giao tiếp GPU-to-GPU giữa các máy chủ riêng biệt trong cùng miền lên tới <strong>1.8 TB/s mỗi GPU</strong>. Yếu tố then chốt cho hiệu suất này là mạng <strong><a href=https://aws.amazon.com/hpc/efa/>Elastic Fabric Adapter (EFAv4)</a></strong>, cung cấp tổng băng thông mạng lên đến <strong>28.8 Tbps</strong> cho mỗi UltraServer.</p><p>EFA kết hợp với <strong>NVIDIA GPUDirect RDMA</strong> cho phép giao tiếp GPU-to-GPU giữa các máy chủ với độ trễ thấp, vượt qua hệ điều hành. Điều này đảm bảo rằng fabric GPU phân tán hoạt động với hiệu suất gần như bộ nhớ cục bộ giữa các node.</p><p>Đây là bước tiến đáng kể so với các UltraServer EC2 P6-B200 trước đây, vốn chỉ cung cấp tối đa 8 GPU B200 Blackwell trên nền tảng x86 dùng PCIe. P6e-GB200 nâng cấp kiến trúc bằng cách cung cấp bộ nhớ thực sự thống nhất qua các rack &mdash; một yêu cầu quan trọng để huấn luyện và vận hành mô hình nghìn tỷ tham số một cách hiệu quả.</p><p><img alt="Amazon EC2 P6e-GB200 UltraServers" src=https://khanh-0.github.io/aws/images/p6e-ultraserver.jpg>
<em>Hình 1: Amazon EC2 P6e-GB200 UltraServers</em></p><hr><h2 id=hiểu-kiến-trúc-ultraserver-ec2-p6e-gb200>Hiểu kiến trúc UltraServer EC2 P6e-GB200</h2><p>Một UltraServer EC2 P6e-GB200 <strong>không phải là một instance EC2 đơn lẻ</strong>. Thay vào đó, nó gồm nhiều instance EC2 được kết nối với nhau để hoạt động như một thực thể hợp nhất:</p><ul><li><strong>u-p6e-gb200x36</strong>: Gồm 36 GPU phân phối trên 9 instance EC2</li><li><strong>u-p6e-gb200x72</strong>: Gồm 72 GPU phân phối trên 18 instance EC2</li></ul><p>Mỗi instance P6e-GB200 cung cấp 4 GPU NVIDIA Blackwell. Do đó:</p><ul><li>Một UltraServer <strong>u-p6e-gb200x36</strong> là 9 instance (9 × 4 = 36 GPU)</li><li>Một UltraServer <strong>u-p6e-gb200x72</strong> là 18 instance (18 × 4 = 72 GPU)</li></ul><p>Trong Amazon EKS, mỗi instance EC2 xuất hiện dưới dạng một node Kubernetes riêng biệt, nhưng EKS hiểu vị trí topology và xử lý chúng như một phần của cùng UltraServer thông qua định tuyến aware topology.</p><hr><h2 id=tích-hợp-p6e-gb200-ultraservers-với-amazon-eks>Tích hợp P6e-GB200 UltraServers với Amazon EKS</h2><p>Nhóm Amazon EKS đã hợp tác chặt chẽ với NVIDIA từ đầu để thiết lập yêu cầu tích hợp P6e-GB200 với các node làm việc và control plane Kubernetes. Dựa trên các yêu cầu đó, chúng tôi phát triển <strong><a href=https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AMIs.html>AMI (Amazon Machine Images)</a></strong> dành cho ARM64 <strong><a href=https://aws.amazon.com/linux/amazon-linux-2023/>Amazon Linux 2023</a></strong> với flavor NVIDIA.</p><p>Chúng tôi cũng đóng gói sẵn các binary cho <strong><a href=https://docs.nvidia.com/multi-node-nvlink-systems/imex-guide/overview.html>Internal Node Memory Exchange/Management Service (IMEX)</a></strong> và cài sẵn phiên bản driver NVIDIA cần thiết.</p><p>Hơn nữa, Amazon EKS đã nhanh chóng hỗ trợ <strong><a href=https://kubernetes.io/docs/concepts/scheduling-eviction/dynamic-resource-allocation/>Dynamic Resource Allocation (DRA)</a></strong> cho người dùng bắt đầu từ phiên bản Kubernetes 1.33 trên EKS (tính năng này hiện vẫn là beta trong Kubernetes gốc).</p><p>Các instance đã được kiểm tra với NVLink qua IMEX cũng như qua EFA, để đạt được luồng dữ liệu tối ưu trong và giữa các UltraServer. Trong thử nghiệm nội bộ, chúng tôi sử dụng thư viện <strong>NVIDIA Collective Communications Library (NCCL)</strong> của NVIDIA, giúp trừu tượng hóa quyết định cấp giao vận từ lớp ứng dụng.</p><hr><h2 id=thách-thức-chạy-khối-lượng-công-việc-ai-phân-tán-trên-kubernetes>Thách thức: chạy khối lượng công việc AI phân tán trên Kubernetes</h2><p>Việc triển khai các workload GPU bó chặt (tightly coupled) qua nhiều node truyền thống gặp nhiều thách thức trong Kubernetes. Cách cấp tài nguyên truyền thống của Kubernetes giả định phần cứng gắn liền với từng node, làm khó quản lý tài nguyên GPU và kết nối bộ nhớ đồng nhất (memory-coherent interconnects) giữa các node.</p><p>Điều này phổ biến với các workload huấn luyện quy mô lớn như LLM hoặc mô hình thị giác máy tính cần nhiều GPU hoạt động song song.</p><p>Hãy xem cách tiếp cận truyền thống khi yêu cầu GPU trong một pod:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>resources</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>limits</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>nvidia.com/gpu</span>: <span style=color:#ae81ff>2</span>
</span></span></code></pre></div><p>Cách tiếp cận tĩnh này hoạt động tốt cho GPU cục bộ nhưng không thể biểu diễn topology kết nối phức tạp hoặc kênh giao tiếp GPU-to-GPU cần thiết cho các framework huấn luyện phân tán.</p><hr><h2 id=giải-pháp-kubernetes-dra-và-imex>Giải pháp: Kubernetes DRA và IMEX</h2><p>Để giải quyết những thách thức này, Kubernetes giới thiệu <strong>DRA (Dynamic Resource Allocation)</strong>, một framework mở rộng Kubernetes vượt ra ngoài CPU và bộ nhớ truyền thống để xử lý các topologies phần cứng phức tạp.</p><p>Amazon EKS đã kích hoạt DRA trong Kubernetes phiên bản 1.33, cung cấp khả năng quản lý topology GPU tinh vi mà trước đây không thể thực hiện được bằng cấp tài nguyên GPU truyền thống.</p><h3 id=cách-dra-giải-quyết-vấn-đề-cấp-gpu-truyền-thống>Cách DRA giải quyết vấn đề cấp GPU truyền thống</h3><p>Khác với mô hình tài nguyên tĩnh (ví dụ <code>nvidia.com/gpu: 2</code>) &ndash; trong đó bạn yêu cầu một số GPU cố định mà không quan tâm topology &ndash; DRA cho phép ứng dụng mô tả yêu cầu tài nguyên theo cách khai báo qua <strong>ComputeDomain</strong> và <strong>ResourceClaims</strong>.</p><p>Đây là sự chuyển đổi căn bản, giúp Kubernetes đưa ra quyết định cấp tài nguyên thông minh dựa vào topology thực tế, xem xét kết nối NVLink, băng thông bộ nhớ, và khoảng cách vật lý một cách tự động.</p><p>Quan trọng nhất, DRA ẩn đi các cấu hình thủ công phức tạp như cài đặt dịch vụ IMEX, quản lý partition NVLink, và khởi tạo phần cứng cấp thấp &mdash; những việc này nếu không sẽ đòi hỏi chuyên môn sâu về cụm GPU.</p><p><strong>NVIDIA DRA Driver</strong> là phần kết nối quan trọng giữa API DRA của Kubernetes và phần cứng bên dưới. Nó bao gồm hai plugin kubelet chuyên dụng:</p><ul><li><code>gpu-kubelet-plugin</code>: cho các tính năng cấp GPU nâng cao</li><li><code>compute-domain-kubelet-plugin</code>: điều phối primitives IMEX một cách tự động</li></ul><p>Khi bạn tạo một <strong>ComputeDomain</strong> yêu cầu 36 GPU qua 9 instance EC2 (mỗi instance có 4 GPU Blackwell), hoặc 72 GPU qua 18 instance cho một UltraServer đầy đủ, hệ thống sẽ tự động:</p><ul><li>Triển khai daemon IMEX</li><li>Thiết lập giao tiếp gRPC giữa các node</li><li>Tạo miền bộ nhớ đồng nhất (memory-coherent domain) với ánh xạ cross-node</li><li>Cung cấp các file thiết bị trong container</li></ul><h3 id=lên-lịch-aware-topology--đồng-nhất-bộ-nhớ-memory-coherence>Lên lịch aware topology & đồng nhất bộ nhớ (memory coherence)</h3><p>Khi một node tham gia vào một cluster EKS, control plane sẽ tiếp nhận thông tin topology liên quan đến instance qua API topology EC2 và gán nhãn (labels) cho node Kubernetes khi tham gia:</p><ul><li>Mỗi node P6e-GB200 được tự động gán nhãn loại capacity block (<code>eks.amazonaws.com/capacityType=CAPACITY_BLOCK</code> và <code>eks.amazonaws.com/nodegroup=...</code>) và các nhãn topology mạng chi tiết (<code>topology.k8s.aws/network-node-layer-1</code> đến <code>network-node-layer-4</code>)</li><li>Những nhãn này chỉ ra vị trí vật lý trong fabric mạng UltraServer</li></ul><p>Khi <strong>GPU Feature Discovery (GFD)</strong> được bật trong <strong><a href=https://github.com/NVIDIA/gpu-operator>NVIDIA GPU Operator</a></strong>, nó áp các nhãn clique (<code>nvidia.com/gpu.clique</code>) cho mỗi node để xác định GPU nào thuộc cùng một miền NVLink.</p><p>Những chiều topology này cho phép bạn thiết kế scheduling aware topology cho workload phân tán trên hoặc xuyên các nhóm node UltraServer.</p><p><strong>IMEX</strong> là khả năng then chốt của các hệ thống hỗ trợ NVLink như GB200 cho phép GPU giữa các node khác nhau truy cập trực tiếp bộ nhớ của nhau qua NVLink. Khi một <strong>kênh IMEX (IMEX channel)</strong> được cấp qua Kubernetes và DRA thông qua một ComputeDomain, nó xuất hiện trong container như một file thiết bị (ví dụ <code>/dev/nvidia-caps-imex-channels/channel0</code>).</p><p>Điều này cho phép ứng dụng CUDA hoạt động như thể tất cả GPU nằm trên cùng một board.</p><p>Khả năng này đặc biệt quan trọng cho các framework huấn luyện phân tán như <strong><a href=https://docs.open-mpi.org/en/v5.0.x/index.html>MPI</a></strong> và <strong><a href=https://developer.nvidia.com/nccl>NCCL</a></strong>. Chúng giờ đây có thể đạt hiệu suất gần như mức &ldquo;bare-metal&rdquo; qua các ranh giới node mà không cần cấu hình tùy chỉnh hay thay đổi mã.</p><p>Công nghệ <strong><a href=https://www.nvidia.com/en-us/data-center/nvlink/>NVLink 5.0</a></strong> cung cấp nền tảng băng thông để vận hành các kênh này với <strong>1.8 TB/s</strong> hai chiều mỗi GPU.</p><p>Điều này cho phép thực thi các miền tính toán (compute domains) đồng nhất bộ nhớ xuyên rack &mdash; tạo nền tảng cho hệ thống AI đa node chạy thời gian thực. Trong kiến trúc NVL72, lên đến 72 GPU có thể kết nối trong một miền NVLink đồng nhất bộ nhớ.</p><p>GPU được tổ chức thành các <strong>clique</strong> dựa trên kết nối vật lý qua NVSwitches, với mọi GPU trong cùng một node chắc chắn thuộc cùng một clique và chia sẻ cùng Cluster UUID.</p><p>Khi GFD được bật, nó gán nhãn <code>nvidia.com/gpu.clique</code> cho mỗi node chứa ID miền NVL và ID clique (ví dụ <code>cluster-abc.0</code>), cho phép người dùng thiết kế scheduling aware topology sử dụng node affinity rules.</p><p>Khi lên lịch công việc huấn luyện qua 9 instance của UltraServer u-p6e-gb200x36 hoặc 18 instance u-p6e-gb200x72, kube-scheduler với các affinity rule hợp lý đảm bảo rằng tất cả node thuộc cùng một miền NVLink để đạt băng thông tối đa.</p><p>Mặc dù NVLink cung cấp băng thông siêu cao trong cùng miền vật lý, mạng EFA đảm bảo giao tiếp giữa các UltraServers khác nhau có độ trễ thấp và throughput cao. Khả năng RDMA của EFA kết hợp với GPUDirect cho phép các GPU giao tiếp trực tiếp xuyên node mà CPU không can thiệp, tạo ra kiến trúc lai trong đó giao tiếp nội UltraServer dùng NVLink còn giữa các UltraServer dùng EFA.</p><p>Điều này làm cho P6e-GB200 phù hợp cho huấn luyện mô hình khổng lồ có thể mở rộng từ triển khai đơn rack đến cụm siêu máy tính đa rack trong khi vẫn giữ được đặc tính hiệu suất tối ưu ở mọi quy mô.</p><h3 id=quy-trình-lên-lịch-workload-với-dra>Quy trình lên lịch workload với DRA</h3><p>Lưu đồ dưới đây minh họa cách Kubernetes DRA tích hợp với công nghệ NVIDIA GB200 IMEX để triển khai khối lượng công việc huấn luyện AI phân tán trên nhiều node.</p><p>Khi một pod yêu cầu 8 GPU để huấn luyện phân tán với các quy tắc affinity được cấu hình chính xác, hệ thống sẽ điều phối việc triển khai thông qua một quy trình phối hợp:</p><ol><li>Người dùng chỉ định các pod cụ thể nhắm mục tiêu theo affinity theo node (<code>nvidia.com/gpu.clique</code>)</li><li>Kube-scheduler đặt các pod dựa trên các ràng buộc về affinity này</li><li>Các thành phần DRA xử lý việc quản lý tài nguyên và phối hợp giữa các node</li><li>Driver NVIDIA quản lý phân bổ GPU và điều phối IMEX</li><li>Dịch vụ IMEX đảm bảo tính nhất quán của bộ nhớ giữa các node thông qua giao tiếp gRPC</li></ol><p>Kết quả là triển khai liền mạch trên hai node (mỗi node 4 GPU) trong cùng một miền NVLink, cho phép giao tiếp băng thông cao, độ trễ thấp, điều cần thiết cho khối lượng công việc huấn luyện AI quy mô lớn.</p><p><img alt="DRA Workflow" src=https://khanh-0.github.io/aws/images/Blog/Blog_2/bl2_2.png></p><hr><h2 id=cách-sử-dụng-p6e-gb200-với-kubernetes-dra-trên-amazon-eks>Cách sử dụng P6e-GB200 với Kubernetes DRA trên Amazon EKS</h2><p>Phần này hướng dẫn từng bước thiết lập cụm EKS với UltraServer EC2 P6e-GB200 để tận dụng các khả năng nói trên.</p><h3 id=yêu-cầu-tiên-quyết>Yêu cầu tiên quyết</h3><p>Trước khi bắt đầu, hãy đảm bảo rằng bạn có các công cụ và quyền truy cập sau. Tham khảo <strong><a href=https://docs.aws.amazon.com/eks/latest/userguide/setting-up.html>EKS User Guide</a></strong> để biết hướng dẫn.</p><ul><li>Đã cài đặt <strong><a href=https://aws.amazon.com/cli/>AWS Command Line Interface (AWS CLI)</a></strong></li><li><code>eksctl</code> (phiên bản hỗ trợ EKS 1.33)</li><li><code>kubectl</code></li><li><code>helm</code></li><li>Quyền truy cập <strong>Capacity Blocks</strong> EC2 cho các instance P6e-GB200</li></ul><h3 id=bước-1-đặt-trước-capacity-ultraserver-p6e-gb200>Bước 1: Đặt trước capacity UltraServer P6e-GB200</h3><div class="notices note"><p>UltraServers P6e-GB200 chỉ có sẵn thông qua <strong>Capacity Blocks</strong> dành cho machine learning (ML). Bạn phải <strong>đặt trước UltraServer (không phải các instance riêng lẻ)</strong> trước khi tạo cụm EKS.</p></div><p>Trong giao diện console AWS:</p><ol><li>Vào <strong>EC2 Console → Capacity Reservations → Capacity Blocks</strong></li><li>Chọn tab <strong>UltraServers</strong> (không phải Instances)</li><li>Chọn một trong:<ul><li><code>u-p6e-gb200x36</code> (36 GPU qua 9 instance)</li><li><code>u-p6e-gb200x72</code> (72 GPU qua 18 instance)</li></ul></li><li>Hoàn thành việc đặt trước cho khoảng thời gian mong muốn</li></ol><h3 id=bước-2-tạo-file-cấu-hình-eks-cluster>Bước 2: Tạo file cấu hình EKS cluster</h3><p>Tạo file tên <code>cluster-config.yaml</code> với nội dung:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#75715e># cluster-config.yaml</span>
</span></span><span style=display:flex><span><span style=color:#f92672>apiVersion</span>: <span style=color:#ae81ff>eksctl.io/v1alpha5</span>
</span></span><span style=display:flex><span><span style=color:#f92672>kind</span>: <span style=color:#ae81ff>ClusterConfig</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>metadata</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>name</span>: <span style=color:#ae81ff>p6e-cluster</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>region</span>: <span style=color:#ae81ff>us-east-1</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>version</span>: <span style=color:#e6db74>&#39;1.33&#39;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>iam</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>withOIDC</span>: <span style=color:#66d9ef>true</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>managedNodeGroups</span>:
</span></span><span style=display:flex><span>  - <span style=color:#f92672>name</span>: <span style=color:#ae81ff>p6e-nodegroup</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>amiFamily</span>: <span style=color:#ae81ff>AmazonLinux2023</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>instanceType</span>: <span style=color:#ae81ff>p6e-gb200.36xlarge</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>desiredCapacity</span>: <span style=color:#ae81ff>9</span>  <span style=color:#75715e># All 9 instances from the UltraServer (36 GPUs total)</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>minSize</span>: <span style=color:#ae81ff>9</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>maxSize</span>: <span style=color:#ae81ff>9</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>labels</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>nvidia.com/gpu.present</span>: <span style=color:#e6db74>&#34;true&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>taints</span>:
</span></span><span style=display:flex><span>      - <span style=color:#f92672>key</span>: <span style=color:#ae81ff>nvidia.com/gpu</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>value</span>: <span style=color:#e6db74>&#34;true&#34;</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>effect</span>: <span style=color:#ae81ff>NoSchedule</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>availabilityZones</span>: [<span style=color:#e6db74>&#34;us-east-1-dfw-2a&#34;</span>]
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># Enable EFA (mandatory for P6e-GB200 UltraServers)</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>efaEnabled</span>: <span style=color:#66d9ef>true</span>
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#f92672>capacityReservation</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>enabled</span>: <span style=color:#66d9ef>true</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>capacityReservationTarget</span>:
</span></span><span style=display:flex><span>        <span style=color:#f92672>capacityReservationId</span>: <span style=color:#e6db74>&#34;cr-1234567890abcdef&#34;</span>  <span style=color:#75715e># Replace with your reservation ID</span>
</span></span></code></pre></div><h3 id=bước-3-triển-khai-cụm-eks>Bước 3: Triển khai cụm EKS</h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>eksctl create cluster -f cluster-config.yaml
</span></span></code></pre></div><p>Lệnh này sẽ tạo cụm EKS phiên bản 1.33 với 9 instance <code>p6e-gb200.36xlarge</code> từ UltraServer bạn đã đặt trước, với mạng EFA được bật để tối ưu giao tiếp GPU-to-GPU.</p><h3 id=bước-4-triển-khai-nvidia-gpu-operator>Bước 4: Triển khai NVIDIA GPU Operator</h3><p>GPU Operator của NVIDIA là thành phần thiết yếu cho instance GB200 vì nó quản lý toàn bộ vòng đời GPU &mdash; bao gồm cấu hình runtime và các tính năng nâng cao như MIG (Multi-Instance GPU).</p><p>Với topology NVLink phức tạp trải qua nhiều node, GPU Operator quản lý tài nguyên GPU động, cấu hình MIG, và xử lý các mối quan hệ liên kết interconnect mà plugin tĩnh không thể xử lý.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># Add the NVIDIA GPU Operator Helm repository</span>
</span></span><span style=display:flex><span>helm repo add nvidia https://nvidia.github.io/gpu-operator
</span></span><span style=display:flex><span>helm repo update
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Deploy the NVIDIA GPU Operator with custom values</span>
</span></span><span style=display:flex><span>cat <span style=color:#e6db74>&lt;&lt;EOF &gt; gpu-operator-values.yaml
</span></span></span><span style=display:flex><span><span style=color:#e6db74># gpu-operator-values.yaml
</span></span></span><span style=display:flex><span><span style=color:#e6db74>driver:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>  enabled: false
</span></span></span><span style=display:flex><span><span style=color:#e6db74>
</span></span></span><span style=display:flex><span><span style=color:#e6db74>mig:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>  strategy: mixed
</span></span></span><span style=display:flex><span><span style=color:#e6db74>
</span></span></span><span style=display:flex><span><span style=color:#e6db74>migManager:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>  enabled: true
</span></span></span><span style=display:flex><span><span style=color:#e6db74>  env:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    - name: WITH_REBOOT
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      value: &#34;true&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>  config:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    create: true
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    name: custom-mig-parted-configs
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    default: &#34;all-disabled&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    data:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      config.yaml: |-
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        version: v1
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        mig-configs:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>          all-disabled:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            - devices: all
</span></span></span><span style=display:flex><span><span style=color:#e6db74>              mig-enabled: false
</span></span></span><span style=display:flex><span><span style=color:#e6db74>          # P4DE profiles (A100 80GB)
</span></span></span><span style=display:flex><span><span style=color:#e6db74>          p4de-half-balanced:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            - devices: [0, 1, 2, 3]
</span></span></span><span style=display:flex><span><span style=color:#e6db74>              mig-enabled: true
</span></span></span><span style=display:flex><span><span style=color:#e6db74>              mig-devices:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>                &#34;1g.10gb&#34;: 2
</span></span></span><span style=display:flex><span><span style=color:#e6db74>                &#34;2g.20gb&#34;: 1
</span></span></span><span style=display:flex><span><span style=color:#e6db74>                &#34;3g.40gb&#34;: 1
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            - devices: [4, 5, 6, 7]
</span></span></span><span style=display:flex><span><span style=color:#e6db74>              mig-enabled: false
</span></span></span><span style=display:flex><span><span style=color:#e6db74>
</span></span></span><span style=display:flex><span><span style=color:#e6db74>devicePlugin:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>  enabled: true
</span></span></span><span style=display:flex><span><span style=color:#e6db74>  config:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    name: &#34;&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    create: false
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    default: &#34;&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>
</span></span></span><span style=display:flex><span><span style=color:#e6db74>toolkit:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>  enabled: false
</span></span></span><span style=display:flex><span><span style=color:#e6db74>
</span></span></span><span style=display:flex><span><span style=color:#e6db74>nfd:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>  enabled: true
</span></span></span><span style=display:flex><span><span style=color:#e6db74>
</span></span></span><span style=display:flex><span><span style=color:#e6db74>gfd:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>  enabled: true
</span></span></span><span style=display:flex><span><span style=color:#e6db74>
</span></span></span><span style=display:flex><span><span style=color:#e6db74>dcgmExporter:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>  enabled: true
</span></span></span><span style=display:flex><span><span style=color:#e6db74>  serviceMonitor:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    enabled: true
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    interval: 15s
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    honorLabels: false
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    additionalLabels:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      release: kube-prometheus-stack
</span></span></span><span style=display:flex><span><span style=color:#e6db74>
</span></span></span><span style=display:flex><span><span style=color:#e6db74>daemonsets:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>  tolerations:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    - key: &#34;nvidia.com/gpu&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      operator: &#34;Exists&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      effect: &#34;NoSchedule&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>  nodeSelector:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    accelerator: nvidia
</span></span></span><span style=display:flex><span><span style=color:#e6db74>  priorityClassName: system-node-critical
</span></span></span><span style=display:flex><span><span style=color:#e6db74>EOF</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Install GPU Operator using values file</span>
</span></span><span style=display:flex><span>helm install gpu-operator nvidia/gpu-operator <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --namespace gpu-operator <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --create-namespace <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --version v25.3.1 <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --values gpu-operator-values.yaml
</span></span></code></pre></div><h3 id=bước-5-cài-đặt-nvidia-dra-driver>Bước 5: Cài đặt NVIDIA DRA Driver</h3><p>Driver DRA của NVIDIA là thành phần thiết yếu cho UltraServer P6e-GB200 vì nó cung cấp các khả năng vượt ra ngoài plugin GPU truyền thống.</p><p>Mặc dù plugin NVIDIA Device Plugin chuẩn chỉ expose các GPU riêng lẻ như tài nguyên đếm được (<code>nvidia.com/gpu: 2</code>), DRA Driver mở rộng hai khả năng quan trọng:</p><ol><li><strong>Quản lý ComputeDomain</strong>: DRA Driver quản lý các ComputeDomain &mdash; là abstraction cho các triển khai Multi-Node NVLink (MNNVL)</li><li><strong>Cấp GPU nâng cao</strong>: Ngoài việc đếm GPU, DRA Driver cho phép cấp cấu hình GPU động, các thiết bị MIG, và scheduling aware topology</li></ol><p>DRA Driver bao gồm hai plugin kubelet:</p><ul><li><code>gpu-kubelet-plugin</code>: cho các chức năng cấp GPU nâng cao</li><li><code>compute-domain-kubelet-plugin</code>: điều phối ComputeDomain</li></ul><p>Tạo file <code>values.yaml</code> để triển khai <strong><a href=https://github.com/NVIDIA/k8s-dra-driver-gpu>NVIDIA DRA Driver</a></strong>:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#75715e># values.yaml</span>
</span></span><span style=display:flex><span>---
</span></span><span style=display:flex><span><span style=color:#f92672>nvidiaDriverRoot</span>: <span style=color:#ae81ff>/</span>
</span></span><span style=display:flex><span><span style=color:#f92672>gpuResourcesEnabledOverride</span>: <span style=color:#66d9ef>true</span>  <span style=color:#75715e># Required to deploy GPU and MIG deviceclasses</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>resources</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>gpus</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>enabled</span>: <span style=color:#66d9ef>true</span>  <span style=color:#75715e># set to false to disable experimental gpu support</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>computeDomains</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>enabled</span>: <span style=color:#66d9ef>true</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>controller</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>nodeSelector</span>: <span style=color:#66d9ef>null</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>affinity</span>: <span style=color:#66d9ef>null</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>tolerations</span>: []
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>kubeletPlugin</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>affinity</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>nodeAffinity</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>requiredDuringSchedulingIgnoredDuringExecution</span>:
</span></span><span style=display:flex><span>        <span style=color:#f92672>nodeSelectorTerms</span>:
</span></span><span style=display:flex><span>          - <span style=color:#f92672>matchExpressions</span>:
</span></span><span style=display:flex><span>              - <span style=color:#f92672>key</span>: <span style=color:#e6db74>&#34;nvidia.com/gpu.present&#34;</span>
</span></span><span style=display:flex><span>                <span style=color:#f92672>operator</span>: <span style=color:#ae81ff>In</span>
</span></span><span style=display:flex><span>                <span style=color:#f92672>values</span>:
</span></span><span style=display:flex><span>                  - <span style=color:#e6db74>&#34;true&#34;</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>tolerations</span>:
</span></span><span style=display:flex><span>    - <span style=color:#f92672>key</span>: <span style=color:#e6db74>&#34;nvidia.com/gpu&#34;</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>operator</span>: <span style=color:#ae81ff>Exists</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>effect</span>: <span style=color:#ae81ff>NoSchedule</span>
</span></span></code></pre></div><p>Sau đó cài đặt trình điều khiển NVIDIA DRA:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>helm repo add nvidia https://helm.ngc.nvidia.com/nvidia
</span></span><span style=display:flex><span>helm repo update
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>helm install nvidia-dra-driver-gpu nvidia/nvidia-dra-driver-gpu <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --version<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;25.3.0-rc.4&#34;</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --namespace nvidia-dra-driver-gpu <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --create-namespace <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  -f values.yaml
</span></span></code></pre></div><p>Sau khi cài, DRA Driver sẽ tạo ra các tài nguyên <strong>DeviceClass</strong> giúp Kubernetes hiểu và cấp ComputeDomain. Điều này giúp việc quản lý topology nâng cao cho workload AI phân tán trên UltraServer EC2 P6e-GB200 trở nên khả thi.</p><h3 id=bước-6-xác-minh-tài-nguyên-dra>Bước 6: Xác minh tài nguyên DRA</h3><p>Kiểm tra xem các tài nguyên DRA đã khả dụng chưa:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl api-resources | grep resource.k8s.io/v1beta1
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Output:</span>
</span></span><span style=display:flex><span><span style=color:#75715e># deviceclasses                    resource.k8s.io/v1beta1        false        DeviceClass</span>
</span></span><span style=display:flex><span><span style=color:#75715e># resourceclaims                   resource.k8s.io/v1beta1        true         ResourceClaim</span>
</span></span><span style=display:flex><span><span style=color:#75715e># resourceclaimtemplates           resource.k8s.io/v1beta1        true         ResourceClaimTemplate</span>
</span></span><span style=display:flex><span><span style=color:#75715e># resourceslices                   resource.k8s.io/v1beta1        false        ResourceSlice</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>kubectl get deviceclasses
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Output:</span>
</span></span><span style=display:flex><span><span style=color:#75715e># NAME                              CAPACITY   ALLOCATABLE   ALLOCATED</span>
</span></span><span style=display:flex><span><span style=color:#75715e># compute-domain-daemon.nvidia.com  36         36            0</span>
</span></span><span style=display:flex><span><span style=color:#75715e># gpu.nvidia.com                    0          0             0</span>
</span></span><span style=display:flex><span><span style=color:#75715e># mig.nvidia.com                    0          0             0</span>
</span></span></code></pre></div><hr><h2 id=xác-thực-cấp-kênh-imex>Xác thực cấp kênh IMEX</h2><p>Khi GPU Operator và DRA driver đã cấu hình, bạn có thể tạo các kênh IMEX để cho phép truy cập bộ nhớ trực tiếp giữa GPU xuyên các node. Ví dụ sau minh họa cách một tài nguyên ComputeDomain tự cấp phát hạ tầng IMEX cần thiết:</p><p>Tạo file <code>imex-channel-injection.yaml</code>:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#75715e># filename: imex-channel-injection.yaml</span>
</span></span><span style=display:flex><span>---
</span></span><span style=display:flex><span><span style=color:#f92672>apiVersion</span>: <span style=color:#ae81ff>resource.nvidia.com/v1beta1</span>
</span></span><span style=display:flex><span><span style=color:#f92672>kind</span>: <span style=color:#ae81ff>ComputeDomain</span>
</span></span><span style=display:flex><span><span style=color:#f92672>metadata</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>name</span>: <span style=color:#ae81ff>imex-channel-injection</span>
</span></span><span style=display:flex><span><span style=color:#f92672>spec</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>numNodes</span>: <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>channel</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>resourceClaimTemplate</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>name</span>: <span style=color:#ae81ff>imex-channel-0</span>
</span></span><span style=display:flex><span>---
</span></span><span style=display:flex><span><span style=color:#f92672>apiVersion</span>: <span style=color:#ae81ff>v1</span>
</span></span><span style=display:flex><span><span style=color:#f92672>kind</span>: <span style=color:#ae81ff>Pod</span>
</span></span><span style=display:flex><span><span style=color:#f92672>metadata</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>name</span>: <span style=color:#ae81ff>imex-channel-injection</span>
</span></span><span style=display:flex><span><span style=color:#f92672>spec</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>affinity</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>nodeAffinity</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>requiredDuringSchedulingIgnoredDuringExecution</span>:
</span></span><span style=display:flex><span>        <span style=color:#f92672>nodeSelectorTerms</span>:
</span></span><span style=display:flex><span>          - <span style=color:#f92672>matchExpressions</span>:
</span></span><span style=display:flex><span>              - <span style=color:#f92672>key</span>: <span style=color:#ae81ff>nvidia.com/gpu.clique</span>
</span></span><span style=display:flex><span>                <span style=color:#f92672>operator</span>: <span style=color:#ae81ff>Exists</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>containers</span>:
</span></span><span style=display:flex><span>    - <span style=color:#f92672>name</span>: <span style=color:#ae81ff>ctr</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>image</span>: <span style=color:#ae81ff>ubuntu:22.04</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>command</span>: [<span style=color:#e6db74>&#34;bash&#34;</span>, <span style=color:#e6db74>&#34;-c&#34;</span>]
</span></span><span style=display:flex><span>      <span style=color:#f92672>args</span>: [<span style=color:#e6db74>&#34;ls -la /dev/nvidia-caps-imex-channels; trap &#39;exit 0&#39; TERM; sleep 9999 &amp; wait&#34;</span>]
</span></span><span style=display:flex><span>      <span style=color:#f92672>resources</span>:
</span></span><span style=display:flex><span>        <span style=color:#f92672>claims</span>:
</span></span><span style=display:flex><span>          - <span style=color:#f92672>name</span>: <span style=color:#ae81ff>imex-channel-0</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>resourceClaims</span>:
</span></span><span style=display:flex><span>    - <span style=color:#f92672>name</span>: <span style=color:#ae81ff>imex-channel-0</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>resourceClaimTemplateName</span>: <span style=color:#ae81ff>imex-channel-0</span>
</span></span></code></pre></div><p>YAML này tạo một tài nguyên ComputeDomain và tham chiếu nó từ một pod. Controller ComputeDomain tự động tạo ResourceClaimTemplate, pod sử dụng để truy cập kênh IMEX. Ở phía sau, việc này kích hoạt việc triển khai daemon IMEX trên node được chọn, và tạo miền IMEX một cách động thay vì thiết lập tĩnh trước.</p><p><strong>Áp dụng và xác thực:</strong></p><p>Bạn sẽ thấy pod như <code>imex-channel-injection-...</code> trong trạng thái Running.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl apply -f imex-channel-injection.yaml
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Confirm the pod that runs to configure the compute domain</span>
</span></span><span style=display:flex><span>kubectl get pods -n nvidia-dra-driver-gpu -l resource.nvidia.com/computeDomain
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Output:</span>
</span></span><span style=display:flex><span><span style=color:#75715e># NAME                                   READY   STATUS    RESTARTS      AGE</span>
</span></span><span style=display:flex><span><span style=color:#75715e># imex-channel-injection-zrrlw-b6dqx     1/1     Running   5 (2m34s ago) 4m5s</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Confirm the IMEX channel is created</span>
</span></span><span style=display:flex><span>kubectl logs imex-channel-injection
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Output:</span>
</span></span><span style=display:flex><span><span style=color:#75715e># total 0</span>
</span></span><span style=display:flex><span><span style=color:#75715e># drwxr-xr-x. 2 root root  60 Apr 22 00:15 .</span>
</span></span><span style=display:flex><span><span style=color:#75715e># drwxr-xr-x. 6 root root 380 Apr 22 00:15 ..</span>
</span></span><span style=display:flex><span><span style=color:#75715e># crw-rw-rw-. 1 root root 241, 0 Apr 22 00:15 channel0</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Show logs of the pod configuring IMEX for the compute domain</span>
</span></span><span style=display:flex><span>kubectl logs -n nvidia-dra-driver-gpu -l resource.nvidia.com/computeDomain --tail<span style=color:#f92672>=</span>-1
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Output:</span>
</span></span><span style=display:flex><span><span style=color:#75715e># /etc/nvidia-imex/nodes_config.cfg:</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 192.168.56.245</span>
</span></span><span style=display:flex><span><span style=color:#75715e># IMEX Log initializing at: 4/22/2025 00:14:21.228</span>
</span></span><span style=display:flex><span><span style=color:#75715e># [Apr 22 2025 00:14:21] [INFO] [tid 43] IMEX version 570.133.20 is running with the following configuration options</span>
</span></span><span style=display:flex><span><span style=color:#75715e># [Apr 22 2025 00:14:21] [INFO] [tid 43] Logging level = 4</span>
</span></span><span style=display:flex><span><span style=color:#75715e># [Apr 22 2025 00:14:21] [INFO] [tid 43] Logging file name/path = /var/log/nvidia-imex.log</span>
</span></span><span style=display:flex><span><span style=color:#75715e># [Apr 22 2025 00:14:21] [INFO] [tid 43] Append to log file = 0</span>
</span></span><span style=display:flex><span><span style=color:#75715e># [Apr 22 2025 00:14:21] [INFO] [tid 43] Max Log file size = 1024 (MBs)</span>
</span></span><span style=display:flex><span><span style=color:#75715e># [Apr 22 2025 00:14:21] [INFO] [tid 43] Use Syslog file = 0</span>
</span></span><span style=display:flex><span><span style=color:#75715e># [Apr 22 2025 00:14:21] [INFO] [tid 43] IMEX Library communication bind interface =</span>
</span></span><span style=display:flex><span><span style=color:#75715e># [Apr 22 2025 00:14:21] [INFO] [tid 43] IMEX library communication bind port = 50000</span>
</span></span><span style=display:flex><span><span style=color:#75715e># [Apr 22 2025 00:14:21] [INFO] [tid 43] Identified this node as ID 0, using bind IP of &#39;196.181.26.911&#39;, and network interface of enp4s0</span>
</span></span><span style=display:flex><span><span style=color:#75715e># [Apr 22 2025 00:14:21] [INFO] [tid 43] nvidia-imex persistence file /var/run/nvidia-imex/persist.dat does not exist. Assuming no previous importers.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># [Apr 22 2025 00:14:21] [INFO] [tid 43] NvGpu Library version matched with GPU Driver version</span>
</span></span><span style=display:flex><span><span style=color:#75715e># [Apr 22 2025 00:14:21] [INFO] [tid 70] Started processing of incoming messages.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># [Apr 22 2025 00:14:21] [INFO] [tid 71] Started processing of incoming messages.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># [Apr 22 2025 00:14:21] [INFO] [tid 72] Started processing of incoming messages.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># [Apr 22 2025 00:14:21] [INFO] [tid 43] Creating gRPC channels to all peers (nPeers = 1).</span>
</span></span><span style=display:flex><span><span style=color:#75715e># [Apr 22 2025 00:14:21] [INFO] [tid 73] Started processing of incoming messages.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># [Apr 22 2025 00:14:21] [INFO] [tid 43] IMEX_WAIT_FOR_QUORUM != FULL, continuing initialization without waiting for connections to all nodes.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># [Apr 22 2025 00:14:21] [INFO] [tid 43] GPU event successfully subscribed</span>
</span></span><span style=display:flex><span><span style=color:#75715e># [Apr 22 2025 00:14:21] [INFO] [tid 74] Connection established to node 0 with ip address 192.168.56.245. Number of times connected: 1</span>
</span></span></code></pre></div><p>Kết quả log sẽ cho biết thông tin khởi tạo IMEX, thiết lập gRPC giữa nodes, và xác nhận rằng miền bộ nhớ đồng nhất được kích hoạt. Điều này cho thấy GPU bộ nhớ từ các node khác nhau trong UltraServer giờ có thể truy cập trực tiếp qua NVLink. Kết quả cuối là hiệu năng chưa từng có cho workload AI phân tán.</p><h3 id=giao-tiếp-imex-đa-node-trong-thực-tế>Giao tiếp IMEX đa node trong thực tế</h3><p>Để minh họa cách driver DRA điều phối giao tiếp GPU xuyên node, phần tiếp theo triển khai một benchmark MPI đa node sử dụng kênh IMEX cho truyền bộ nhớ GPU-to-GPU băng thông cao xuyên các node EC2 P6e-GB200 UltraServer.</p><h4 id=triển-khai-job-mpi-đa-node>Triển khai Job MPI đa node</h4><p>Tạo file yaml <code>nvbandwidth-test-job.yaml</code>:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#75715e># nvbandwidth-test-job.yaml</span>
</span></span><span style=display:flex><span>---
</span></span><span style=display:flex><span><span style=color:#f92672>apiVersion</span>: <span style=color:#ae81ff>resource.nvidia.com/v1beta1</span>
</span></span><span style=display:flex><span><span style=color:#f92672>kind</span>: <span style=color:#ae81ff>ComputeDomain</span>
</span></span><span style=display:flex><span><span style=color:#f92672>metadata</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>name</span>: <span style=color:#ae81ff>nvbandwidth-test-compute-domain</span>
</span></span><span style=display:flex><span><span style=color:#f92672>spec</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>numNodes</span>: <span style=color:#ae81ff>2</span>  <span style=color:#75715e># Request 2 nodes for cross-node testing</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>channel</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>resourceClaimTemplate</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>name</span>: <span style=color:#ae81ff>nvbandwidth-test-compute-domain-channel</span>
</span></span><span style=display:flex><span>---
</span></span><span style=display:flex><span><span style=color:#f92672>apiVersion</span>: <span style=color:#ae81ff>kubeflow.org/v2beta1</span>
</span></span><span style=display:flex><span><span style=color:#f92672>kind</span>: <span style=color:#ae81ff>MPIJob</span>
</span></span><span style=display:flex><span><span style=color:#f92672>metadata</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>name</span>: <span style=color:#ae81ff>nvbandwidth-test</span>
</span></span><span style=display:flex><span><span style=color:#f92672>spec</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>slotsPerWorker</span>: <span style=color:#ae81ff>4</span>  <span style=color:#75715e># 4 GPUs per worker node</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>launcherCreationPolicy</span>: <span style=color:#ae81ff>WaitForWorkersReady</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>mpiReplicaSpecs</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>Worker</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>replicas</span>: <span style=color:#ae81ff>2</span>  <span style=color:#75715e># 2 worker nodes</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>template</span>:
</span></span><span style=display:flex><span>        <span style=color:#f92672>spec</span>:
</span></span><span style=display:flex><span>          <span style=color:#f92672>containers</span>:
</span></span><span style=display:flex><span>            - <span style=color:#f92672>image</span>: <span style=color:#ae81ff>ghcr.io/nvidia/k8s-samples:nvbandwidth-v0.7-8d103163</span>
</span></span><span style=display:flex><span>              <span style=color:#f92672>name</span>: <span style=color:#ae81ff>mpi-worker</span>
</span></span><span style=display:flex><span>              <span style=color:#f92672>resources</span>:
</span></span><span style=display:flex><span>                <span style=color:#f92672>limits</span>:
</span></span><span style=display:flex><span>                  <span style=color:#f92672>nvidia.com/gpu</span>: <span style=color:#ae81ff>4</span>  <span style=color:#75715e># Request 4 GPUs per worker</span>
</span></span><span style=display:flex><span>                <span style=color:#f92672>claims</span>:
</span></span><span style=display:flex><span>                  - <span style=color:#f92672>name</span>: <span style=color:#ae81ff>compute-domain-channel </span> <span style=color:#75715e># Link to IMEX channel</span>
</span></span><span style=display:flex><span>          <span style=color:#f92672>resourceClaims</span>:
</span></span><span style=display:flex><span>            - <span style=color:#f92672>name</span>: <span style=color:#ae81ff>compute-domain-channel</span>
</span></span><span style=display:flex><span>              <span style=color:#f92672>resourceClaimTemplateName</span>: <span style=color:#ae81ff>nvbandwidth-test-compute-domain-channel</span>
</span></span></code></pre></div><p>Khi áp file này:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl apply -f nvbandwidth-test-job.yaml
</span></span></code></pre></div><ol><li><p><strong>ComputeDomain creation and node selection:</strong> Trình điều khiển DRA ngay lập tức bắt đầu sắp xếp thiết lập nhiều node:
a. Xác định 2 node có GPU GB200 có sẵn
b. Xác minh các node thuộc cùng một domain NVLink
c. Tạo tài nguyên ComputeDomain resource</p></li><li><p><strong>IMEX domain establishment:</strong> DRA tự động hóa:
a. Triển khai nhóm daemon IMEX trên cả hai node đã chọn
b. Định cấu hình các kênh cross-node gRPC
c. Thiết lập shared memory mappings giữa các GPU</p></li></ol><p>Kết quả của experiment chứng minh DRA biến cụm GPU đa node thành tài nguyên hợp nhất, cho phép huấn luyện LLM trải khắp các node UltraServer với truy cập bộ nhớ GPU native trong khi vẫn giữ hiệu suất tối ưu. Tất cả 72 GPU trong một UltraServer u-p6e-gb200x72 hiển thị như một vùng nhớ thống nhất cho ứng dụng, và Kubernetes đảm trách toàn bộ orchestration IMEX phức tạp để đội ngũ dữ liệu chỉ cần tập trung vào mô hình, không phải hạ tầng.</p><hr><h2 id=kết-luận>Kết luận</h2><p>Amazon EC2 P6e-GB200 UltraServers trên Amazon EKS đại diện cho bước tiến lớn cho người dùng muốn huấn luyện và triển khai mô hình AI nghìn tỷ tham số ở quy mô. Sự kết hợp giữa GPU Grace Blackwell của NVIDIA với NVLink, hỗ trợ từ Amazon EKS, DRA và công cụ của NVIDIA, đã giúp AWS đưa tính toán AI ở cấp exascale vào phạm vi tiếp cận thông qua các pattern quản lý container quen thuộc.</p><p>Việc tích hợp các kênh IMEX và NVLink cho phép tạo cụm GPU đồng nhất bộ nhớ trải khắp các node và rack, phá vỡ giới hạn truyền thống của tính toán GPU cục bộ node. Cải tiến kiến trúc này mở ra các khả năng mới cho:</p><ul><li>Huấn luyện mô hình nền tảng hàng nghìn tỷ tham số</li><li>Chạy AI đa phương thức với yêu cầu hiệu suất thời gian thực</li><li>Triển khai pipeline suy luận phức tạp với độ trễ dưới một giây</li></ul><p>Để bắt đầu với DRA trên Amazon EKS, bạn có thể tham khảo tài liệu <strong>Amazon EKS AI/ML</strong> để có hướng dẫn toàn diện, và khám phá dự án <strong>AI on EKS</strong>, cung cấp các ví dụ <strong>DRA</strong> bạn có thể thử nghiệm và triển khai trong môi trường của mình.</p><div class="notices warning"><p><strong>LƯU Ý BẢO MẬT:</strong> Các cấu hình trình bày trong bài viết này chỉ là ví dụ cơ bản nhằm minh họa chức năng cốt lõi. Trong môi trường sản xuất, bạn nên bổ sung các kiểm soát bảo mật. Hãy liên hệ với nhóm tài khoản AWS của bạn để biết thêm về cách sử dụng P6e-GB200 trên Amazon EKS.</p></div><hr><h2 id=về-tác-giả>Về tác giả</h2><p><img alt="Vara Bonthu" src=https://khanh-0.github.io/aws/images/Blog/Blog_2/blavt2_1.png></p><p><strong>Vara Bonthu</strong> là Chuyên gia SA chuyên về mã nguồn mở dẫn đầu Data trên EKS và AI trên EKS tại AWS, thúc đẩy các sáng kiến mã nguồn mở và hỗ trợ khách hàng từ nhiều tổ chức. Ông chuyên sâu về công nghệ mã nguồn mở, phân tích dữ liệu, AI/ML và Kubernetes, với kinh nghiệm sâu rộng trong phát triển, DevOps và kiến trúc.</p><hr><p><img alt="Chris Splinter" src=https://khanh-0.github.io/aws/images/Blog/Blog_2/blavt2_2.png></p><p><strong>Chris Splinter</strong> là Quản lý Sản phẩm cao cấp nhóm Amazon EKS, tập trung vào hỗ trợ khách hàng chạy workload AI với Kubernetes.</p><hr><p><img alt="Nick Baker" src=https://khanh-0.github.io/aws/images/Blog/Blog_2/blavt2_3.png></p><p><strong>Nick Baker</strong> là Kỹ sư phát triển phần mềm trong Nhóm Node Runtime trên Amazon EKS. Anh tập trung vào việc bổ sung hỗ trợ cho workload tăng tốc và cải thiện tính ổn định data-plane trên EKS.</p><footer class=footline></footer></div></div><div id=navigation><a class="nav nav-prev" href=https://khanh-0.github.io/aws/vi/3-blogstranslated/3.1-blog1/ title="Dynamic Kubernetes request right sizing with Kubecost"><i class="fa fa-chevron-left"></i></a>
<a class="nav nav-next" href=https://khanh-0.github.io/aws/vi/3-blogstranslated/3.3-blog3/ title="Cách Strangeworks sử dụng Amazon Braket để khám phá vấn đề xếp hàng hóa lên máy bay" style=margin-right:0><i class="fa fa-chevron-right"></i></a></div></section><div style=left:-1000px;overflow:scroll;position:absolute;top:-1000px;border:none;box-sizing:content-box;height:200px;margin:0;padding:0;width:200px><div style=border:none;box-sizing:content-box;height:200px;margin:0;padding:0;width:200px></div></div><script src=https://khanh-0.github.io/aws/js/clipboard.min.js?1765372027></script><script src=https://khanh-0.github.io/aws/js/perfect-scrollbar.min.js?1765372027></script><script src=https://khanh-0.github.io/aws/js/perfect-scrollbar.jquery.min.js?1765372027></script><script src=https://khanh-0.github.io/aws/js/jquery.sticky.js?1765372027></script><script src=https://khanh-0.github.io/aws/js/featherlight.min.js?1765372027></script><script src=https://khanh-0.github.io/aws/js/highlight.pack.js?1765372027></script><script>hljs.initHighlightingOnLoad()</script><script src=https://khanh-0.github.io/aws/js/modernizr.custom-3.6.0.js?1765372027></script><script src=https://khanh-0.github.io/aws/js/learn.js?1765372027></script><script src=https://khanh-0.github.io/aws/js/hugo-learn.js?1765372027></script><link href=https://khanh-0.github.io/aws/mermaid/mermaid.css?1765372027 rel=stylesheet><script src=https://khanh-0.github.io/aws/mermaid/mermaid.js?1765372027></script><script>mermaid.initialize({startOnLoad:!0})</script><script>(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,(e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date),(i=t.createElement(n),a=t.getElementsByTagName(n)[0]),i.async=1,i.src=s,a.parentNode.insertBefore(i,a)})(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-158079754-2","auto"),ga("send","pageview")</script></body></html>