<!doctype html><html lang=en class="js csstransforms3d"><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=generator content="Hugo 0.134.3"><meta name=description content><meta name=author content="thienlh@thienlu.com"><link rel=icon href=https://khanh-0.github.io/aws/images/favicon.png type=image/png><title>Unlocking Next-Generation AI Performance with Dynamic Resource Allocation on Amazon EKS & EC2 P6e-GB200 :: Internship Report</title>
<link href=https://khanh-0.github.io/aws/css/nucleus.css?1765372027 rel=stylesheet><link href=https://khanh-0.github.io/aws/css/fontawesome-all.min.css?1765372027 rel=stylesheet><link href=https://khanh-0.github.io/aws/css/hybrid.css?1765372027 rel=stylesheet><link href=https://khanh-0.github.io/aws/css/featherlight.min.css?1765372027 rel=stylesheet><link href=https://khanh-0.github.io/aws/css/perfect-scrollbar.min.css?1765372027 rel=stylesheet><link href=https://khanh-0.github.io/aws/css/auto-complete.css?1765372027 rel=stylesheet><link href=https://khanh-0.github.io/aws/css/atom-one-dark-reasonable.css?1765372027 rel=stylesheet><link href=https://khanh-0.github.io/aws/css/theme.css?1765372027 rel=stylesheet><link href=https://khanh-0.github.io/aws/css/hugo-theme.css?1765372027 rel=stylesheet><link href=https://khanh-0.github.io/aws/css/theme-workshop.css?1765372027 rel=stylesheet><script src=https://khanh-0.github.io/aws/js/jquery-3.3.1.min.js?1765372027></script><style>:root #header+#content>#left>#rlblock_left{display:none!important}</style></head><body data-url=https://khanh-0.github.io/aws/3-blogstranslated/3.2-blog2/><nav id=sidebar class=showVisitedLinks><div id=header-wrapper><div id=header><a id=logo href=https://khanh-0.github.io/aws/><svg id="Layer_1" data-name="Layer 1" viewBox="0 0 60 30" width="30%"><defs><style>.cls-1{fill:#fff}.cls-2{fill:#f90;fill-rule:evenodd}</style></defs><title>AWS-Logo_White-Color</title><path class="cls-1" d="M14.09 10.85a4.7 4.7.0 00.19 1.48 7.73 7.73.0 00.54 1.19.77.77.0 01.12.38.64.64.0 01-.32.49l-1 .7a.83.83.0 01-.44.15.69.69.0 01-.49-.23 3.8 3.8.0 01-.6-.77q-.25-.42-.51-1a6.14 6.14.0 01-4.89 2.3 4.54 4.54.0 01-3.32-1.19 4.27 4.27.0 01-1.22-3.2 4.28 4.28.0 011.46-3.4A6.06 6.06.0 017.69 6.46a12.47 12.47.0 011.76.13q.92.13 1.91.36V5.73a3.65 3.65.0 00-.79-2.66A3.81 3.81.0 007.86 2.3a7.71 7.71.0 00-1.79.22 12.78 12.78.0 00-1.79.57 4.55 4.55.0 01-.58.22h-.26q-.35.0-.35-.52V2a1.09 1.09.0 01.12-.58 1.2 1.2.0 01.47-.35A10.88 10.88.0 015.77.32 10.19 10.19.0 018.36.0a6 6 0 014.35 1.35 5.49 5.49.0 011.38 4.09zM7.34 13.38a5.36 5.36.0 001.72-.31A3.63 3.63.0 0010.63 12 2.62 2.62.0 0011.19 11a5.63 5.63.0 00.16-1.44v-.7a14.35 14.35.0 00-1.53-.28 12.37 12.37.0 00-1.56-.1 3.84 3.84.0 00-2.47.67A2.34 2.34.0 005 11a2.35 2.35.0 00.61 1.76A2.4 2.4.0 007.34 13.38zm13.35 1.8a1 1 0 01-.64-.16 1.3 1.3.0 01-.35-.65L15.81 1.51a3 3 0 01-.15-.67.36.36.0 01.41-.41H17.7a1 1 0 01.65.16 1.4 1.4.0 01.33.65l2.79 11 2.59-11A1.17 1.17.0 0124.39.6a1.1 1.1.0 01.67-.16H26.4a1.1 1.1.0 01.67.16 1.17 1.17.0 01.32.65L30 12.39 32.88 1.25A1.39 1.39.0 0133.22.6a1 1 0 01.65-.16h1.54a.36.36.0 01.41.41 1.36 1.36.0 010 .26 3.64 3.64.0 01-.12.41l-4 12.86a1.3 1.3.0 01-.35.65 1 1 0 01-.64.16H29.25a1 1 0 01-.67-.17 1.26 1.26.0 01-.32-.67L25.67 3.64l-2.56 10.7a1.26 1.26.0 01-.32.67 1 1 0 01-.67.17zm21.36.44a11.28 11.28.0 01-2.56-.29 7.44 7.44.0 01-1.92-.67 1 1 0 01-.61-.93v-.84q0-.52.38-.52a.9.9.0 01.31.06l.42.17a8.77 8.77.0 001.83.58 9.78 9.78.0 002 .2 4.48 4.48.0 002.43-.55 1.76 1.76.0 00.86-1.57 1.61 1.61.0 00-.45-1.16A4.29 4.29.0 0043 9.22l-2.41-.76A5.15 5.15.0 0138 6.78a3.94 3.94.0 01-.83-2.41 3.7 3.7.0 01.45-1.85 4.47 4.47.0 011.19-1.37 5.27 5.27.0 011.7-.86A7.4 7.4.0 0142.6.0a8.87 8.87.0 011.12.07q.57.07 1.08.19t.95.26a4.27 4.27.0 01.7.29 1.59 1.59.0 01.49.41.94.94.0 01.15.55v.79q0 .52-.38.52a1.76 1.76.0 01-.64-.2 7.74 7.74.0 00-3.2-.64 4.37 4.37.0 00-2.21.47 1.6 1.6.0 00-.79 1.48 1.58 1.58.0 00.49 1.18 4.94 4.94.0 001.83.92L44.55 7a5.08 5.08.0 012.57 1.6A3.76 3.76.0 0147.9 11a4.21 4.21.0 01-.44 1.93 4.4 4.4.0 01-1.21 1.47 5.43 5.43.0 01-1.85.93A8.25 8.25.0 0142.05 15.62z"/><path class="cls-2" d="M45.19 23.81C39.72 27.85 31.78 30 25 30A36.64 36.64.0 01.22 20.57c-.51-.46-.06-1.09.56-.74A49.78 49.78.0 0025.53 26.4 49.23 49.23.0 0044.4 22.53C45.32 22.14 46.1 23.14 45.19 23.81z"/><path class="cls-2" d="M47.47 21.21c-.7-.9-4.63-.42-6.39-.21-.53.06-.62-.4-.14-.74 3.13-2.2 8.27-1.57 8.86-.83s-.16 5.89-3.09 8.35c-.45.38-.88.18-.68-.32C46.69 25.8 48.17 22.11 47.47 21.21z"/></svg></a></div><div class=searchbox><label for=search-by><i class="fas fa-search"></i></label>
<input data-search-input id=search-by type=search placeholder=Search...>
<span data-search-clear><i class="fas fa-times"></i></span></div><script type=text/javascript src=https://khanh-0.github.io/aws/js/lunr.min.js?1765372027></script><script type=text/javascript src=https://khanh-0.github.io/aws/js/auto-complete.js?1765372027></script><script type=text/javascript>var baseurl="https://khanh-0.github.io/aws/"</script><script type=text/javascript src=https://khanh-0.github.io/aws/js/search.js?1765372027></script></div><div class=highlightable><ul class=topics><li data-nav-id=/1-worklog/ title=Worklog class=dd-item><a href=https://khanh-0.github.io/aws/1-worklog/><b>1. </b>Worklog
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/1-worklog/1.1-week1/ title="Week 1 Worklog" class=dd-item><a href=https://khanh-0.github.io/aws/1-worklog/1.1-week1/><b>1.1. </b>Week 1 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.2-week2/ title="Week 2 Worklog" class=dd-item><a href=https://khanh-0.github.io/aws/1-worklog/1.2-week2/><b>1.2. </b>Week 2 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.3-week3/ title="Week 3 Worklog" class=dd-item><a href=https://khanh-0.github.io/aws/1-worklog/1.3-week3/><b>1.3. </b>Week 3 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.4-week4/ title="Week 4 Worklog" class=dd-item><a href=https://khanh-0.github.io/aws/1-worklog/1.4-week4/><b>1.4. </b>Week 4 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.5-week5/ title="Week 5 Worklog" class=dd-item><a href=https://khanh-0.github.io/aws/1-worklog/1.5-week5/><b>1.5. </b>Week 5 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.6-week6/ title="Week 6 Worklog" class=dd-item><a href=https://khanh-0.github.io/aws/1-worklog/1.6-week6/><b>1.6. </b>Week 6 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.7-week7/ title="Week 7 Worklog" class=dd-item><a href=https://khanh-0.github.io/aws/1-worklog/1.7-week7/><b>1.7. </b>Week 7 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.8-week8/ title="Week 8 Worklog" class=dd-item><a href=https://khanh-0.github.io/aws/1-worklog/1.8-week8/><b>1.8. </b>Week 8 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.9-week9/ title="Week 9 Worklog" class=dd-item><a href=https://khanh-0.github.io/aws/1-worklog/1.9-week9/><b>1.9. </b>Week 9 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.10-week10/ title="Week 10 Worklog" class=dd-item><a href=https://khanh-0.github.io/aws/1-worklog/1.10-week10/><b>1.10. </b>Week 10 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.11-week11/ title="Week 11 Worklog" class=dd-item><a href=https://khanh-0.github.io/aws/1-worklog/1.11-week11/><b>1.11. </b>Week 11 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.12-week12/ title="Week 12 Worklog" class=dd-item><a href=https://khanh-0.github.io/aws/1-worklog/1.12-week12/><b>1.12. </b>Week 12 Worklog
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/2-proposal/ title=Proposal class=dd-item><a href=https://khanh-0.github.io/aws/2-proposal/><b>2. </b>Proposal
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/3-blogstranslated/ title="Translated Blogs" class="dd-item
parent"><a href=https://khanh-0.github.io/aws/3-blogstranslated/><b>3. </b>Translated Blogs
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/3-blogstranslated/3.1-blog1/ title="Dynamic Kubernetes Request Right Sizing with Kubecost" class=dd-item><a href=https://khanh-0.github.io/aws/3-blogstranslated/3.1-blog1/><b>3.1. </b>Dynamic Kubernetes Request Right Sizing with Kubecost
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/3-blogstranslated/3.2-blog2/ title="Unlocking Next-Generation AI Performance with Dynamic Resource Allocation on Amazon EKS & EC2 P6e-GB200" class="dd-item
active"><a href=https://khanh-0.github.io/aws/3-blogstranslated/3.2-blog2/><b>3.2. </b>Unlocking Next-Generation AI Performance with Dynamic Resource Allocation on Amazon EKS & EC2 P6e-GB200
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/3-blogstranslated/3.3-blog3/ title="How Strangeworks Uses Amazon Braket to Explore Aircraft Loading Optimization" class=dd-item><a href=https://khanh-0.github.io/aws/3-blogstranslated/3.3-blog3/><b>3. </b>How Strangeworks Uses Amazon Braket to Explore Aircraft Loading Optimization
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/4-eventparticipated/ title="Events Participated" class=dd-item><a href=https://khanh-0.github.io/aws/4-eventparticipated/><b>4. </b>Events Participated
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/4-eventparticipated/4.1-event1/ title="Kick-off AWS First Cloud Journey Workforce" class=dd-item><a href=https://khanh-0.github.io/aws/4-eventparticipated/4.1-event1/><b>4.1. </b>Kick-off AWS First Cloud Journey Workforce
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/4-eventparticipated/4.2-event2/ title="Cloud Day AWS 2025 in HCMC" class=dd-item><a href=https://khanh-0.github.io/aws/4-eventparticipated/4.2-event2/><b>4.2. </b>Cloud Day AWS 2025 in HCMC
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/4-eventparticipated/4.3-event3/ title="AI-Driven Development Session with Amazon Q Developer & Kiro" class=dd-item><a href=https://khanh-0.github.io/aws/4-eventparticipated/4.3-event3/><b>4.3. </b>AI-Driven Development Session with Amazon Q Developer & Kiro
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/4-eventparticipated/4.4-event4/ title="CMC Global TechTalk Series – Cloud & Digital Transformation" class=dd-item><a href=https://khanh-0.github.io/aws/4-eventparticipated/4.4-event4/><b>4.4. </b>CMC Global TechTalk Series – Cloud & Digital Transformation
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/4-eventparticipated/4.5-event5/ title="AWS Cloud Mastery Series #1: AI/ML/GenAI on AWS" class=dd-item><a href=https://khanh-0.github.io/aws/4-eventparticipated/4.5-event5/><b>4.5. </b>AWS Cloud Mastery Series #1: AI/ML/GenAI on AWS
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/4-eventparticipated/4.6-event6/ title="AWS Cloud Mastery Series #2: DevOps on AWS" class=dd-item><a href=https://khanh-0.github.io/aws/4-eventparticipated/4.6-event6/><b>4.6. </b>AWS Cloud Mastery Series #2: DevOps on AWS
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/4-eventparticipated/4.7-event7/ title="CloundFront as Your Foundation And AWS WAF & Application Protection" class=dd-item><a href=https://khanh-0.github.io/aws/4-eventparticipated/4.7-event7/><b>4.7. </b>CloundFront as Your Foundation And AWS WAF & Application Protection
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/4-eventparticipated/4.8-event8/ title="Game Day – Secret Agent(ic) Unicorns" class=dd-item><a href=https://khanh-0.github.io/aws/4-eventparticipated/4.8-event8/><b>4.8. </b>Game Day – Secret Agent(ic) Unicorns
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/4-eventparticipated/4.9-event9/ title="AWS Cloud Mastery Series #3: Security Pillar – AWS Well-Architected" class=dd-item><a href=https://khanh-0.github.io/aws/4-eventparticipated/4.9-event9/><b>4.9. </b>AWS Cloud Mastery Series #3: Security Pillar – AWS Well-Architected
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/5-workshop/ title=Workshop class=dd-item><a href=https://khanh-0.github.io/aws/5-workshop/><b>5. </b>Workshop
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/5-workshop/5.1-workshop-overview/ title=Introduction class=dd-item><a href=https://khanh-0.github.io/aws/5-workshop/5.1-workshop-overview/><b>5.1. </b>Introduction
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/5-workshop/5.2-prerequiste/ title="Preparation Steps" class=dd-item><a href=https://khanh-0.github.io/aws/5-workshop/5.2-prerequiste/><b>5.2. </b>Preparation Steps
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/5-workshop/5.3-architecture/ title="RAG Architecture Deployed on AWS AgentCore" class=dd-item><a href=https://khanh-0.github.io/aws/5-workshop/5.3-architecture/><b>5.3. </b>RAG Architecture Deployed on AWS AgentCore
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/5-workshop/5.3-architecture/5.3.1-agentcore-memory/ title="AgentCore Memory" class=dd-item><a href=https://khanh-0.github.io/aws/5-workshop/5.3-architecture/5.3.1-agentcore-memory/><b>5.3.1 </b>AgentCore Memory
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/5-workshop/5.3-architecture/5.3.2-groq-api/ title="Calling Groq API" class=dd-item><a href=https://khanh-0.github.io/aws/5-workshop/5.3-architecture/5.3.2-groq-api/><b>5.3.2 </b>Calling Groq API
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/5-workshop/5.3-architecture/5.3.3-chunking/ title="Chunking & Embedding" class=dd-item><a href=https://khanh-0.github.io/aws/5-workshop/5.3-architecture/5.3.3-chunking/><b>5.3.3 </b>Chunking & Embedding
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/5-workshop/5.4-agent-core-run/ title="Run Agent Core" class=dd-item><a href=https://khanh-0.github.io/aws/5-workshop/5.4-agent-core-run/><b>5.4. </b>Run Agent Core
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/5-workshop/5.4-agent-core-run/5.4.1-run-agentcore/ title="Configure & Deploy AgentCore" class=dd-item><a href=https://khanh-0.github.io/aws/5-workshop/5.4-agent-core-run/5.4.1-run-agentcore/><b>5.4.1 </b>Configure & Deploy AgentCore
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/5-workshop/5.4-agent-core-run/5.4.2-call-agentcore/ title="Calling AgentCore" class=dd-item><a href=https://khanh-0.github.io/aws/5-workshop/5.4-agent-core-run/5.4.2-call-agentcore/><b>5.4.2 </b>Calling AgentCore
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/5-workshop/5.5-clean/ title="Clean up" class=dd-item><a href=https://khanh-0.github.io/aws/5-workshop/5.5-clean/><b>5.5 </b>Clean up
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/6-self-evaluation/ title=Self-Assessment class=dd-item><a href=https://khanh-0.github.io/aws/6-self-evaluation/><b>6. </b>Self-Assessment
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/7-feedback/ title="Sharing and Feedback" class=dd-item><a href=https://khanh-0.github.io/aws/7-feedback/><b>7. </b>Sharing and Feedback
<i class="fas fa-check read-icon"></i></a></li></ul><section id=shortcuts><h3>More</h3><ul><li><a class=padding href=https://www.facebook.com/groups/awsstudygroupfcj/><i class='fab fa-facebook'></i> AWS Study Group</a></li></ul></section><section id=prefooter><hr><ul><li><a class=padding><i class="fas fa-language fa-fw"></i><div class=select-style><select id=select-language onchange="location=this.value"><option id=en value=https://khanh-0.github.io/aws/3-blogstranslated/3.2-blog2/ selected>English</option><option id=vi value=https://khanh-0.github.io/aws/vi/3-blogstranslated/3.2-blog2/>Tiếng Việt</option></select><svg id="Capa_1" xmlns:xlink="http://www.w3.org/1999/xlink" width="255" height="255" viewBox="0 0 255 255" style="enable-background:new 0 0 255 255"><g><g id="arrow-drop-down"><polygon points="0,63.75 127.5,191.25 255,63.75"/></g></g></svg></div></a></li><li><a class=padding href=# data-clear-history-toggle><i class="fas fa-history fa-fw"></i> Clear History</a></li></ul></section><section id=footer><left><b>Workshop</b><br><img src="https://hitwebcounter.com/counter/counter.php?page=7920860&style=0038&nbdigits=9&type=page&initCount=0" title=Migrate alt="web counter" border=0></a><br><b><a href=https://cloudjourney.awsstudygroup.com/>Cloud Journey</a></b><br><img src="https://hitwebcounter.com/counter/counter.php?page=7830807&style=0038&nbdigits=9&type=page&initCount=0" title="Total CLoud Journey" alt="web counter" border=0>
</left><left><br><br><b>Last Updated</b><br><i><span id=lastUpdated style=color:orange></span>
</i><script>const today=new Date,formattedDate=today.toLocaleDateString("en-GB");document.getElementById("lastUpdated").textContent=formattedDate</script></left><left><br><br><b>Team</b><br><i><a href=https://www.facebook.com/groups/660548818043427 style=color:orange>First Cloud Journey</a><br></i></left><script async defer src=https://buttons.github.io/buttons.js></script></section></div></nav><section id=body><div id=overlay></div><div class="padding highlightable"><div><div id=top-bar><div id=breadcrumbs itemscope itemtype=http://data-vocabulary.org/Breadcrumb><span id=sidebar-toggle-span><a href=# id=sidebar-toggle data-sidebar-toggle><i class="fas fa-bars"></i>
</a></span><span id=toc-menu><i class="fas fa-list-alt"></i></span>
<span class=links><a href=https://khanh-0.github.io/aws/>Internship Report</a> > <a href=https://khanh-0.github.io/aws/3-blogstranslated/>Translated Blogs</a> > Unlocking Next-Generation AI Performance with Dynamic Resource Allocation on Amazon EKS & EC2 P6e-GB200
          
       </span></div><div class=progress><div class=wrapper><nav id=TableOfContents><ul><li><a href=#the-power-behind-the-p6e-gb200-nvidia-gb200-grace-blackwell-architecture>The Power Behind the P6e-GB200: NVIDIA GB200 Grace Blackwell Architecture</a></li><li><a href=#understanding-ec2-p6e-gb200-ultraserver-architecture>Understanding EC2 P6e-GB200 UltraServer Architecture</a></li><li><a href=#integrating-p6e-gb200-ultraservers-with-amazon-eks>Integrating P6e-GB200 UltraServers with Amazon EKS</a></li><li><a href=#challenge-running-distributed-ai-workloads-on-kubernetes>Challenge: Running Distributed AI Workloads on Kubernetes</a></li><li><a href=#solution-kubernetes-dra-and-imex>Solution: Kubernetes DRA and IMEX</a><ul><li><a href=#how-dra-resolves-traditional-gpu-allocation-limits>How DRA Resolves Traditional GPU Allocation Limits</a></li><li><a href=#topology-aware-scheduling--memory-coherence>Topology-aware Scheduling & Memory Coherence</a></li><li><a href=#dra-workload-scheduling-workflow>DRA Workload Scheduling Workflow</a></li></ul></li><li><a href=#using-p6e-gb200-with-kubernetes-dra-on-amazon-eks>Using P6e-GB200 with Kubernetes DRA on Amazon EKS</a><ul><li><a href=#prerequisites>Prerequisites</a></li><li><a href=#step-1-reserve-ultraserver-p6e-gb200-capacity>Step 1: Reserve UltraServer P6e-GB200 Capacity</a></li><li><a href=#step-2-create-eks-cluster-configuration-file>Step 2: Create EKS Cluster Configuration File</a></li><li><a href=#step-3-deploy-eks-cluster>Step 3: Deploy EKS Cluster</a></li><li><a href=#step-4-deploy-nvidia-gpu-operator>Step 4: Deploy NVIDIA GPU Operator</a></li><li><a href=#step-5-install-nvidia-dra-driver>Step 5: Install NVIDIA DRA Driver</a></li><li><a href=#step-6-verify-dra-resources>Step 6: Verify DRA Resources</a></li></ul></li><li><a href=#validate-imex-channels>Validate IMEX Channels</a></li><li><a href=#multi-node-imex-communication-in-practice>Multi-Node IMEX Communication in Practice</a><ul><li><a href=#deploy-multi-node-mpi-job>Deploy Multi-Node MPI Job</a></li></ul></li><li><a href=#conclusion>Conclusion</a></li><li><a href=#about-the-authors>About the Authors</a></li></ul></nav></div></div></div></div><div id=head-tags></div><div id=body-inner><h1>Unlocking Next-Generation AI Performance with Dynamic Resource Allocation on Amazon EKS & EC2 P6e-GB200</h1><hr><h1 id=unlocking-next-generation-ai-performance-with-dynamic-resource-allocation-on-amazon-eks--ec2-p6e-gb200>Unlocking Next-Generation AI Performance with Dynamic Resource Allocation on Amazon EKS & EC2 P6e-GB200</h1><p><em>By Vara Bonthu, Nick Baker, and Chris Splinter – September 2, 2025</em></p><p>The rapid evolution of agentic AI and large language models (LLMs), especially reasoning models, has created unprecedented demands for computational resources. Modern advanced AI models span hundreds of billions to trillions of parameters and require massive compute power, large memory, and high-speed interconnects to operate efficiently.</p><p>Organizations developing applications for natural language processing, scientific simulations, 3D content generation, and multimodal reasoning need infrastructure that can scale from today’s hundreds-of-billion-parameter models to future trillion-parameter boundaries while maintaining performance.</p><p>In this article, we explore how <strong><a href=https://aws.amazon.com/ec2/>Amazon Elastic Compute Cloud (Amazon EC2)</a> <a href=https://aws.amazon.com/ec2/instance-types/p6/>P6e-GB200 UltraServers</a></strong> transform distributed AI workloads through seamless integration with Kubernetes.</p><p>AWS introduces the EC2 P6e-GB200 UltraServers to meet the growing demand for large-scale AI model training and inference. They represent a significant architectural breakthrough for distributed AI workloads. Moreover, the launch of the EC2 P6e-GB200 UltraServer includes support for <strong><a href=https://aws.amazon.com/eks/>Amazon EKS (Elastic Kubernetes Service)</a></strong>, providing a Kubernetes-native environment to deploy and scale from hundreds-of-billion-parameter models to trillions of parameters as AI landscapes continue to evolve.</p><hr><h2 id=the-power-behind-the-p6e-gb200-nvidia-gb200-grace-blackwell-architecture>The Power Behind the P6e-GB200: NVIDIA GB200 Grace Blackwell Architecture</h2><p>At the core of EC2 P6e-GB200 UltraServers is the <strong><a href=https://www.nvidia.com/en-us/data-center/gb200-nvl72/>NVIDIA GB200 Grace Blackwell Superchip</a></strong>, which integrates two NVIDIA Blackwell GPUs and one NVIDIA Grace CPU. Additionally, it provides NVLink Chip-to-Chip (C2C) connectivity between these components, delivering <strong>900 GB/s</strong> bidirectional bandwidth—significantly faster than traditional PCIe interfaces.</p><p>When deployed at rack scale, EC2 P6e-GB200 UltraServers participate in NVIDIA’s <strong><a href=https://developer.nvidia.com/blog/nvidia-contributes-nvidia-gb200-nvl72-designs-to-open-compute-project/>NVL72</a></strong> architecture, creating memory-coherent domains up to 72 GPUs.</p><p>Fifth-generation <strong><a href=https://www.nvidia.com/en-us/data-center/nvlink/>NVLink</a></strong> enables GPU-to-GPU communication across hosts within the same domain at up to <strong>1.8 TB/s per GPU</strong>. A key enabler of this performance is the <strong><a href=https://aws.amazon.com/hpc/efa/>Elastic Fabric Adapter (EFAv4)</a></strong> network, providing total network bandwidth up to <strong>28.8 Tbps</strong> per UltraServer.</p><p>EFA, combined with <strong>NVIDIA GPUDirect RDMA</strong>, enables GPU-to-GPU communication across hosts with low latency, bypassing the operating system. This ensures that the distributed GPU fabric operates with near-local memory performance across nodes.</p><p>This marks a significant improvement over previous EC2 P6-B200 UltraServers, which offered up to eight B200 Blackwell GPUs on x86 PCIe-based platforms. The P6e-GB200 upgrades the architecture by providing truly unified memory across racks—a critical requirement for training and operating trillion-parameter models efficiently.</p><p><img alt="Amazon EC2 P6e-GB200 UltraServers" src=https://khanh-0.github.io/aws/images/p6e-ultraserver.jpg>
<em>Figure 1: Amazon EC2 P6e-GB200 UltraServers</em></p><hr><h2 id=understanding-ec2-p6e-gb200-ultraserver-architecture>Understanding EC2 P6e-GB200 UltraServer Architecture</h2><p>An EC2 P6e-GB200 UltraServer <strong>is not a single EC2 instance</strong>. Instead, it consists of multiple EC2 instances connected to operate as a unified entity:</p><ul><li><strong>u-p6e-gb200x36</strong>: 36 GPUs distributed across 9 EC2 instances</li><li><strong>u-p6e-gb200x72</strong>: 72 GPUs distributed across 18 EC2 instances</li></ul><p>Each P6e-GB200 instance provides 4 NVIDIA Blackwell GPUs. Therefore:</p><ul><li>A <strong>u-p6e-gb200x36</strong> UltraServer = 9 instances (9 × 4 = 36 GPUs)</li><li>A <strong>u-p6e-gb200x72</strong> UltraServer = 18 instances (18 × 4 = 72 GPUs)</li></ul><p>In Amazon EKS, each EC2 instance appears as a separate Kubernetes node, but EKS understands topology location and treats them as part of the same UltraServer through topology-aware routing.</p><hr><h2 id=integrating-p6e-gb200-ultraservers-with-amazon-eks>Integrating P6e-GB200 UltraServers with Amazon EKS</h2><p>The Amazon EKS team collaborated closely with NVIDIA from the outset to establish integration requirements for P6e-GB200 with Kubernetes worker and control plane nodes. Based on these requirements, we developed <strong><a href=https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AMIs.html>AMI (Amazon Machine Images)</a></strong> for ARM64 <strong><a href=https://aws.amazon.com/linux/amazon-linux-2023/>Amazon Linux 2023</a></strong> with NVIDIA flavor.</p><p>We also pre-packaged binaries for <strong><a href=https://docs.nvidia.com/multi-node-nvlink-systems/imex-guide/overview.html>Internal Node Memory Exchange/Management Service (IMEX)</a></strong> and installed the required NVIDIA driver version.</p><p>Furthermore, Amazon EKS quickly supported <strong><a href=https://kubernetes.io/docs/concepts/scheduling-eviction/dynamic-resource-allocation/>Dynamic Resource Allocation (DRA)</a></strong> for users starting from Kubernetes 1.33 on EKS (this feature is still in beta in vanilla Kubernetes).</p><p>Instances have been validated with NVLink via IMEX as well as via EFA to achieve optimal data flow within and between UltraServers. Internally, we leverage <strong>NVIDIA Collective Communications Library (NCCL)</strong> to abstract transport-level decisions from the application layer.</p><hr><h2 id=challenge-running-distributed-ai-workloads-on-kubernetes>Challenge: Running Distributed AI Workloads on Kubernetes</h2><p>Deploying tightly coupled GPU workloads across multiple traditional nodes presents challenges in Kubernetes. Kubernetes’ traditional resource allocation assumes hardware tied to each node, making GPU resource management and memory-coherent interconnects across nodes difficult.</p><p>This is common for large-scale training workloads, such as LLMs or computer vision models requiring many GPUs to operate in parallel.</p><p>A traditional approach when requesting GPUs in a pod looks like this:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>resources</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>limits</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>nvidia.com/gpu</span>: <span style=color:#ae81ff>2</span>
</span></span></code></pre></div><p>This static approach works for local GPUs but cannot represent complex interconnect topologies or GPU-to-GPU communication channels required by distributed training frameworks.</p><hr><h2 id=solution-kubernetes-dra-and-imex>Solution: Kubernetes DRA and IMEX</h2><p>To address these challenges, Kubernetes introduces <strong>DRA (Dynamic Resource Allocation)</strong>, an extension framework that goes beyond traditional CPU and memory to handle complex hardware topologies.</p><p>Amazon EKS enabled DRA in Kubernetes 1.33, providing sophisticated GPU topology management that static GPU allocation cannot achieve.</p><h3 id=how-dra-resolves-traditional-gpu-allocation-limits>How DRA Resolves Traditional GPU Allocation Limits</h3><p>Unlike static resource models (e.g., <code>nvidia.com/gpu: 2</code>)—where you request a fixed number of GPUs without considering topology—DRA allows applications to declaratively describe resource requests via <strong>ComputeDomain</strong> and <strong>ResourceClaims</strong>.</p><p>This fundamental shift enables Kubernetes to make intelligent resource decisions based on actual topology, considering NVLink connectivity, memory bandwidth, and physical distance automatically.</p><p>Critically, DRA abstracts away complex manual configurations, such as IMEX setup, NVLink partition management, and low-level hardware initialization, which would otherwise require deep GPU cluster expertise.</p><p>The <strong>NVIDIA DRA Driver</strong> is the key connector between Kubernetes DRA APIs and underlying hardware, including two specialized kubelet plugins:</p><ul><li><code>gpu-kubelet-plugin</code>: for advanced GPU allocation features</li><li><code>compute-domain-kubelet-plugin</code>: automatically orchestrates IMEX primitives</li></ul><p>When creating a <strong>ComputeDomain</strong> requesting 36 GPUs across 9 EC2 instances (each with 4 Blackwell GPUs) or 72 GPUs across 18 instances for a full UltraServer, the system automatically:</p><ul><li>Deploys the IMEX daemon</li><li>Establishes gRPC communication between nodes</li><li>Creates a memory-coherent domain with cross-node mappings</li><li>Exposes device files in containers</li></ul><h3 id=topology-aware-scheduling--memory-coherence>Topology-aware Scheduling & Memory Coherence</h3><p>When a node joins an EKS cluster, the control plane receives topology information via the EC2 topology API and labels Kubernetes nodes:</p><ul><li>Each P6e-GB200 node is automatically labeled with capacity block type (<code>eks.amazonaws.com/capacityType=CAPACITY_BLOCK</code> and <code>eks.amazonaws.com/nodegroup=...</code>) and detailed network topology labels (<code>topology.k8s.aws/network-node-layer-1</code> through <code>network-node-layer-4</code>)</li><li>These labels indicate physical location within the UltraServer network fabric</li></ul><p>When <strong>GPU Feature Discovery (GFD)</strong> is enabled in <strong><a href=https://github.com/NVIDIA/gpu-operator>NVIDIA GPU Operator</a></strong>, it applies clique labels (<code>nvidia.com/gpu.clique</code>) to identify GPUs within the same NVLink domain.</p><p>This topology enables scheduling-aware workloads across or within UltraServer node groups.</p><p><strong>IMEX</strong> is the core capability that allows GPUs across different nodes to directly access each other’s memory over NVLink. When an <strong>IMEX channel</strong> is provisioned via Kubernetes and DRA through a ComputeDomain, it appears in the container as a device file (e.g., <code>/dev/nvidia-caps-imex-channels/channel0</code>).</p><p>This allows CUDA applications to operate as if all GPUs were on the same board.</p><p>This capability is critical for distributed training frameworks like <strong><a href=https://docs.open-mpi.org/en/v5.0.x/index.html>MPI</a></strong> and <strong><a href=https://developer.nvidia.com/nccl>NCCL</a></strong>, now achieving near &ldquo;bare-metal&rdquo; performance across node boundaries without custom configuration or code changes.</p><p><strong><a href=https://www.nvidia.com/en-us/data-center/nvlink/>NVLink 5.0</a></strong> provides the bandwidth foundation to operate these channels at <strong>1.8 TB/s</strong> bidirectionally per GPU.</p><p>This enables memory-coherent compute domains across racks—foundational for real-time multi-node AI systems. In the NVL72 architecture, up to 72 GPUs can connect in a single memory-coherent NVLink domain.</p><p>GPUs are organized into <strong>cliques</strong> based on physical NVSwitch connections, with all GPUs in the same node belonging to the same clique and sharing a Cluster UUID.</p><p>With GFD enabled, <code>nvidia.com/gpu.clique</code> labels each node with NVL domain ID and clique ID (e.g., <code>cluster-abc.0</code>), enabling scheduling-aware topology using node affinity rules.</p><p>When scheduling training across 9 nodes of u-p6e-gb200x36 or 18 nodes of u-p6e-gb200x72, the kube-scheduler ensures all nodes belong to the same NVLink domain for maximum bandwidth.</p><p>While NVLink provides ultra-high bandwidth within a physical domain, EFA ensures low-latency, high-throughput communication between different UltraServers. EFA’s RDMA capability combined with GPUDirect allows GPUs to communicate directly across nodes, creating a hybrid architecture where intra-UltraServer uses NVLink and inter-UltraServer uses EFA.</p><p>This makes the P6e-GB200 ideal for training massive models that scale from single-rack deployments to multi-rack supercomputers while maintaining optimal performance characteristics at all scales.</p><h3 id=dra-workload-scheduling-workflow>DRA Workload Scheduling Workflow</h3><p>The diagram below illustrates how Kubernetes DRA integrates with NVIDIA GB200 IMEX to deploy distributed AI training workloads across nodes.</p><p>When a pod requests 8 GPUs for distributed training with properly configured affinity rules, the system orchestrates deployment through a coordinated process:</p><ol><li>Users specify targeted pods by node affinity (<code>nvidia.com/gpu.clique</code>)</li><li>Kube-scheduler places pods according to these affinity constraints</li><li>DRA components manage resource allocation and node coordination</li><li>NVIDIA driver handles GPU allocation and IMEX orchestration</li><li>IMEX service ensures memory consistency across nodes via gRPC</li></ol><p>The result is seamless deployment across two nodes (each with 4 GPUs) within the same NVLink domain, enabling high-bandwidth, low-latency communication essential for large-scale AI training workloads.</p><p><img alt="DRA Workflow" src=https://khanh-0.github.io/aws/images/Blog/Blog_2/bl2_2.png></p><hr><h2 id=using-p6e-gb200-with-kubernetes-dra-on-amazon-eks>Using P6e-GB200 with Kubernetes DRA on Amazon EKS</h2><p>This section provides step-by-step guidance to set up an EKS cluster with EC2 P6e-GB200 UltraServers to leverage the above capabilities.</p><h3 id=prerequisites>Prerequisites</h3><p>Before starting, ensure you have the following tools and access. Refer to the <strong><a href=https://docs.aws.amazon.com/eks/latest/userguide/setting-up.html>EKS User Guide</a></strong>.</p><ul><li>Installed <strong><a href=https://aws.amazon.com/cli/>AWS CLI</a></strong></li><li><code>eksctl</code> (version supporting EKS 1.33)</li><li><code>kubectl</code></li><li><code>helm</code></li><li>EC2 <strong>Capacity Blocks</strong> access for P6e-GB200 instances</li></ul><h3 id=step-1-reserve-ultraserver-p6e-gb200-capacity>Step 1: Reserve UltraServer P6e-GB200 Capacity</h3><div class="notices note"><p>P6e-GB200 UltraServers are available only through <strong>Capacity Blocks</strong> for machine learning (ML). You must <strong>reserve the UltraServer (not individual instances)</strong> before creating an EKS cluster.</p></div><p>In the AWS console:</p><ol><li><p>Go to <strong>EC2 Console → Capacity Reservations → Capacity Blocks</strong></p></li><li><p>Select the <strong>UltraServers</strong> tab (not Instances)</p></li><li><p>Choose one of:</p><ul><li><code>u-p6e-gb200x36</code> (36 GPUs across 9 instances)</li><li><code>u-p6e-gb200x72</code> (72 GPUs across 18 instances)</li></ul></li><li><p>Complete the reservation for the desired time period</p></li></ol><h3 id=step-2-create-eks-cluster-configuration-file>Step 2: Create EKS Cluster Configuration File</h3><p>Create a file named <code>cluster-config.yaml</code> with the following content:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#75715e># cluster-config.yaml</span>
</span></span><span style=display:flex><span><span style=color:#f92672>apiVersion</span>: <span style=color:#ae81ff>eksctl.io/v1alpha5</span>
</span></span><span style=display:flex><span><span style=color:#f92672>kind</span>: <span style=color:#ae81ff>ClusterConfig</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>metadata</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>name</span>: <span style=color:#ae81ff>p6e-cluster</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>region</span>: <span style=color:#ae81ff>us-east-1</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>version</span>: <span style=color:#e6db74>&#39;1.33&#39;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>iam</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>withOIDC</span>: <span style=color:#66d9ef>true</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>managedNodeGroups</span>:
</span></span><span style=display:flex><span>  - <span style=color:#f92672>name</span>: <span style=color:#ae81ff>p6e-nodegroup</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>amiFamily</span>: <span style=color:#ae81ff>AmazonLinux2023</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>instanceType</span>: <span style=color:#ae81ff>p6e-gb200.36xlarge</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>desiredCapacity</span>: <span style=color:#ae81ff>9</span>  <span style=color:#75715e># All 9 instances from the UltraServer (36 GPUs total)</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>minSize</span>: <span style=color:#ae81ff>9</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>maxSize</span>: <span style=color:#ae81ff>9</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>labels</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>nvidia.com/gpu.present</span>: <span style=color:#e6db74>&#34;true&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>taints</span>:
</span></span><span style=display:flex><span>      - <span style=color:#f92672>key</span>: <span style=color:#ae81ff>nvidia.com/gpu</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>value</span>: <span style=color:#e6db74>&#34;true&#34;</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>effect</span>: <span style=color:#ae81ff>NoSchedule</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>availabilityZones</span>: [<span style=color:#e6db74>&#34;us-east-1-dfw-2a&#34;</span>]
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># Enable EFA (mandatory for P6e-GB200 UltraServers)</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>efaEnabled</span>: <span style=color:#66d9ef>true</span>
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#f92672>capacityReservation</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>enabled</span>: <span style=color:#66d9ef>true</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>capacityReservationTarget</span>:
</span></span><span style=display:flex><span>        <span style=color:#f92672>capacityReservationId</span>: <span style=color:#e6db74>&#34;cr-1234567890abcdef&#34;</span>  <span style=color:#75715e># Replace with your reservation ID</span>
</span></span></code></pre></div><h3 id=step-3-deploy-eks-cluster>Step 3: Deploy EKS Cluster</h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>eksctl create cluster -f cluster-config.yaml
</span></span></code></pre></div><p>This command creates an EKS 1.33 cluster with 9 <code>p6e-gb200.36xlarge</code> instances from your reserved UltraServer, with EFA network enabled to optimize GPU-to-GPU communication.</p><h3 id=step-4-deploy-nvidia-gpu-operator>Step 4: Deploy NVIDIA GPU Operator</h3><p>The NVIDIA GPU Operator is essential for GB200 instances as it manages the full GPU lifecycle—including runtime configuration and advanced features such as MIG.</p><p>With complex NVLink topology spanning multiple nodes, GPU Operator dynamically manages GPU resources, configures MIG, and handles interconnect relationships that static plugins cannot.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># Add the NVIDIA GPU Operator Helm repository</span>
</span></span><span style=display:flex><span>helm repo add nvidia https://nvidia.github.io/gpu-operator
</span></span><span style=display:flex><span>helm repo update
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Deploy the NVIDIA GPU Operator with custom values</span>
</span></span><span style=display:flex><span>cat <span style=color:#e6db74>&lt;&lt;EOF &gt; gpu-operator-values.yaml
</span></span></span><span style=display:flex><span><span style=color:#e6db74># gpu-operator-values.yaml
</span></span></span><span style=display:flex><span><span style=color:#e6db74>driver:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>  enabled: false
</span></span></span><span style=display:flex><span><span style=color:#e6db74>
</span></span></span><span style=display:flex><span><span style=color:#e6db74>mig:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>  strategy: mixed
</span></span></span><span style=display:flex><span><span style=color:#e6db74>
</span></span></span><span style=display:flex><span><span style=color:#e6db74>migManager:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>  enabled: true
</span></span></span><span style=display:flex><span><span style=color:#e6db74>  env:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    - name: WITH_REBOOT
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      value: &#34;true&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>  config:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    create: true
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    name: custom-mig-parted-configs
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    default: &#34;all-disabled&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    data:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      config.yaml: |-
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        version: v1
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        mig-configs:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>          all-disabled:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            - devices: all
</span></span></span><span style=display:flex><span><span style=color:#e6db74>              mig-enabled: false
</span></span></span><span style=display:flex><span><span style=color:#e6db74>          # P4DE profiles (A100 80GB)
</span></span></span><span style=display:flex><span><span style=color:#e6db74>          p4de-half-balanced:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            - devices: [0, 1, 2, 3]
</span></span></span><span style=display:flex><span><span style=color:#e6db74>              mig-enabled: true
</span></span></span><span style=display:flex><span><span style=color:#e6db74>              mig-devices:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>                &#34;1g.10gb&#34;: 2
</span></span></span><span style=display:flex><span><span style=color:#e6db74>                &#34;2g.20gb&#34;: 1
</span></span></span><span style=display:flex><span><span style=color:#e6db74>                &#34;3g.40gb&#34;: 1
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            - devices: [4, 5, 6, 7]
</span></span></span><span style=display:flex><span><span style=color:#e6db74>              mig-enabled: false
</span></span></span><span style=display:flex><span><span style=color:#e6db74>
</span></span></span><span style=display:flex><span><span style=color:#e6db74>devicePlugin:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>  enabled: true
</span></span></span><span style=display:flex><span><span style=color:#e6db74>  config:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    name: &#34;&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    create: false
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    default: &#34;&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>
</span></span></span><span style=display:flex><span><span style=color:#e6db74>toolkit:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>  enabled: false
</span></span></span><span style=display:flex><span><span style=color:#e6db74>
</span></span></span><span style=display:flex><span><span style=color:#e6db74>nfd:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>  enabled: true
</span></span></span><span style=display:flex><span><span style=color:#e6db74>
</span></span></span><span style=display:flex><span><span style=color:#e6db74>gfd:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>  enabled: true
</span></span></span><span style=display:flex><span><span style=color:#e6db74>
</span></span></span><span style=display:flex><span><span style=color:#e6db74>dcgmExporter:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>  enabled: true
</span></span></span><span style=display:flex><span><span style=color:#e6db74>  serviceMonitor:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    enabled: true
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    interval: 15s
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    honorLabels: false
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    additionalLabels:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      release: kube-prometheus-stack
</span></span></span><span style=display:flex><span><span style=color:#e6db74>
</span></span></span><span style=display:flex><span><span style=color:#e6db74>daemonsets:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>  tolerations:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    - key: &#34;nvidia.com/gpu&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      operator: &#34;Exists&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      effect: &#34;NoSchedule&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>  nodeSelector:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    accelerator: nvidia
</span></span></span><span style=display:flex><span><span style=color:#e6db74>  priorityClassName: system-node-critical
</span></span></span><span style=display:flex><span><span style=color:#e6db74>EOF</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Install GPU Operator using values file</span>
</span></span><span style=display:flex><span>helm install gpu-operator nvidia/gpu-operator <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --namespace gpu-operator <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --create-namespace <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --version v25.3.1 <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --values gpu-operator-values.yaml
</span></span></code></pre></div><h3 id=step-5-install-nvidia-dra-driver>Step 5: Install NVIDIA DRA Driver</h3><p>The NVIDIA DRA driver is essential for P6e-GB200 UltraServers, providing capabilities beyond traditional GPU plugins.</p><p>While the standard NVIDIA Device Plugin exposes individual GPUs as countable resources (<code>nvidia.com/gpu: 2</code>), the DRA driver extends two important capabilities:</p><ol><li><strong>ComputeDomain Management</strong>: DRA Driver manages ComputeDomains—an abstraction for Multi-Node NVLink (MNNVL) deployments</li><li><strong>Advanced GPU Allocation</strong>: Beyond counting GPUs, it allows dynamic GPU allocation, MIG devices, and scheduling-aware topology</li></ol><p>The DRA driver includes two kubelet plugins:</p><ul><li><code>gpu-kubelet-plugin</code>: for advanced GPU allocation functions</li><li><code>compute-domain-kubelet-plugin</code>: orchestrates ComputeDomain</li></ul><p>Create a <code>values.yaml</code> for **<a href=https://github.com/NVIDIA/k8s-dra-driver-gpu>NVIDIA DRA Driver</a>`:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#75715e># values.yaml</span>
</span></span><span style=display:flex><span>---
</span></span><span style=display:flex><span><span style=color:#f92672>nvidiaDriverRoot</span>: <span style=color:#ae81ff>/</span>
</span></span><span style=display:flex><span><span style=color:#f92672>gpuResourcesEnabledOverride</span>: <span style=color:#66d9ef>true</span>  <span style=color:#75715e># Required to deploy GPU and MIG deviceclasses</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>resources</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>gpus</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>enabled</span>: <span style=color:#66d9ef>true</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>computeDomains</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>enabled</span>: <span style=color:#66d9ef>true</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>controller</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>nodeSelector</span>: <span style=color:#66d9ef>null</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>affinity</span>: <span style=color:#66d9ef>null</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>tolerations</span>: []
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>kubeletPlugin</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>affinity</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>nodeAffinity</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>requiredDuringSchedulingIgnoredDuringExecution</span>:
</span></span><span style=display:flex><span>        <span style=color:#ae81ff>node</span>
</span></span></code></pre></div><p>Then install the NVIDIA DRA driver:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>helm repo add nvidia https://helm.ngc.nvidia.com/nvidia
</span></span><span style=display:flex><span>helm repo update
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>helm install nvidia-dra-driver-gpu nvidia/nvidia-dra-driver-gpu <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --version<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;25.3.0-rc.4&#34;</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --namespace nvidia-dra-driver-gpu <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --create-namespace <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  -f values.yaml
</span></span></code></pre></div><p>After installation, the DRA driver creates <strong>DeviceClass</strong> resources that allow Kubernetes to understand and allocate ComputeDomains. This enables advanced topology management for distributed AI workloads on EC2 P6e-GB200 UltraServers.</p><h3 id=step-6-verify-dra-resources>Step 6: Verify DRA Resources</h3><p>Check if the DRA resources are available:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl api-resources | grep resource.k8s.io/v1beta1
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Output:</span>
</span></span><span style=display:flex><span><span style=color:#75715e># deviceclasses                    resource.k8s.io/v1beta1        false        DeviceClass</span>
</span></span><span style=display:flex><span><span style=color:#75715e># resourceclaims                   resource.k8s.io/v1beta1        true         ResourceClaim</span>
</span></span><span style=display:flex><span><span style=color:#75715e># resourceclaimtemplates           resource.k8s.io/v1beta1        true         ResourceClaimTemplate</span>
</span></span><span style=display:flex><span><span style=color:#75715e># resourceslices                   resource.k8s.io/v1beta1        false        ResourceSlice</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>kubectl get deviceclasses
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Output:</span>
</span></span><span style=display:flex><span><span style=color:#75715e># NAME                              CAPACITY   ALLOCATABLE   ALLOCATED</span>
</span></span><span style=display:flex><span><span style=color:#75715e># compute-domain-daemon.nvidia.com  36         36            0</span>
</span></span><span style=display:flex><span><span style=color:#75715e># gpu.nvidia.com                    0          0             0</span>
</span></span><span style=display:flex><span><span style=color:#75715e># mig.nvidia.com                    0          0             0</span>
</span></span></code></pre></div><hr><h2 id=validate-imex-channels>Validate IMEX Channels</h2><p>Once the GPU Operator and DRA driver are configured, you can create IMEX channels to enable direct GPU memory access across nodes. The example below shows how a ComputeDomain resource automatically provisions the required IMEX infrastructure:</p><p>Create <code>imex-channel-injection.yaml</code>:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#75715e># filename: imex-channel-injection.yaml</span>
</span></span><span style=display:flex><span>---
</span></span><span style=display:flex><span><span style=color:#f92672>apiVersion</span>: <span style=color:#ae81ff>resource.nvidia.com/v1beta1</span>
</span></span><span style=display:flex><span><span style=color:#f92672>kind</span>: <span style=color:#ae81ff>ComputeDomain</span>
</span></span><span style=display:flex><span><span style=color:#f92672>metadata</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>name</span>: <span style=color:#ae81ff>imex-channel-injection</span>
</span></span><span style=display:flex><span><span style=color:#f92672>spec</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>numNodes</span>: <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>channel</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>resourceClaimTemplate</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>name</span>: <span style=color:#ae81ff>imex-channel-0</span>
</span></span><span style=display:flex><span>---
</span></span><span style=display:flex><span><span style=color:#f92672>apiVersion</span>: <span style=color:#ae81ff>v1</span>
</span></span><span style=display:flex><span><span style=color:#f92672>kind</span>: <span style=color:#ae81ff>Pod</span>
</span></span><span style=display:flex><span><span style=color:#f92672>metadata</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>name</span>: <span style=color:#ae81ff>imex-channel-injection</span>
</span></span><span style=display:flex><span><span style=color:#f92672>spec</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>affinity</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>nodeAffinity</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>requiredDuringSchedulingIgnoredDuringExecution</span>:
</span></span><span style=display:flex><span>        <span style=color:#f92672>nodeSelectorTerms</span>:
</span></span><span style=display:flex><span>          - <span style=color:#f92672>matchExpressions</span>:
</span></span><span style=display:flex><span>              - <span style=color:#f92672>key</span>: <span style=color:#ae81ff>nvidia.com/gpu.clique</span>
</span></span><span style=display:flex><span>                <span style=color:#f92672>operator</span>: <span style=color:#ae81ff>Exists</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>containers</span>:
</span></span><span style=display:flex><span>    - <span style=color:#f92672>name</span>: <span style=color:#ae81ff>ctr</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>image</span>: <span style=color:#ae81ff>ubuntu:22.04</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>command</span>: [<span style=color:#e6db74>&#34;bash&#34;</span>, <span style=color:#e6db74>&#34;-c&#34;</span>]
</span></span><span style=display:flex><span>      <span style=color:#f92672>args</span>: [<span style=color:#e6db74>&#34;ls -la /dev/nvidia-caps-imex-channels; trap &#39;exit 0&#39; TERM; sleep 9999 &amp; wait&#34;</span>]
</span></span><span style=display:flex><span>      <span style=color:#f92672>resources</span>:
</span></span><span style=display:flex><span>        <span style=color:#f92672>claims</span>:
</span></span><span style=display:flex><span>          - <span style=color:#f92672>name</span>: <span style=color:#ae81ff>imex-channel-0</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>resourceClaims</span>:
</span></span><span style=display:flex><span>    - <span style=color:#f92672>name</span>: <span style=color:#ae81ff>imex-channel-0</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>resourceClaimTemplateName</span>: <span style=color:#ae81ff>imex-channel-0</span>
</span></span></code></pre></div><p>This YAML creates a ComputeDomain resource and references it from a pod. The ComputeDomain controller automatically generates the ResourceClaimTemplate, which the pod uses to access the IMEX channel. Behind the scenes, this triggers deployment of the IMEX daemon on the selected node and dynamically establishes the IMEX domain instead of requiring a static setup.</p><p><strong>Apply and verify:</strong></p><p>You should see the pod <code>imex-channel-injection-...</code> in Running state.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl apply -f imex-channel-injection.yaml
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Confirm the pod that runs to configure the compute domain</span>
</span></span><span style=display:flex><span>kubectl get pods -n nvidia-dra-driver-gpu -l resource.nvidia.com/computeDomain
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Output:</span>
</span></span><span style=display:flex><span><span style=color:#75715e># NAME                                   READY   STATUS    RESTARTS      AGE</span>
</span></span><span style=display:flex><span><span style=color:#75715e># imex-channel-injection-zrrlw-b6dqx     1/1     Running   5 (2m34s ago) 4m5s</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Confirm the IMEX channel is created</span>
</span></span><span style=display:flex><span>kubectl logs imex-channel-injection
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Output:</span>
</span></span><span style=display:flex><span><span style=color:#75715e># total 0</span>
</span></span><span style=display:flex><span><span style=color:#75715e># drwxr-xr-x. 2 root root  60 Apr 22 00:15 .</span>
</span></span><span style=display:flex><span><span style=color:#75715e># drwxr-xr-x. 6 root root 380 Apr 22 00:15 ..</span>
</span></span><span style=display:flex><span><span style=color:#75715e># crw-rw-rw-. 1 root root 241, 0 Apr 22 00:15 channel0</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Show logs of the pod configuring IMEX for the compute domain</span>
</span></span><span style=display:flex><span>kubectl logs -n nvidia-dra-driver-gpu -l resource.nvidia.com/computeDomain --tail<span style=color:#f92672>=</span>-1
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Output:</span>
</span></span><span style=display:flex><span><span style=color:#75715e># /etc/nvidia-imex/nodes_config.cfg:</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 192.168.56.245</span>
</span></span><span style=display:flex><span><span style=color:#75715e># IMEX Log initializing at: 4/22/2025 00:14:21.228</span>
</span></span><span style=display:flex><span><span style=color:#75715e># [INFO] IMEX version 570.133.20 is running with configuration options</span>
</span></span><span style=display:flex><span><span style=color:#75715e># [INFO] GPU event successfully subscribed</span>
</span></span><span style=display:flex><span><span style=color:#75715e># [INFO] Connection established to node 0 with IP 192.168.56.245</span>
</span></span></code></pre></div><p>The logs show IMEX initialization, gRPC setup between nodes, and confirmation that the unified memory domain is active. GPUs across nodes in the UltraServer can now access memory directly over NVLink, providing unprecedented performance for distributed AI workloads.</p><hr><h2 id=multi-node-imex-communication-in-practice>Multi-Node IMEX Communication in Practice</h2><p>To illustrate how the DRA driver coordinates GPU communication across nodes, the next section deploys a multi-node MPI benchmark using IMEX channels for high-bandwidth GPU-to-GPU memory transfers across EC2 P6e-GB200 UltraServer nodes.</p><h3 id=deploy-multi-node-mpi-job>Deploy Multi-Node MPI Job</h3><p>Create <code>nvbandwidth-test-job.yaml</code>:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#75715e># nvbandwidth-test-job.yaml</span>
</span></span><span style=display:flex><span>---
</span></span><span style=display:flex><span><span style=color:#f92672>apiVersion</span>: <span style=color:#ae81ff>resource.nvidia.com/v1beta1</span>
</span></span><span style=display:flex><span><span style=color:#f92672>kind</span>: <span style=color:#ae81ff>ComputeDomain</span>
</span></span><span style=display:flex><span><span style=color:#f92672>metadata</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>name</span>: <span style=color:#ae81ff>nvbandwidth-test-compute-domain</span>
</span></span><span style=display:flex><span><span style=color:#f92672>spec</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>numNodes</span>: <span style=color:#ae81ff>2</span>  <span style=color:#75715e># Request 2 nodes for cross-node testing</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>channel</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>resourceClaimTemplate</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>name</span>: <span style=color:#ae81ff>nvbandwidth-test-compute-domain-channel</span>
</span></span><span style=display:flex><span>---
</span></span><span style=display:flex><span><span style=color:#f92672>apiVersion</span>: <span style=color:#ae81ff>kubeflow.org/v2beta1</span>
</span></span><span style=display:flex><span><span style=color:#f92672>kind</span>: <span style=color:#ae81ff>MPIJob</span>
</span></span><span style=display:flex><span><span style=color:#f92672>metadata</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>name</span>: <span style=color:#ae81ff>nvbandwidth-test</span>
</span></span><span style=display:flex><span><span style=color:#f92672>spec</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>slotsPerWorker</span>: <span style=color:#ae81ff>4</span>  <span style=color:#75715e># 4 GPUs per worker node</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>launcherCreationPolicy</span>: <span style=color:#ae81ff>WaitForWorkersReady</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>mpiReplicaSpecs</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>Worker</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>replicas</span>: <span style=color:#ae81ff>2</span>  <span style=color:#75715e># 2 worker nodes</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>template</span>:
</span></span><span style=display:flex><span>        <span style=color:#f92672>spec</span>:
</span></span><span style=display:flex><span>          <span style=color:#f92672>containers</span>:
</span></span><span style=display:flex><span>            - <span style=color:#f92672>image</span>: <span style=color:#ae81ff>ghcr.io/nvidia/k8s-samples:nvbandwidth-v0.7-8d103163</span>
</span></span><span style=display:flex><span>              <span style=color:#f92672>name</span>: <span style=color:#ae81ff>mpi-worker</span>
</span></span><span style=display:flex><span>              <span style=color:#f92672>resources</span>:
</span></span><span style=display:flex><span>                <span style=color:#f92672>limits</span>:
</span></span><span style=display:flex><span>                  <span style=color:#f92672>nvidia.com/gpu</span>: <span style=color:#ae81ff>4</span>  <span style=color:#75715e># Request 4 GPUs per worker</span>
</span></span><span style=display:flex><span>                <span style=color:#f92672>claims</span>:
</span></span><span style=display:flex><span>                  - <span style=color:#f92672>name</span>: <span style=color:#ae81ff>compute-domain-channel </span> <span style=color:#75715e># Link to IMEX channel</span>
</span></span><span style=display:flex><span>          <span style=color:#f92672>resourceClaims</span>:
</span></span><span style=display:flex><span>            - <span style=color:#f92672>name</span>: <span style=color:#ae81ff>compute-domain-channel</span>
</span></span><span style=display:flex><span>              <span style=color:#f92672>resourceClaimTemplateName</span>: <span style=color:#ae81ff>nvbandwidth-test-compute-domain-channel</span>
</span></span></code></pre></div><p>Apply with:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl apply -f nvbandwidth-test-job.yaml
</span></span></code></pre></div><ol><li><p><strong>ComputeDomain creation and node selection:</strong> The DRA driver immediately selects nodes:</p><ul><li>Identifies 2 nodes with available GB200 GPUs</li><li>Ensures nodes belong to the same NVLink domain</li><li>Creates the ComputeDomain resource</li></ul></li><li><p><strong>IMEX domain establishment:</strong> DRA automatically:</p><ul><li>Deploys IMEX daemons on both nodes</li><li>Configures cross-node gRPC channels</li><li>Sets up shared memory mappings between GPUs</li></ul></li></ol><p>The experiment shows that DRA transforms multi-node GPU clusters into a unified resource, enabling LLM training across UltraServer nodes with native GPU memory access while maintaining optimal performance. All 72 GPUs in a u-p6e-gb200x72 UltraServer appear as a single memory domain, with Kubernetes orchestrating IMEX automatically so data teams can focus on modeling instead of infrastructure.</p><h2 id=conclusion>Conclusion</h2><p>Amazon EC2 P6e-GB200 UltraServers on Amazon EKS represent a major advancement for users looking to train and deploy trillion-parameter AI models at scale. The combination of NVIDIA Grace Blackwell GPUs with NVLink, support from Amazon EKS, DRA, and NVIDIA tooling has made exascale AI computing accessible through familiar container management patterns.</p><p>The integration of IMEX channels and NVLink enables a unified GPU memory cluster across nodes and racks, breaking the traditional limits of node-local GPU computing. This architectural improvement unlocks new possibilities for:</p><ul><li>Training foundation models with trillions of parameters</li><li>Running multimodal AI workloads with real-time performance requirements</li><li>Deploying complex inference pipelines with sub-second latency</li></ul><p>To get started with DRA on Amazon EKS, refer to the <strong>Amazon EKS AI/ML</strong> documentation for comprehensive guidance and explore the <strong>AI on EKS</strong> project, which provides <strong>DRA</strong> examples you can experiment with and deploy in your environment.</p><div class="notices warning"><p><strong>SECURITY NOTE:</strong> The configurations presented in this article are basic examples intended to illustrate core functionality. In production environments, you should implement additional security controls. Contact your AWS account team for guidance on using P6e-GB200 on Amazon EKS.</p></div><hr><h2 id=about-the-authors>About the Authors</h2><p><img alt="Vara Bonthu" src=https://khanh-0.github.io/aws/images/Blog/Blog_2/blavt2_1.png></p><p><strong>Vara Bonthu</strong> is a Senior SA specializing in open-source data and AI on EKS at AWS, driving open-source initiatives and supporting customers across organizations. He has deep expertise in open-source technologies, data analytics, AI/ML, and Kubernetes, with extensive experience in development, DevOps, and architecture.</p><hr><p><img alt="Chris Splinter" src=https://khanh-0.github.io/aws/images/Blog/Blog_2/blavt2_2.png></p><p><strong>Chris Splinter</strong> is a Senior Product Manager on the Amazon EKS team, focusing on helping customers run AI workloads with Kubernetes.</p><hr><p><img alt="Nick Baker" src=https://khanh-0.github.io/aws/images/Blog/Blog_2/blavt2_3.png></p><p><strong>Nick Baker</strong> is a Software Development Engineer on the Node Runtime team at Amazon EKS. He focuses on enhancing support for accelerated workloads and improving data-plane stability on EKS.</p><footer class=footline></footer></div></div><div id=navigation><a class="nav nav-prev" href=https://khanh-0.github.io/aws/3-blogstranslated/3.1-blog1/ title="Dynamic Kubernetes Request Right Sizing with Kubecost"><i class="fa fa-chevron-left"></i></a>
<a class="nav nav-next" href=https://khanh-0.github.io/aws/3-blogstranslated/3.3-blog3/ title="How Strangeworks Uses Amazon Braket to Explore Aircraft Loading Optimization" style=margin-right:0><i class="fa fa-chevron-right"></i></a></div></section><div style=left:-1000px;overflow:scroll;position:absolute;top:-1000px;border:none;box-sizing:content-box;height:200px;margin:0;padding:0;width:200px><div style=border:none;box-sizing:content-box;height:200px;margin:0;padding:0;width:200px></div></div><script src=https://khanh-0.github.io/aws/js/clipboard.min.js?1765372027></script><script src=https://khanh-0.github.io/aws/js/perfect-scrollbar.min.js?1765372027></script><script src=https://khanh-0.github.io/aws/js/perfect-scrollbar.jquery.min.js?1765372027></script><script src=https://khanh-0.github.io/aws/js/jquery.sticky.js?1765372027></script><script src=https://khanh-0.github.io/aws/js/featherlight.min.js?1765372027></script><script src=https://khanh-0.github.io/aws/js/highlight.pack.js?1765372027></script><script>hljs.initHighlightingOnLoad()</script><script src=https://khanh-0.github.io/aws/js/modernizr.custom-3.6.0.js?1765372027></script><script src=https://khanh-0.github.io/aws/js/learn.js?1765372027></script><script src=https://khanh-0.github.io/aws/js/hugo-learn.js?1765372027></script><link href=https://khanh-0.github.io/aws/mermaid/mermaid.css?1765372027 rel=stylesheet><script src=https://khanh-0.github.io/aws/mermaid/mermaid.js?1765372027></script><script>mermaid.initialize({startOnLoad:!0})</script><script>(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,(e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date),(i=t.createElement(n),a=t.getElementsByTagName(n)[0]),i.async=1,i.src=s,a.parentNode.insertBefore(i,a)})(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-158079754-2","auto"),ga("send","pageview")</script></body></html>